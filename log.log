Attaching to controller-1, kafka-1, db-1, kafka-ui-1, springcoreapi-1
controller-1  | ===> User
controller-1  | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
controller-1  | ===> Configuring ...
kafka-1       | ===> User
kafka-1       | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
kafka-1       | ===> Configuring ...
controller-1  | ===> Running preflight checks ... 
controller-1  | ===> Check if /var/lib/kafka/data is writable ...
controller-1  | ===> Using provided cluster id Nk018hRAQFytWskYqtQduw ...
kafka-1       | ===> Running preflight checks ... 
kafka-1       | ===> Check if /var/lib/kafka/data is writable ...
kafka-1       | ===> Using provided cluster id Nk018hRAQFytWskYqtQduw ...
db-1          | The files belonging to this database system will be owned by user "postgres".
db-1          | This user must also own the server process.
db-1          | 
db-1          | The database cluster will be initialized with locale "en_US.utf8".
db-1          | The default database encoding has accordingly been set to "UTF8".
db-1          | The default text search configuration will be set to "english".
db-1          | 
db-1          | Data page checksums are enabled.
db-1          | 
db-1          | fixing permissions on existing directory /var/lib/postgresql/18/docker ... ok
db-1          | creating subdirectories ... ok
db-1          | selecting dynamic shared memory implementation ... posix
db-1          | selecting default "max_connections" ... 100
db-1          | selecting default "shared_buffers" ... 128MB
db-1          | selecting default time zone ... Etc/UTC
db-1          | creating configuration files ... ok
db-1          | running bootstrap script ... ok
db-1          | performing post-bootstrap initialization ... ok
db-1          | syncing data to disk ... ok
db-1          | 
db-1          | 
db-1          | Success. You can now start the database server using:
db-1          | 
db-1          |     pg_ctl -D /var/lib/postgresql/18/docker -l logfile start
db-1          | 
db-1          | waiting for server to start....2025-11-13 18:47:44.650 UTC [51] LOG:  starting PostgreSQL 18.0 (Debian 18.0-1.pgdg13+3) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit
db-1          | 2025-11-13 18:47:44.657 UTC [51] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
db-1          | 2025-11-13 18:47:44.686 UTC [57] LOG:  database system was shut down at 2025-11-13 18:47:44 UTC
db-1          | 2025-11-13 18:47:44.700 UTC [51] LOG:  database system is ready to accept connections
kafka-ui-1    | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
db-1          |  done
db-1          | server started
db-1          | CREATE DATABASE
db-1          | 
db-1          | 
db-1          | /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
db-1          | 
db-1          | waiting for server to shut down...2025-11-13 18:47:45.251 UTC [51] LOG:  received fast shutdown request
db-1          | .2025-11-13 18:47:45.258 UTC [51] LOG:  aborting any active transactions
db-1          | 2025-11-13 18:47:45.262 UTC [51] LOG:  background worker "logical replication launcher" (PID 60) exited with exit code 1
db-1          | 2025-11-13 18:47:45.262 UTC [55] LOG:  shutting down
db-1          | 2025-11-13 18:47:45.269 UTC [55] LOG:  checkpoint starting: shutdown immediate
db-1          | 2025-11-13 18:47:45.410 UTC [55] LOG:  checkpoint complete: wrote 943 buffers (5.8%), wrote 3 SLRU buffers; 0 WAL file(s) added, 0 removed, 0 recycled; write=0.032 s, sync=0.087 s, total=0.149 s; sync files=303, longest=0.015 s, average=0.001 s; distance=4352 kB, estimate=4352 kB; lsn=0/1B9FBB0, redo lsn=0/1B9FBB0
db-1          | 2025-11-13 18:47:45.433 UTC [51] LOG:  database system is shut down
db-1          |  done
db-1          | server stopped
db-1          | 
db-1          | PostgreSQL init process complete; ready for start up.
db-1          | 
springcoreapi-1  | [INFO] Scanning for projects...
kafka-ui-1       |  _   _ ___    __             _                _          _  __      __ _
kafka-ui-1       | | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
kafka-ui-1       | | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
kafka-ui-1       |  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
kafka-ui-1       |                                  |_|                                             
kafka-ui-1       | 
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] ------------< com.joey.stanley.group.project:feedback-api >-------------
springcoreapi-1  | [INFO] Building feedback-api 0.0.1-SNAPSHOT
springcoreapi-1  | [INFO]   from pom.xml
springcoreapi-1  | [INFO] --------------------------------[ jar ]---------------------------------
kafka-ui-1       | [30m2025-11-13 18:47:47,714[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.u.DynamicConfigOperations[0;39m: Dynamic config file /etc/kafkaui/dynamic_config.yaml doesnt exist or not readable
kafka-ui-1       | [30m2025-11-13 18:47:47,732[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
kafka-ui-1       | [30m2025-11-13 18:47:47,732[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.1.3, Spring v6.0.11
kafka-ui-1       | [30m2025-11-13 18:47:47,734[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] --- clean:3.4.1:clean (default-clean) @ feedback-api ---
springcoreapi-1  | [INFO] Deleting /app/target
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] --- resources:3.3.1:resources (default-resources) @ feedback-api ---
springcoreapi-1  | [INFO] Copying 1 resource from src/main/resources to target/classes
springcoreapi-1  | [INFO] Copying 0 resource from src/main/resources to target/classes
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] --- compiler:3.14.1:compile (default-compile) @ feedback-api ---
springcoreapi-1  | [INFO] Recompiling the module because of changed source code.
springcoreapi-1  | [INFO] Compiling 11 source files with javac [debug parameters release 21] to target/classes
kafka-1          | ===> Launching ... 
controller-1     | ===> Launching ... 
kafka-1          | ===> Launching kafka ... 
controller-1     | ===> Launching kafka ... 
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] --- resources:3.3.1:testResources (default-testResources) @ feedback-api ---
springcoreapi-1  | [INFO] skip non existing resourceDirectory /app/src/test/resources
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] --- compiler:3.14.1:testCompile (default-testCompile) @ feedback-api ---
springcoreapi-1  | [INFO] Recompiling the module because of changed dependency.
springcoreapi-1  | [INFO] Compiling 2 source files with javac [debug parameters release 21] to target/test-classes
controller-1     | [2025-11-13 18:47:55,958] INFO Registered `kafka:type=kafka.Log4jController` MBean (kafka.utils.Log4jControllerRegistration$)
controller-1     | [2025-11-13 18:47:55,958] INFO Registered `kafka:type=kafka.Log4jController` MBean (kafka.utils.Log4jControllerRegistration$)
kafka-1          | [2025-11-13 18:47:55,995] INFO Registered `kafka:type=kafka.Log4jController` MBean (kafka.utils.Log4jControllerRegistration$)
kafka-1          | [2025-11-13 18:47:55,995] INFO Registered `kafka:type=kafka.Log4jController` MBean (kafka.utils.Log4jControllerRegistration$)
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] --- surefire:3.5.4:test (default-test) @ feedback-api ---
kafka-ui-1       | [30m2025-11-13 18:47:57,140[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster LocalKafka
springcoreapi-1  | [INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] -------------------------------------------------------
springcoreapi-1  | [INFO]  T E S T S
springcoreapi-1  | [INFO] -------------------------------------------------------
controller-1     | [2025-11-13 18:47:57,842] INFO KafkaConfig values: 
controller-1     | 	add.partitions.to.txn.retry.backoff.max.ms = 100
controller-1     | 	add.partitions.to.txn.retry.backoff.ms = 20
controller-1     | 	advertised.listeners = null
controller-1     | 	alter.config.policy.class.name = null
controller-1     | 	alter.log.dirs.replication.quota.window.num = 11
controller-1     | 	alter.log.dirs.replication.quota.window.size.seconds = 1
controller-1     | 	authorizer.class.name = 
controller-1     | 	auto.create.topics.enable = true
controller-1     | 	auto.leader.rebalance.enable = true
controller-1     | 	background.threads = 10
controller-1     | 	broker.heartbeat.interval.ms = 2000
controller-1     | 	broker.id = 1
controller-1     | 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
controller-1     | 	broker.rack = rack-0
controller-1     | 	broker.session.timeout.ms = 9000
controller-1     | 	broker.session.uuid = hLJXuen0TMSXMJfs9PSzFA
controller-1     | 	client.quota.callback.class = null
controller-1     | 	client.quota.max.throttle.time.in.response.ms = 60000
controller-1     | 	client.quota.max.throttle.time.ms = 5000
controller-1     | 	compression.gzip.level = -1
controller-1     | 	compression.lz4.level = 9
controller-1     | 	compression.type = producer
controller-1     | 	compression.zstd.level = 3
controller-1     | 	confluent.accp.enabled = false
controller-1     | 	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
controller-1     | 	confluent.alter.broker.health.max.demoted.brokers = 2147483647
controller-1     | 	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
controller-1     | 	confluent.ansible.managed = false
controller-1     | 	confluent.api.visibility = DEFAULT
controller-1     | 	confluent.append.record.interceptor.classes = []
controller-1     | 	confluent.apply.create.topic.policy.to.create.partitions = false
controller-1     | 	confluent.authorizer.authority.name = 
controller-1     | 	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
controller-1     | 	confluent.backpressure.disk.enable = false
controller-1     | 	confluent.backpressure.disk.free.threshold.bytes = 21474836480
controller-1     | 	confluent.backpressure.disk.produce.bytes.per.second = 131072
controller-1     | 	confluent.backpressure.disk.threshold.recovery.factor = 1.5
controller-1     | 	confluent.backpressure.request.min.broker.limit = 200
controller-1     | 	confluent.backpressure.request.queue.size.percentile = p95
controller-1     | 	confluent.backpressure.types = null
controller-1     | 	confluent.balancer.api.state.topic = _confluent_balancer_api_state
controller-1     | 	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
controller-1     | 	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
controller-1     | 	confluent.balancer.capacity.threshold.upper.limit = 0.95
controller-1     | 	confluent.balancer.cell.load.upper.bound = 0.7
controller-1     | 	confluent.balancer.cell.overload.detection.interval.ms = 3600000
controller-1     | 	confluent.balancer.cell.overload.duration.ms = 86400000
controller-1     | 	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
controller-1     | 	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.cpu.balance.threshold = 1.1
controller-1     | 	confluent.balancer.cpu.goal.act.as.capacity.goal = false
controller-1     | 	confluent.balancer.cpu.low.utilization.threshold = 0.2
controller-1     | 	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
controller-1     | 	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
controller-1     | 	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
controller-1     | 	confluent.balancer.disk.max.load = 0.85
controller-1     | 	confluent.balancer.disk.min.free.space.gb = 0
controller-1     | 	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
controller-1     | 	confluent.balancer.disk.utilization.detector.duration.ms = 600000
controller-1     | 	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
controller-1     | 	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
controller-1     | 	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
controller-1     | 	confluent.balancer.enable = true
controller-1     | 	confluent.balancer.enable.network.capacity.metric.ingestion = false
controller-1     | 	confluent.balancer.exclude.topic.names = []
controller-1     | 	confluent.balancer.exclude.topic.prefixes = []
controller-1     | 	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
controller-1     | 	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
controller-1     | 	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
controller-1     | 	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
controller-1     | 	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
controller-1     | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
controller-1     | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
controller-1     | 	confluent.balancer.incremental.balancing.enabled = false
controller-1     | 	confluent.balancer.incremental.balancing.goals = []
controller-1     | 	confluent.balancer.incremental.balancing.lower.bound = 0.02
controller-1     | 	confluent.balancer.incremental.balancing.min.valid.windows = 5
controller-1     | 	confluent.balancer.incremental.balancing.step.ratio = 0.2
controller-1     | 	confluent.balancer.inter.cell.balancing.enabled = false
controller-1     | 	confluent.balancer.inter.cell.movements.excluded.tenant.ids = []
controller-1     | 	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
controller-1     | 	confluent.balancer.max.replicas = 2147483647
controller-1     | 	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
controller-1     | 	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
controller-1     | 	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
controller-1     | 	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
controller-1     | 	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.rebalancing.goals = []
controller-1     | 	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.resource.utilization.detector.interval.ms = 60000
controller-1     | 	confluent.balancer.sbc.metrics.parser.enabled = false
controller-1     | 	confluent.balancer.self.healing.maximum.rounds = 1
controller-1     | 	confluent.balancer.task.history.retention.days = 30
controller-1     | 	confluent.balancer.tenant.maximum.movements = 0
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.consume_out = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.cpu = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.nw_in = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.nw_out = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.produce_in = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.replica_count = 3
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.consume_out = 614400.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.cpu = 300.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_in = 204800.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_out = 614400.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.produce_in = 204800.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.replica_count = 45000.0
controller-1     | 	confluent.balancer.tenant.striping.enable.dry.run.mode = true
controller-1     | 	confluent.balancer.tenant.striping.enabled = false
controller-1     | 	confluent.balancer.tenant.striping.expiry.counter.threshold = 10
controller-1     | 	confluent.balancer.tenant.striping.rate.limit = 3
controller-1     | 	confluent.balancer.tenant.striping.resource.usage.expiry.ms = 3600000
controller-1     | 	confluent.balancer.tenant.suspension.ms = 86400000
controller-1     | 	confluent.balancer.throttle.bytes.per.second = 10485760
controller-1     | 	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
controller-1     | 	confluent.balancer.topic.partition.maximum.movements = 3
controller-1     | 	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
controller-1     | 	confluent.balancer.topic.partition.movements.history.limit = 900
controller-1     | 	confluent.balancer.topic.partition.suspension.ms = 3600000
controller-1     | 	confluent.balancer.topic.replication.factor = 1
controller-1     | 	confluent.balancer.triggering.goals = []
controller-1     | 	confluent.balancer.v2.addition.enabled = false
controller-1     | 	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
controller-1     | 	confluent.balancer.v2.executor.enabled = false
controller-1     | 	confluent.basic.auth.credentials.source = null
controller-1     | 	confluent.basic.auth.user.info = null
controller-1     | 	confluent.bearer.assertion.claim.aud = null
controller-1     | 	confluent.bearer.assertion.claim.exp.minutes = null
controller-1     | 	confluent.bearer.assertion.claim.iss = null
controller-1     | 	confluent.bearer.assertion.claim.jti.include = null
controller-1     | 	confluent.bearer.assertion.claim.nbf.include = null
controller-1     | 	confluent.bearer.assertion.claim.sub = null
controller-1     | 	confluent.bearer.assertion.file = null
controller-1     | 	confluent.bearer.assertion.private.key.file = null
controller-1     | 	confluent.bearer.assertion.private.key.passphrase = null
controller-1     | 	confluent.bearer.assertion.template.file = null
controller-1     | 	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
controller-1     | 	confluent.bearer.auth.client.id = null
controller-1     | 	confluent.bearer.auth.client.secret = null
controller-1     | 	confluent.bearer.auth.credentials.source = null
controller-1     | 	confluent.bearer.auth.identity.pool.id = null
controller-1     | 	confluent.bearer.auth.issuer.endpoint.url = null
controller-1     | 	confluent.bearer.auth.logical.cluster = null
controller-1     | 	confluent.bearer.auth.scope = null
controller-1     | 	confluent.bearer.auth.scope.claim.name = scope
controller-1     | 	confluent.bearer.auth.sub.claim.name = sub
controller-1     | 	confluent.bearer.auth.token = null
controller-1     | 	confluent.broker.health.manager.enabled = true
controller-1     | 	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
controller-1     | 	confluent.broker.health.manager.hard.kill.duration.ms = 60000
controller-1     | 	confluent.broker.health.manager.mitigation.enabled = false
controller-1     | 	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
controller-1     | 	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
controller-1     | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
controller-1     | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
controller-1     | 	confluent.broker.health.manager.sample.duration.ms = 1000
controller-1     | 	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
controller-1     | 	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
controller-1     | 	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
controller-1     | 	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.broker.load.advertised.limit.load = 0.8
controller-1     | 	confluent.broker.load.average.service.request.time.ms = 0.1
controller-1     | 	confluent.broker.load.delay.metric.start.ms = 180000
controller-1     | 	confluent.broker.load.enabled = false
controller-1     | 	confluent.broker.load.num.samples = 60
controller-1     | 	confluent.broker.load.tenant.metric.enable = false
controller-1     | 	confluent.broker.load.update.metric.tags.interval.ms = 60000
controller-1     | 	confluent.broker.load.window.size.ms = 60000
controller-1     | 	confluent.broker.load.workload.coefficient = 20.0
controller-1     | 	confluent.broker.registration.delay.ms = 0
controller-1     | 	confluent.broker.type = confluent_platform
controller-1     | 	confluent.broker.type.topic.enabled = true
controller-1     | 	confluent.calling.resource.identity.type.map = 
controller-1     | 	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
controller-1     | 	confluent.catalog.collector.enable = false
controller-1     | 	confluent.catalog.collector.full.configs.enable = false
controller-1     | 	confluent.catalog.collector.max.bytes.per.snapshot = 850000
controller-1     | 	confluent.catalog.collector.max.topics.process = 500
controller-1     | 	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
controller-1     | 	confluent.catalog.collector.multitenant.topics.enable = true
controller-1     | 	confluent.catalog.collector.snapshot.init.delay.sec = 60
controller-1     | 	confluent.catalog.collector.snapshot.interval.sec = 300
controller-1     | 	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
controller-1     | 	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
controller-1     | 	confluent.cdc.api.keys.topic = 
controller-1     | 	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
controller-1     | 	confluent.cdc.client.quotas.enable = false
controller-1     | 	confluent.cdc.client.quotas.topic.name = 
controller-1     | 	confluent.cdc.lkc.metadata.topic = 
controller-1     | 	confluent.cdc.user.metadata.enable = false
controller-1     | 	confluent.cdc.user.metadata.topic = _confluent-user_metadata
controller-1     | 	confluent.cell.metrics.refresh.period.ms = 60000
controller-1     | 	confluent.cells.default.size = 15
controller-1     | 	confluent.cells.enable = false
controller-1     | 	confluent.cells.implicit.creation.enable = false
controller-1     | 	confluent.cells.k2.base.broker.index = -1
controller-1     | 	confluent.cells.load.refresher.enable = true
controller-1     | 	confluent.cells.max.size = 15
controller-1     | 	confluent.cells.min.size = 6
controller-1     | 	confluent.checksum.enabled.files = [none]
controller-1     | 	confluent.client.topic.max.metrics.count = 1000
controller-1     | 	confluent.client.topic.metrics.expiry.sec = 3600
controller-1     | 	confluent.client.topic.metrics.ignore_client_id_pattern = (?:link-.*-)?broker-\d+-fetcher-\d+(?:-pool-.*)?
controller-1     | 	confluent.client.topic.metrics.ignore_internal_topic_pattern = _.*
controller-1     | 	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
controller-1     | 	confluent.clm.enabled = false
controller-1     | 	confluent.clm.frequency.in.hours = 6
controller-1     | 	confluent.clm.list.object.thread_pool.size = 1
controller-1     | 	confluent.clm.max.backup.days = 3
controller-1     | 	confluent.clm.min.delay.in.minutes = 30
controller-1     | 	confluent.clm.thread.pool.size = 2
controller-1     | 	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
controller-1     | 	confluent.close.connections.on.credential.delete = false
controller-1     | 	confluent.cluster.link.admin.max.in.flight.requests = 1000
controller-1     | 	confluent.cluster.link.admin.request.batch.size = 1
controller-1     | 	confluent.cluster.link.allow.config.providers = true
controller-1     | 	confluent.cluster.link.allow.legacy.message.format = false
controller-1     | 	confluent.cluster.link.allow.truncation.below.hwm = false
controller-1     | 	confluent.cluster.link.availability.check.mode = ALL
controller-1     | 	confluent.cluster.link.background.thread.affinity = LINK
controller-1     | 	confluent.cluster.link.bootstrap.translation.feature.enable = true
controller-1     | 	confluent.cluster.link.clients.max.idle.ms = 3153600000000
controller-1     | 	confluent.cluster.link.enable = true
controller-1     | 	confluent.cluster.link.enable.local.admin = false
controller-1     | 	confluent.cluster.link.enable.metrics.reduction = false
controller-1     | 	confluent.cluster.link.enable.metrics.reduction.advanced = false
controller-1     | 	confluent.cluster.link.fetch.response.min.bytes = 1
controller-1     | 	confluent.cluster.link.fetch.response.total.bytes = 2147483647
controller-1     | 	confluent.cluster.link.fetcher.auto.tune.enable = false
controller-1     | 	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
controller-1     | 	confluent.cluster.link.insync.fetch.response.min.bytes = 1
controller-1     | 	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
controller-1     | 	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
controller-1     | 	confluent.cluster.link.intranet.connectivity.enable = false
controller-1     | 	confluent.cluster.link.intranet.connectivity.migration.enable = false
controller-1     | 	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.cluster.link.k1.to.k2.migration.enable = false
controller-1     | 	confluent.cluster.link.k2.mirror.topic.metadata.enable = false
controller-1     | 	confluent.cluster.link.local.admin.multitenant.enable = false
controller-1     | 	confluent.cluster.link.local.reverse.connection.listener.map = null
controller-1     | 	confluent.cluster.link.max.client.connections = 2147483647
controller-1     | 	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
controller-1     | 	confluent.cluster.link.metadata.topic.enable = false
controller-1     | 	confluent.cluster.link.metadata.topic.min.isr = 2
controller-1     | 	confluent.cluster.link.metadata.topic.partitions = 50
controller-1     | 	confluent.cluster.link.metadata.topic.replication.factor = 3
controller-1     | 	confluent.cluster.link.mirror.transition.batch.size = 10
controller-1     | 	confluent.cluster.link.num.background.threads = 1
controller-1     | 	confluent.cluster.link.num.fetchers = 1
controller-1     | 	confluent.cluster.link.periodic.task.batch.size = 2147483647
controller-1     | 	confluent.cluster.link.periodic.task.min.interval.ms = 1000
controller-1     | 	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
controller-1     | 	confluent.cluster.link.replica.fetch.connections.mode = combined
controller-1     | 	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
controller-1     | 	confluent.cluster.link.replication.quota.mode.per.tenant.overrides = 
controller-1     | 	confluent.cluster.link.replication.quota.window.num = 11
controller-1     | 	confluent.cluster.link.replication.quota.window.size.seconds = 2
controller-1     | 	confluent.cluster.link.request.quota.capacity = 400
controller-1     | 	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
controller-1     | 	confluent.cluster.link.switchover.disabled.principals = []
controller-1     | 	confluent.cluster.link.switchover.enable = false
controller-1     | 	confluent.cluster.link.switchover.listeners = []
controller-1     | 	confluent.cluster.link.switchover.server.states = []
controller-1     | 	confluent.cluster.link.tenant.replication.quota.enable = false
controller-1     | 	confluent.cluster.link.tenant.request.quota.enable = false
controller-1     | 	confluent.cluster.metadata.snapshot.tier.delete.enable = false
controller-1     | 	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
controller-1     | 	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
controller-1     | 	confluent.cluster.metadata.snapshot.tier.upload.enable = false
controller-1     | 	confluent.compacted.topic.prefer.tier.fetch.ms = -1
controller-1     | 	confluent.connection.invalid.request.delay.enable = false
controller-1     | 	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
controller-1     | 	confluent.consumer.fetch.partition.pruning.enable = true
controller-1     | 	confluent.consumer.lag.emitter.enabled = false
controller-1     | 	confluent.consumer.lag.emitter.interval.ms = 60000
controller-1     | 	confluent.dataflow.policy.watch.monitor.ms = 300000
controller-1     | 	confluent.default.data.policy.enforcement = true
controller-1     | 	confluent.defer.isr.shrink.enable = false
controller-1     | 	confluent.describe.topic.partitions.enabled = true
controller-1     | 	confluent.disk.io.manager.enable = false
controller-1     | 	confluent.disk.throughput.headroom = 10485760
controller-1     | 	confluent.disk.throughput.limit = 10485760000
controller-1     | 	confluent.disk.throughput.quota.tier.archive = 1048576000
controller-1     | 	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
controller-1     | 	confluent.durability.audit.batch.flush.frequency.ms = 900000
controller-1     | 	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
controller-1     | 	confluent.durability.audit.enable = false
controller-1     | 	confluent.durability.audit.idempotent.producer = false
controller-1     | 	confluent.durability.audit.initial.job.delay.ms = 900000
controller-1     | 	confluent.durability.audit.io.bytes.per.sec = 10485760
controller-1     | 	confluent.durability.audit.log.ignored.event.types = 
controller-1     | 	confluent.durability.audit.reporting.batch.ms = 1800000
controller-1     | 	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
controller-1     | 	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
controller-1     | 	confluent.durability.topic.partition.count = 50
controller-1     | 	confluent.durability.topic.replication.factor = 3
controller-1     | 	confluent.e2e_checksum.protection.enabled = false
controller-1     | 	confluent.e2e_checksum.protection.files = [none]
controller-1     | 	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
controller-1     | 	confluent.elastic.cku.enabled = false
controller-1     | 	confluent.elastic.cku.scaletozero.enabled = false
controller-1     | 	confluent.eligible.controllers = []
controller-1     | 	confluent.emit.network.type.default = 
controller-1     | 	confluent.emit.network.type.tag = false
controller-1     | 	confluent.enable.broker.reporting.min.usage.mode = true
controller-1     | 	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
controller-1     | 	confluent.fail.unsatisfied.placement.constraints = false
controller-1     | 	confluent.fetch.from.follower.require.leader.epoch.enable = false
controller-1     | 	confluent.fetch.partition.pruning.enable = true
controller-1     | 	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
controller-1     | 	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
controller-1     | 	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
controller-1     | 	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
controller-1     | 	confluent.flexible.fanout.enabled = false
controller-1     | 	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
controller-1     | 	confluent.flexible.fanout.mode = TENANT_QUOTA
controller-1     | 	confluent.floor.connection.rate.per.ip = -1.0
controller-1     | 	confluent.floor.connection.rate.per.tenant = -1.0
controller-1     | 	confluent.group.coordinator.dynamic.append.linger.enable = false
controller-1     | 	confluent.group.coordinator.max.partition.queue.size = -1
controller-1     | 	confluent.group.coordinator.offsets.batching.enable = false
controller-1     | 	confluent.group.coordinator.offsets.writer.threads = 2
controller-1     | 	confluent.group.coordinator.slow.event.log.count = 10
controller-1     | 	confluent.group.coordinator.slow.event.log.interval.ms = -1
controller-1     | 	confluent.group.coordinator.txn.offset.validation.enable = false
controller-1     | 	confluent.group.highest.offset.commit.rates.log.count = 10
controller-1     | 	confluent.group.highest.offset.commit.rates.log.enable = false
controller-1     | 	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
controller-1     | 	confluent.group.metadata.load.threads = 32
controller-1     | 	confluent.group.subscription.pattern.log.interval.ms = -1
controller-1     | 	confluent.heap.tenured.notify.bytes = 0
controller-1     | 	confluent.heap.tenured.notify.enabled = false
controller-1     | 	confluent.hot.partition.ratio = 0.8
controller-1     | 	confluent.http.server.start.timeout.ms = 60000
controller-1     | 	confluent.http.server.stop.timeout.ms = 30000
controller-1     | 	confluent.intelligent.replication.enable = false
controller-1     | 	confluent.intelligent.replication.push.max.memory.buffer.bytes = 209715200
controller-1     | 	confluent.intelligent.replication.push.max.threads = 4
controller-1     | 	confluent.intelligent.replication.push.threads.per.remote.broker = 1
controller-1     | 	confluent.internal.metrics.enable = false
controller-1     | 	confluent.internal.rest.server.bind.port = null
controller-1     | 	confluent.internal.rest.server.ssl.enable = false
controller-1     | 	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
controller-1     | 	confluent.lat.network.context.verification.enable = false
controller-1     | 	confluent.leader.epoch.checkpoint.checksum.enabled = false
controller-1     | 	confluent.listener.protocol = TCP
controller-1     | 	confluent.log.cleaner.timestamp.validation.enable = true
controller-1     | 	confluent.log.placement.constraints = 
controller-1     | 	confluent.max.broker.load = 1.0
controller-1     | 	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
controller-1     | 	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
controller-1     | 	confluent.max.connection.rate.per.ip = -1.0
controller-1     | 	confluent.max.connection.rate.per.tenant = -1.0
controller-1     | 	confluent.max.connection.throttle.ms = null
controller-1     | 	confluent.max.segment.ms = 9223372036854775807
controller-1     | 	confluent.metadata.active.encryptor = null
controller-1     | 	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
controller-1     | 	confluent.metadata.encryptor.classes = null
controller-1     | 	confluent.metadata.encryptor.required = false
controller-1     | 	confluent.metadata.encryptor.secret.file = null
controller-1     | 	confluent.metadata.encryptor.secrets = null
controller-1     | 	confluent.metadata.jvm.warmup.ms = 60000
controller-1     | 	confluent.metadata.leader.balance.slice.delay.ms = 100
controller-1     | 	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
controller-1     | 	confluent.metadata.max.leader.balance.changes.per.slice = 1000
controller-1     | 	confluent.metadata.rbac_auth.read.controller.enable = false
controller-1     | 	confluent.metadata.rbac_auth.update.controller.enable = false
controller-1     | 	confluent.metadata.reject.when.throttled.enable = false
controller-1     | 	confluent.metadata.server.cluster.registry.clusters = []
controller-1     | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
controller-1     | 	confluent.min.acks = 0
controller-1     | 	confluent.min.connection.throttle.ms = 0
controller-1     | 	confluent.min.segment.ms = 1
controller-1     | 	confluent.missing.id.cache.ttl.sec = 60
controller-1     | 	confluent.missing.id.query.range = 20000
controller-1     | 	confluent.missing.schema.cache.ttl.sec = 60
controller-1     | 	confluent.mtls.build.client.cert.chain.enable = false
controller-1     | 	confluent.mtls.enable = false
controller-1     | 	confluent.mtls.listener.name = EXTERNAL
controller-1     | 	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
controller-1     | 	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
controller-1     | 	confluent.mtls.truststore.manager.class.name = null
controller-1     | 	confluent.multitenant.authorizer.enable.acl.state = false
controller-1     | 	confluent.multitenant.interceptor.balancer.apis.enabled = false
controller-1     | 	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
controller-1     | 	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
controller-1     | 	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
controller-1     | 	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
controller-1     | 	confluent.multitenant.listener.names = null
controller-1     | 	confluent.multitenant.parse.lkc.id.enable = false
controller-1     | 	confluent.multitenant.parse.sni.host.name.enable = false
controller-1     | 	confluent.network.health.manager.enabled = false
controller-1     | 	confluent.network.health.manager.external.listener.name = EXTERNAL
controller-1     | 	confluent.network.health.manager.externalconnectivitystartup.enabled = false
controller-1     | 	confluent.network.health.manager.min.healthy.network.samples = 3
controller-1     | 	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
controller-1     | 	confluent.network.health.manager.mitigation.enabled = false
controller-1     | 	confluent.network.health.manager.network.sample.window.size = 120
controller-1     | 	confluent.network.health.manager.sample.duration.ms = 1000
controller-1     | 	confluent.oauth.flat.networking.verification.enable = false
controller-1     | 	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
controller-1     | 	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
controller-1     | 	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
controller-1     | 	confluent.offsets.topic.max.message.bytes = -1
controller-1     | 	confluent.offsets.topic.placement.constraints = 
controller-1     | 	confluent.omit.network.processor.metric.tag = false
controller-1     | 	confluent.operator.managed = false
controller-1     | 	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
controller-1     | 	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
controller-1     | 	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
controller-1     | 	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
controller-1     | 	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
controller-1     | 	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
controller-1     | 	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
controller-1     | 	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings = 
controller-1     | 	confluent.ppv2.endpoint.scheme.enable = false
controller-1     | 	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
controller-1     | 	confluent.ppv2.endpoint.scheme.template.variable.cloud = 
controller-1     | 	confluent.ppv2.endpoint.scheme.template.variable.domain = 
controller-1     | 	confluent.ppv2.endpoint.scheme.template.variable.region = 
controller-1     | 	confluent.ppv2.endpoint.scheme.template.variables = 
controller-1     | 	confluent.ppv2.endpoint.scheme.templates = 
controller-1     | 	confluent.prefer.tier.fetch.ms = -1
controller-1     | 	confluent.produce.throttle.pre.check.enable = false
controller-1     | 	confluent.produce.throttle.pre.check.for.new.connection.enable = false
controller-1     | 	confluent.producer.id.cache.broker.hard.limit = -1
controller-1     | 	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
controller-1     | 	confluent.producer.id.cache.extra.eviction.percentage = 0
controller-1     | 	confluent.producer.id.cache.limit = 2147483647
controller-1     | 	confluent.producer.id.cache.partition.hard.limit = -1
controller-1     | 	confluent.producer.id.cache.tenant.hard.limit = -1
controller-1     | 	confluent.producer.id.quota.manager.enable = false
controller-1     | 	confluent.producer.id.quota.window.num = 11
controller-1     | 	confluent.producer.id.quota.window.size.seconds = 1
controller-1     | 	confluent.producer.id.throttle.enable = false
controller-1     | 	confluent.producer.id.throttle.enable.threshold.percentage = 100
controller-1     | 	confluent.protocol.netty.http2.connection.window.size = 31457280
controller-1     | 	confluent.protocol.netty.http2.flow.control.enabled = true
controller-1     | 	confluent.protocol.netty.http2.initial.window.size = 153600
controller-1     | 	confluent.protocol.netty.http2.max.frame.size = 16384
controller-1     | 	confluent.protocol.netty.http2.stream.graceful.close.timeout.ms = 60000
controller-1     | 	confluent.protocol.netty.num.boss.threads = 1
controller-1     | 	confluent.protocol.netty.num.worker.threads = 4
controller-1     | 	confluent.proxy.mode.local.default = false
controller-1     | 	confluent.proxy.protocol.fallback.enabled = false
controller-1     | 	confluent.proxy.protocol.parser = class io.confluent.kafka.common.network.CloudProxyTlvParser
controller-1     | 	confluent.proxy.protocol.version = NONE
controller-1     | 	confluent.quota.computing.usage.adjustment = 0.5
controller-1     | 	confluent.quota.dynamic.adjustment.min.usage = 102400
controller-1     | 	confluent.quota.dynamic.enable = false
controller-1     | 	confluent.quota.dynamic.publishing.interval.ms = 60000
controller-1     | 	confluent.quota.dynamic.reporting.interval.ms = 30000
controller-1     | 	confluent.quota.tenant.broker.max.consumer.rate = 13107200
controller-1     | 	confluent.quota.tenant.broker.max.producer.rate = 13107200
controller-1     | 	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
controller-1     | 	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
controller-1     | 	confluent.quota.tenant.fetch.multiplier = 1.0
controller-1     | 	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
controller-1     | 	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
controller-1     | 	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
controller-1     | 	confluent.quota.tenant.internal.broker.max.controller.mutation.rate = 9223372036854775807
controller-1     | 	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
controller-1     | 	confluent.quota.tenant.internal.throttling.enable = false
controller-1     | 	confluent.quota.tenant.produce.multiplier = 1.0
controller-1     | 	confluent.quota.tenant.user.quotas.enable = false
controller-1     | 	confluent.rack.id.mapping = null
controller-1     | 	confluent.regional.metadata.client.class = null
controller-1     | 	confluent.regional.resource.manager.client.scheduler.threads = 2
controller-1     | 	confluent.regional.resource.manager.endpoint = null
controller-1     | 	confluent.regional.resource.manager.grpc.endpoint = null
controller-1     | 	confluent.reject.invalid.sni.hostnames = false
controller-1     | 	confluent.replica.fetch.backoff.max.ms = 1000
controller-1     | 	confluent.replica.fetch.connections.mode = combined
controller-1     | 	confluent.replication.mode = PULL
controller-1     | 	confluent.replication.push.feature.enable = false
controller-1     | 	confluent.reporters.telemetry.auto.enable = true
controller-1     | 	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
controller-1     | 	confluent.request.pipelining.enable = true
controller-1     | 	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
controller-1     | 	confluent.require.calling.resource.identity = false
controller-1     | 	confluent.require.compatible.keystore.updates = true
controller-1     | 	confluent.require.confluent.issuer = false
controller-1     | 	confluent.roll.check.interval.ms = 300000
controller-1     | 	confluent.schema.registry.max.cache.size = 10000
controller-1     | 	confluent.schema.registry.max.retries = 1
controller-1     | 	confluent.schema.registry.retries.wait.ms = 0
controller-1     | 	confluent.schema.registry.url = null
controller-1     | 	confluent.schema.validation.context.name.enable = false
controller-1     | 	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
controller-1     | 	confluent.schema.validator.multitenant.enable = false
controller-1     | 	confluent.schema.validator.samples.per.min = 0
controller-1     | 	confluent.security.bc.approved.mode.enable = false
controller-1     | 	confluent.security.event.logger.authentication.enable = false
controller-1     | 	confluent.security.event.logger.authentication.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.authorization.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
controller-1     | 	confluent.security.event.logger.enable = true
controller-1     | 	confluent.security.event.logger.kafka.request.rate.limit = -1
controller-1     | 	confluent.security.event.logger.physical.cluster.id = 
controller-1     | 	confluent.security.event.router.config = 
controller-1     | 	confluent.security.revoked.certificate.ids = 
controller-1     | 	confluent.segment.eager.roll.enable = false
controller-1     | 	confluent.segment.speculative.prefetch.enable = false
controller-1     | 	confluent.share.coordinator.slow.event.log.count = 10
controller-1     | 	confluent.share.coordinator.slow.event.log.interval.ms = -1
controller-1     | 	confluent.share.metadata.load.threads = 32
controller-1     | 	confluent.spiffe.id.principal.extraction.rules = 
controller-1     | 	confluent.ssl.key.password = null
controller-1     | 	confluent.ssl.keystore.location = null
controller-1     | 	confluent.ssl.keystore.password = null
controller-1     | 	confluent.ssl.keystore.type = null
controller-1     | 	confluent.ssl.protocol = null
controller-1     | 	confluent.ssl.truststore.location = null
controller-1     | 	confluent.ssl.truststore.password = null
controller-1     | 	confluent.ssl.truststore.type = null
controller-1     | 	confluent.step.connection.rate.per.ip = -1.0
controller-1     | 	confluent.step.connection.rate.per.tenant = -1.0
controller-1     | 	confluent.storage.probe.disk.metrics.collection.enabled = false
controller-1     | 	confluent.storage.probe.period.ms = -1
controller-1     | 	confluent.storage.probe.slow.write.threshold.ms = 5000
controller-1     | 	confluent.stray.log.delete.delay.ms = 604800000
controller-1     | 	confluent.stray.log.max.deletions.per.run = 72
controller-1     | 	confluent.subdomain.prefix = null
controller-1     | 	confluent.subdomain.separator.map = null
controller-1     | 	confluent.subdomain.separator.variable = %sep
controller-1     | 	confluent.system.time.roll.enable = false
controller-1     | 	confluent.telemetry.enabled = false
controller-1     | 	confluent.telemetry.external.client.metrics.delta.temporality = true
controller-1     | 	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
controller-1     | 	confluent.telemetry.external.client.metrics.push.enabled = false
controller-1     | 	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
controller-1     | 	confluent.telemetry.external.client.metrics.subscription.match.list = null
controller-1     | 	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
controller-1     | 	confluent.telemetry.external.client.metrics.supported.compression.types = [zstd, lz4, gzip, snappy]
controller-1     | 	confluent.tenant.latency.metric.enabled = false
controller-1     | 	confluent.tenantaware.encryption.key.manager.enable = false
controller-1     | 	confluent.tenantaware.encryption.key.manager.proactive.key.generation.enable = false
controller-1     | 	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
controller-1     | 	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
controller-1     | 	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
controller-1     | 	confluent.tier.archiver.num.threads = 2
controller-1     | 	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
controller-1     | 	confluent.tier.azure.block.blob.container = null
controller-1     | 	confluent.tier.azure.block.blob.cred.file.path = null
controller-1     | 	confluent.tier.azure.block.blob.endpoint = null
controller-1     | 	confluent.tier.azure.block.blob.prefix = 
controller-1     | 	confluent.tier.backend = 
controller-1     | 	confluent.tier.bucket.probe.period.ms = -1
controller-1     | 	confluent.tier.cleaner.compact.min.efficiency = 0.5
controller-1     | 	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
controller-1     | 	confluent.tier.cleaner.dedupe.buffer.size = 134217728
controller-1     | 	confluent.tier.cleaner.dual.compaction = false
controller-1     | 	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
controller-1     | 	confluent.tier.cleaner.dual.compaction.validation.percent = 0
controller-1     | 	confluent.tier.cleaner.enable = false
controller-1     | 	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
controller-1     | 	confluent.tier.cleaner.feature.enable = false
controller-1     | 	confluent.tier.cleaner.io.buffer.load.factor = 0.9
controller-1     | 	confluent.tier.cleaner.io.buffer.size = 10485760
controller-1     | 	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
controller-1     | 	confluent.tier.cleaner.min.cleanable.ratio = 0.75
controller-1     | 	confluent.tier.cleaner.num.threads = 2
controller-1     | 	confluent.tier.enable = false
controller-1     | 	confluent.tier.feature = false
controller-1     | 	confluent.tier.fenced.segment.delete.delay.ms = 600000
controller-1     | 	confluent.tier.fetcher.async.enable = false
controller-1     | 	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
controller-1     | 	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
controller-1     | 	confluent.tier.fetcher.memorypool.bytes = 0
controller-1     | 	confluent.tier.fetcher.num.threads = 4
controller-1     | 	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
controller-1     | 	confluent.tier.fetcher.offset.cache.period.ms = 60000
controller-1     | 	confluent.tier.fetcher.offset.cache.size = 200000
controller-1     | 	confluent.tier.gcs.bucket = null
controller-1     | 	confluent.tier.gcs.cred.file.path = null
controller-1     | 	confluent.tier.gcs.prefix = 
controller-1     | 	confluent.tier.gcs.region = null
controller-1     | 	confluent.tier.gcs.sse.customer.encryption.key = null
controller-1     | 	confluent.tier.gcs.write.chunk.size = 0
controller-1     | 	confluent.tier.local.hotset.bytes = -1
controller-1     | 	confluent.tier.local.hotset.ms = 86400000
controller-1     | 	confluent.tier.max.partition.fetch.bytes.override = 0
controller-1     | 	confluent.tier.metadata.bootstrap.servers = null
controller-1     | 	confluent.tier.metadata.catchup.max.poll.ms = 0
controller-1     | 	confluent.tier.metadata.max.poll.ms = 100
controller-1     | 	confluent.tier.metadata.namespace = null
controller-1     | 	confluent.tier.metadata.num.partitions = 50
controller-1     | 	confluent.tier.metadata.replication.factor = 3
controller-1     | 	confluent.tier.metadata.request.timeout.ms = 30000
controller-1     | 	confluent.tier.metadata.snapshots.enable = false
controller-1     | 	confluent.tier.metadata.snapshots.interval.ms = 86400000
controller-1     | 	confluent.tier.metadata.snapshots.retention.days = 7
controller-1     | 	confluent.tier.metadata.snapshots.threads = 2
controller-1     | 	confluent.tier.object.fetcher.num.threads = 1
controller-1     | 	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
controller-1     | 	confluent.tier.partition.state.cleanup.enable = false
controller-1     | 	confluent.tier.partition.state.cleanup.interval.ms = 86400000
controller-1     | 	confluent.tier.partition.state.commit.interval.ms = 15000
controller-1     | 	confluent.tier.prefetch.cache.enable = false
controller-1     | 	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
controller-1     | 	confluent.tier.prefetch.cache.range.bytes = 5242880
controller-1     | 	confluent.tier.prefetch.cache.total.size.bytes = 209715200
controller-1     | 	confluent.tier.s3.assumerole.arn = null
controller-1     | 	confluent.tier.s3.auto.abort.threshold.bytes = 500000
controller-1     | 	confluent.tier.s3.aws.endpoint.override = null
controller-1     | 	confluent.tier.s3.aws.signer.override = null
controller-1     | 	confluent.tier.s3.bucket = null
controller-1     | 	confluent.tier.s3.cred.file.path = null
controller-1     | 	confluent.tier.s3.force.path.style.access = false
controller-1     | 	confluent.tier.s3.ipv6.enabled = true
controller-1     | 	confluent.tier.s3.prefix = 
controller-1     | 	confluent.tier.s3.region = null
controller-1     | 	confluent.tier.s3.security.providers = null
controller-1     | 	confluent.tier.s3.sse.algorithm = AES256
controller-1     | 	confluent.tier.s3.sse.customer.encryption.key = null
controller-1     | 	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
controller-1     | 	confluent.tier.s3.ssl.key.password = null
controller-1     | 	confluent.tier.s3.ssl.keystore.location = null
controller-1     | 	confluent.tier.s3.ssl.keystore.password = null
controller-1     | 	confluent.tier.s3.ssl.keystore.type = null
controller-1     | 	confluent.tier.s3.ssl.protocol = TLSv1.3
controller-1     | 	confluent.tier.s3.ssl.provider = null
controller-1     | 	confluent.tier.s3.ssl.truststore.location = null
controller-1     | 	confluent.tier.s3.ssl.truststore.password = null
controller-1     | 	confluent.tier.s3.ssl.truststore.type = null
controller-1     | 	confluent.tier.s3.storage.class.override = 
controller-1     | 	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
controller-1     | 	confluent.tier.s3.v2.enabled = false
controller-1     | 	confluent.tier.segment.hotset.roll.min.bytes = 104857600
controller-1     | 	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
controller-1     | 	confluent.tier.topic.data.loss.validation.fencing.enable = false
controller-1     | 	confluent.tier.topic.delete.backoff.ms = 21600000
controller-1     | 	confluent.tier.topic.delete.check.interval.ms = 300000
controller-1     | 	confluent.tier.topic.delete.max.inprogress.partitions = 100
controller-1     | 	confluent.tier.topic.head.data.loss.validation.enable = true
controller-1     | 	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
controller-1     | 	confluent.tier.topic.materialization.from.snapshot.enable = false
controller-1     | 	confluent.tier.topic.producer.enable.idempotence = true
controller-1     | 	confluent.tier.topic.snapshots.enable = false
controller-1     | 	confluent.tier.topic.snapshots.interval.ms = 300000
controller-1     | 	confluent.tier.topic.snapshots.max.records = 100000
controller-1     | 	confluent.tier.topic.snapshots.retention.hours = 168
controller-1     | 	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
controller-1     | 	confluent.topic.partition.default.placement = 2
controller-1     | 	confluent.topic.policy.use.computed.assignments = false
controller-1     | 	confluent.topic.replica.assignor.builder.class = 
controller-1     | 	confluent.track.api.key.per.ip = false
controller-1     | 	confluent.track.per.ip.max.size = 100000
controller-1     | 	confluent.track.tenant.id.per.ip = false
controller-1     | 	confluent.traffic.cdc.network.id.routes.enable = false
controller-1     | 	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
controller-1     | 	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
controller-1     | 	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
controller-1     | 	confluent.traffic.network.id = 
controller-1     | 	confluent.traffic.network.type = 
controller-1     | 	confluent.transaction.2pc.timeout.ms = -1
controller-1     | 	confluent.transaction.logging.verbosity = 0
controller-1     | 	confluent.transaction.state.log.placement.constraints = 
controller-1     | 	confluent.unique.deprecated.request.metrics.per.tenant = 1000
controller-1     | 	confluent.valid.broker.rack.set = null
controller-1     | 	confluent.valid.sni.hostnames = 
controller-1     | 	confluent.valid.sni.hostnames.exclude.suffix = 
controller-1     | 	confluent.verify.group.subscription.prefix = false
controller-1     | 	confluent.virtual.topic.creation.enabled = false
controller-1     | 	confluent.zone.tagged.request.metrics.enable = false
controller-1     | 	connection.failed.authentication.delay.ms = 100
controller-1     | 	connection.min.expire.interval.ms = 250
controller-1     | 	connections.max.age.ms = 3153600000000
controller-1     | 	connections.max.idle.ms = 600000
controller-1     | 	connections.max.reauth.ms = 0
controller-1     | 	controlled.shutdown.enable = true
controller-1     | 	controller.listener.names = CONTROLLER
controller-1     | 	controller.performance.always.log.threshold.ms = 2000
controller-1     | 	controller.performance.sample.period.ms = 60000
controller-1     | 	controller.quorum.append.linger.ms = 25
controller-1     | 	controller.quorum.bootstrap.servers = []
controller-1     | 	controller.quorum.election.backoff.max.ms = 1000
controller-1     | 	controller.quorum.election.timeout.ms = 1000
controller-1     | 	controller.quorum.fetch.timeout.ms = 2000
controller-1     | 	controller.quorum.request.timeout.ms = 2000
controller-1     | 	controller.quorum.retry.backoff.ms = 20
controller-1     | 	controller.quorum.voters = [1@controller-1:19091]
controller-1     | 	controller.quota.window.num = 11
controller-1     | 	controller.quota.window.size.seconds = 1
controller-1     | 	controller.socket.timeout.ms = 30000
controller-1     | 	create.cluster.link.policy.class.name = null
controller-1     | 	create.topic.policy.class.name = null
controller-1     | 	default.replication.factor = 1
controller-1     | 	delegation.token.expiry.check.interval.ms = 3600000
controller-1     | 	delegation.token.expiry.time.ms = 86400000
controller-1     | 	delegation.token.max.lifetime.ms = 604800000
controller-1     | 	delegation.token.secret.key = null
controller-1     | 	delete.records.purgatory.purge.interval.requests = 1
controller-1     | 	delete.topic.enable = true
controller-1     | 	early.start.listeners = null
controller-1     | 	enable.fips = false
controller-1     | 	fetch.max.bytes = 57671680
controller-1     | 	fetch.purgatory.purge.interval.requests = 1000
controller-1     | 	floor.max.connection.creation.rate = null
controller-1     | 	follower.replication.throttled.rate = 9223372036854775807
controller-1     | 	follower.replication.throttled.replicas = none
controller-1     | 	group.consumer.assignors = [uniform, range]
controller-1     | 	group.consumer.heartbeat.interval.ms = 5000
controller-1     | 	group.consumer.max.heartbeat.interval.ms = 15000
controller-1     | 	group.consumer.max.session.timeout.ms = 60000
controller-1     | 	group.consumer.max.size = 2147483647
controller-1     | 	group.consumer.migration.policy = bidirectional
controller-1     | 	group.consumer.min.heartbeat.interval.ms = 5000
controller-1     | 	group.consumer.min.session.timeout.ms = 45000
controller-1     | 	group.consumer.regex.refresh.interval.ms = 600000
controller-1     | 	group.consumer.session.timeout.ms = 45000
controller-1     | 	group.coordinator.append.linger.ms = 5
controller-1     | 	group.coordinator.rebalance.protocols = [classic, consumer, share, streams]
controller-1     | 	group.coordinator.threads = 4
controller-1     | 	group.initial.rebalance.delay.ms = 3000
controller-1     | 	group.max.session.timeout.ms = 1800000
controller-1     | 	group.max.size = 2147483647
controller-1     | 	group.min.session.timeout.ms = 6000
controller-1     | 	group.share.assignors = [simple]
controller-1     | 	group.share.delivery.count.limit = 5
controller-1     | 	group.share.enable = false
controller-1     | 	group.share.heartbeat.interval.ms = 5000
controller-1     | 	group.share.initialize.retry.interval.ms = 30000
controller-1     | 	group.share.max.heartbeat.interval.ms = 15000
controller-1     | 	group.share.max.record.lock.duration.ms = 60000
controller-1     | 	group.share.max.session.timeout.ms = 60000
controller-1     | 	group.share.max.share.sessions = 2000
controller-1     | 	group.share.max.size = 200
controller-1     | 	group.share.min.heartbeat.interval.ms = 5000
controller-1     | 	group.share.min.record.lock.duration.ms = 15000
controller-1     | 	group.share.min.session.timeout.ms = 45000
controller-1     | 	group.share.partition.max.record.locks = 2000
controller-1     | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
controller-1     | 	group.share.record.lock.duration.ms = 30000
controller-1     | 	group.share.rollout.ready = true
controller-1     | 	group.share.session.timeout.ms = 45000
controller-1     | 	group.streams.heartbeat.interval.ms = 5000
controller-1     | 	group.streams.max.heartbeat.interval.ms = 15000
controller-1     | 	group.streams.max.session.timeout.ms = 60000
controller-1     | 	group.streams.max.size = 2147483647
controller-1     | 	group.streams.max.standby.replicas = 2
controller-1     | 	group.streams.min.heartbeat.interval.ms = 5000
controller-1     | 	group.streams.min.session.timeout.ms = 45000
controller-1     | 	group.streams.num.standby.replicas = 0
controller-1     | 	group.streams.session.timeout.ms = 45000
controller-1     | 	initial.broker.registration.timeout.ms = 60000
controller-1     | 	inter.broker.listener.name = null
controller-1     | 	internal.metadata.delete.delay.millis = 60000
controller-1     | 	internal.metadata.log.segment.bytes = null
controller-1     | 	internal.metadata.max.batch.size.in.bytes = 8388608
controller-1     | 	internal.metadata.max.fetch.size.in.bytes = 8388608
controller-1     | 	k2.stack.builder.class.name = null
controller-1     | 	k2.startup.timeout.ms = 60000
controller-1     | 	k2.topic.metadata.refresh.ms = 10000
controller-1     | 	kafka.metrics.polling.interval.secs = 10
controller-1     | 	kafka.metrics.reporters = []
controller-1     | 	leader.imbalance.check.interval.seconds = 300
controller-1     | 	leader.replication.throttled.rate = 9223372036854775807
controller-1     | 	leader.replication.throttled.replicas = none
controller-1     | 	listener.security.protocol.map = CONTROLLER:PLAINTEXT
controller-1     | 	listeners = CONTROLLER://controller-1:19091
controller-1     | 	log.cleaner.backoff.ms = 15000
controller-1     | 	log.cleaner.dedupe.buffer.size = 134217728
controller-1     | 	log.cleaner.delete.retention.ms = 86400000
controller-1     | 	log.cleaner.enable = true
controller-1     | 	log.cleaner.hash.algorithm = MD5
controller-1     | 	log.cleaner.io.buffer.load.factor = 0.9
controller-1     | 	log.cleaner.io.buffer.size = 524288
controller-1     | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
controller-1     | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
controller-1     | 	log.cleaner.min.cleanable.ratio = 0.5
controller-1     | 	log.cleaner.min.compaction.lag.ms = 0
controller-1     | 	log.cleaner.threads = 1
controller-1     | 	log.cleanup.policy = [delete]
controller-1     | 	log.cleanup.policy.empty.validation = none
controller-1     | 	log.deletion.max.segments.per.run = 2147483647
controller-1     | 	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
controller-1     | 	log.dir = /tmp/kafka-logs
controller-1     | 	log.dir.failure.timeout.ms = 30000
controller-1     | 	log.dirs = /var/lib/kafka/data
controller-1     | 	log.flush.interval.messages = 9223372036854775807
controller-1     | 	log.flush.interval.ms = null
controller-1     | 	log.flush.offset.checkpoint.interval.ms = 60000
controller-1     | 	log.flush.scheduler.interval.ms = 9223372036854775807
controller-1     | 	log.flush.start.offset.checkpoint.interval.ms = 60000
controller-1     | 	log.index.interval.bytes = 4096
controller-1     | 	log.index.size.max.bytes = 10485760
controller-1     | 	log.initial.task.delay.ms = 30000
controller-1     | 	log.local.retention.bytes = -2
controller-1     | 	log.local.retention.ms = -2
controller-1     | 	log.message.timestamp.after.max.ms = 3600000
controller-1     | 	log.message.timestamp.before.max.ms = 9223372036854775807
controller-1     | 	log.message.timestamp.type = CreateTime
controller-1     | 	log.preallocate = false
controller-1     | 	log.retention.bytes = -1
controller-1     | 	log.retention.check.interval.ms = 300000
controller-1     | 	log.retention.hours = 168
controller-1     | 	log.retention.minutes = null
controller-1     | 	log.retention.ms = null
controller-1     | 	log.roll.hours = 168
controller-1     | 	log.roll.jitter.hours = 0
controller-1     | 	log.roll.jitter.ms = null
controller-1     | 	log.roll.ms = null
controller-1     | 	log.segment.bytes = 1073741824
controller-1     | 	log.segment.delete.delay.ms = 60000
controller-1     | 	max.connection.creation.rate = 1.7976931348623157E308
controller-1     | 	max.connection.creation.rate.per.ip.enable.threshold = 0.0
controller-1     | 	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
controller-1     | 	max.connections = 2147483647
controller-1     | 	max.connections.per.ip = 2147483647
controller-1     | 	max.connections.per.ip.overrides = 
controller-1     | 	max.connections.per.tenant = 0
controller-1     | 	max.connections.protected.listeners = []
controller-1     | 	max.connections.reap.amount = 0
controller-1     | 	max.incremental.fetch.session.cache.slots = 1000
controller-1     | 	max.request.partition.size.limit = 2000
controller-1     | 	message.max.bytes = 1048588
controller-1     | 	metadata.log.dir = null
controller-1     | 	metadata.log.max.record.bytes.between.snapshots = 20971520
controller-1     | 	metadata.log.max.snapshot.interval.ms = 3600000
controller-1     | 	metadata.log.segment.bytes = 1073741824
controller-1     | 	metadata.log.segment.ms = 604800000
controller-1     | 	metadata.max.idle.interval.ms = 500
controller-1     | 	metadata.max.retention.bytes = 104857600
controller-1     | 	metadata.max.retention.ms = 604800000
controller-1     | 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
controller-1     | 	metrics.num.samples = 2
controller-1     | 	metrics.recording.level = INFO
controller-1     | 	metrics.sample.window.ms = 30000
controller-1     | 	min.insync.replicas = 1
controller-1     | 	multitenant.authorizer.support.resource.ids = false
controller-1     | 	multitenant.metadata.class = null
controller-1     | 	multitenant.metadata.dir = null
controller-1     | 	multitenant.metadata.reload.delay.ms = 120000
controller-1     | 	multitenant.metadata.ssl.certs.path = null
controller-1     | 	multitenant.tenant.delete.batch.size = 10
controller-1     | 	multitenant.tenant.delete.check.ms = 120000
controller-1     | 	multitenant.tenant.delete.delay = 604800000
controller-1     | 	node.id = 1
controller-1     | 	num.io.threads = 8
controller-1     | 	num.network.threads = 3
controller-1     | 	num.partitions = 1
controller-1     | 	num.recovery.threads.per.data.dir = 2
controller-1     | 	num.replica.alter.log.dirs.threads = null
controller-1     | 	num.replica.fetchers = 1
controller-1     | 	offset.metadata.max.bytes = 4096
controller-1     | 	offsets.commit.timeout.ms = 5000
controller-1     | 	offsets.load.buffer.size = 5242880
controller-1     | 	offsets.retention.check.interval.ms = 600000
controller-1     | 	offsets.retention.minutes = 10080
controller-1     | 	offsets.topic.compression.codec = 0
controller-1     | 	offsets.topic.num.partitions = 50
controller-1     | 	offsets.topic.replication.factor = 3
controller-1     | 	offsets.topic.segment.bytes = 104857600
controller-1     | 	otel.exporter.otlp.custom.endpoint = default
controller-1     | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
controller-1     | 	process.roles = [controller]
controller-1     | 	producer.id.expiration.check.interval.ms = 600000
controller-1     | 	producer.id.expiration.ms = 86400000
controller-1     | 	producer.purgatory.purge.interval.requests = 1000
controller-1     | 	queued.max.request.bytes = -1
controller-1     | 	queued.max.requests = 500
controller-1     | 	quota.window.num = 11
controller-1     | 	quota.window.size.seconds = 1
controller-1     | 	quotas.consumption.expiration.time.ms = 600000
controller-1     | 	quotas.expiration.interval.ms = 3600000
controller-1     | 	quotas.expiration.time.ms = 604800000
controller-1     | 	quotas.lazy.evaluation.threshold = 0.5
controller-1     | 	quotas.topic.append.timeout.ms = 5000
controller-1     | 	quotas.topic.compression.codec = 3
controller-1     | 	quotas.topic.load.buffer.size = 5242880
controller-1     | 	quotas.topic.num.partitions = 50
controller-1     | 	quotas.topic.placement.constraints = 
controller-1     | 	quotas.topic.replication.factor = 3
controller-1     | 	quotas.topic.segment.bytes = 104857600
controller-1     | 	remote.fetch.max.wait.ms = 500
controller-1     | 	remote.list.offsets.request.timeout.ms = 30000
controller-1     | 	remote.log.index.file.cache.total.size.bytes = 1073741824
controller-1     | 	remote.log.manager.copier.thread.pool.size = 10
controller-1     | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
controller-1     | 	remote.log.manager.copy.quota.window.num = 11
controller-1     | 	remote.log.manager.copy.quota.window.size.seconds = 1
controller-1     | 	remote.log.manager.expiration.thread.pool.size = 10
controller-1     | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
controller-1     | 	remote.log.manager.fetch.quota.window.num = 11
controller-1     | 	remote.log.manager.fetch.quota.window.size.seconds = 1
controller-1     | 	remote.log.manager.task.interval.ms = 30000
controller-1     | 	remote.log.manager.task.retry.backoff.max.ms = 30000
controller-1     | 	remote.log.manager.task.retry.backoff.ms = 500
controller-1     | 	remote.log.manager.task.retry.jitter = 0.2
controller-1     | 	remote.log.manager.thread.pool.size = 2
controller-1     | 	remote.log.metadata.custom.metadata.max.bytes = 128
controller-1     | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
controller-1     | 	remote.log.metadata.manager.class.path = null
controller-1     | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
controller-1     | 	remote.log.metadata.manager.listener.name = null
controller-1     | 	remote.log.reader.max.pending.tasks = 100
controller-1     | 	remote.log.reader.threads = 10
controller-1     | 	remote.log.storage.manager.class.name = null
controller-1     | 	remote.log.storage.manager.class.path = null
controller-1     | 	remote.log.storage.manager.impl.prefix = rsm.config.
controller-1     | 	remote.log.storage.system.enable = false
controller-1     | 	replica.fetch.backoff.ms = 1000
controller-1     | 	replica.fetch.max.bytes = 1048576
controller-1     | 	replica.fetch.min.bytes = 1
controller-1     | 	replica.fetch.response.max.bytes = 10485760
controller-1     | 	replica.fetch.wait.max.ms = 500
controller-1     | 	replica.high.watermark.checkpoint.interval.ms = 5000
controller-1     | 	replica.lag.time.max.ms = 30000
controller-1     | 	replica.selector.class = null
controller-1     | 	replica.socket.receive.buffer.bytes = 65536
controller-1     | 	replica.socket.timeout.ms = 30000
controller-1     | 	replication.quota.window.num = 11
controller-1     | 	replication.quota.window.size.seconds = 1
controller-1     | 	request.timeout.ms = 30000
controller-1     | 	sasl.client.callback.handler.class = null
controller-1     | 	sasl.enabled.mechanisms = [GSSAPI]
controller-1     | 	sasl.jaas.config = null
controller-1     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
controller-1     | 	sasl.kerberos.min.time.before.relogin = 60000
controller-1     | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
controller-1     | 	sasl.kerberos.service.name = null
controller-1     | 	sasl.kerberos.ticket.renew.jitter = 0.05
controller-1     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
controller-1     | 	sasl.login.callback.handler.class = null
controller-1     | 	sasl.login.class = null
controller-1     | 	sasl.login.connect.timeout.ms = null
controller-1     | 	sasl.login.read.timeout.ms = null
controller-1     | 	sasl.login.refresh.buffer.seconds = 300
controller-1     | 	sasl.login.refresh.min.period.seconds = 60
controller-1     | 	sasl.login.refresh.window.factor = 0.8
controller-1     | 	sasl.login.refresh.window.jitter = 0.05
controller-1     | 	sasl.login.retry.backoff.max.ms = 10000
controller-1     | 	sasl.login.retry.backoff.ms = 100
controller-1     | 	sasl.mechanism.controller.protocol = GSSAPI
controller-1     | 	sasl.mechanism.inter.broker.protocol = GSSAPI
controller-1     | 	sasl.oauthbearer.assertion.algorithm = RS256
controller-1     | 	sasl.oauthbearer.assertion.claim.aud = null
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
controller-1     | 	sasl.oauthbearer.assertion.claim.iss = null
controller-1     | 	sasl.oauthbearer.assertion.claim.jti.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
controller-1     | 	sasl.oauthbearer.assertion.claim.sub = null
controller-1     | 	sasl.oauthbearer.assertion.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
controller-1     | 	sasl.oauthbearer.assertion.template.file = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.id = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.secret = null
controller-1     | 	sasl.oauthbearer.clock.skew.seconds = 30
controller-1     | 	sasl.oauthbearer.expected.audience = null
controller-1     | 	sasl.oauthbearer.expected.issuer = null
controller-1     | 	sasl.oauthbearer.iat.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jti.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
controller-1     | 	sasl.oauthbearer.jwks.endpoint.url = null
controller-1     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
controller-1     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
controller-1     | 	sasl.oauthbearer.scope = null
controller-1     | 	sasl.oauthbearer.scope.claim.name = scope
controller-1     | 	sasl.oauthbearer.sub.claim.name = sub
controller-1     | 	sasl.oauthbearer.token.endpoint.url = null
controller-1     | 	sasl.server.authn.async.enable = false
controller-1     | 	sasl.server.authn.async.max.threads = 1
controller-1     | 	sasl.server.authn.async.timeout.ms = 30000
controller-1     | 	sasl.server.callback.handler.class = null
controller-1     | 	sasl.server.max.receive.size = 524288
controller-1     | 	security.inter.broker.protocol = PLAINTEXT
controller-1     | 	security.providers = null
controller-1     | 	server.max.startup.time.ms = 9223372036854775807
controller-1     | 	share.coordinator.append.linger.ms = 5
controller-1     | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
controller-1     | 	share.coordinator.load.buffer.size = 5242880
controller-1     | 	share.coordinator.snapshot.update.records.per.snapshot = 500
controller-1     | 	share.coordinator.state.topic.compression.codec = 0
controller-1     | 	share.coordinator.state.topic.min.isr = 2
controller-1     | 	share.coordinator.state.topic.num.partitions = 50
controller-1     | 	share.coordinator.state.topic.prune.interval.ms = 300000
controller-1     | 	share.coordinator.state.topic.replication.factor = 3
controller-1     | 	share.coordinator.state.topic.segment.bytes = 104857600
controller-1     | 	share.coordinator.threads = 1
controller-1     | 	share.coordinator.write.timeout.ms = 5000
controller-1     | 	share.fetch.purgatory.purge.interval.requests = 1000
controller-1     | 	socket.connection.setup.timeout.max.ms = 30000
controller-1     | 	socket.connection.setup.timeout.ms = 10000
controller-1     | 	socket.listen.backlog.size = 50
controller-1     | 	socket.receive.buffer.bytes = 102400
controller-1     | 	socket.request.max.bytes = 104857600
controller-1     | 	socket.send.buffer.bytes = 102400
controller-1     | 	ssl.allow.dn.changes = false
controller-1     | 	ssl.allow.san.changes = false
controller-1     | 	ssl.cipher.suites = []
controller-1     | 	ssl.client.auth = none
controller-1     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
controller-1     | 	ssl.endpoint.identification.algorithm = https
controller-1     | 	ssl.engine.factory.class = null
controller-1     | 	ssl.key.password = null
controller-1     | 	ssl.keymanager.algorithm = SunX509
controller-1     | 	ssl.keystore.certificate.chain = null
controller-1     | 	ssl.keystore.key = null
controller-1     | 	ssl.keystore.location = null
controller-1     | 	ssl.keystore.password = null
controller-1     | 	ssl.keystore.type = JKS
controller-1     | 	ssl.principal.mapping.rules = DEFAULT
controller-1     | 	ssl.protocol = TLSv1.3
controller-1     | 	ssl.provider = null
controller-1     | 	ssl.secure.random.implementation = null
controller-1     | 	ssl.trustmanager.algorithm = PKIX
controller-1     | 	ssl.truststore.certificates = null
controller-1     | 	ssl.truststore.location = null
controller-1     | 	ssl.truststore.password = null
controller-1     | 	ssl.truststore.type = JKS
controller-1     | 	telemetry.max.bytes = 1048576
controller-1     | 	throughput.quota.window.num = 11
controller-1     | 	token.impersonation.validation = true
controller-1     | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
controller-1     | 	transaction.max.timeout.ms = 900000
controller-1     | 	transaction.metadata.load.threads = 32
controller-1     | 	transaction.partition.verification.enable = true
controller-1     | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
controller-1     | 	transaction.state.log.load.buffer.size = 5242880
controller-1     | 	transaction.state.log.min.isr = 2
controller-1     | 	transaction.state.log.num.partitions = 50
controller-1     | 	transaction.state.log.replication.factor = 1
controller-1     | 	transaction.state.log.segment.bytes = 104857600
controller-1     | 	transaction.two.phase.commit.enable = false
controller-1     | 	transactional.id.expiration.ms = 604800000
controller-1     | 	unclean.leader.election.enable = false
controller-1     | 	unclean.leader.election.interval.ms = 300000
controller-1     | 	unstable.api.versions.enable = false
controller-1     | 	unstable.feature.versions.enable = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:57,903] INFO KafkaConfig values: 
kafka-1          | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafka-1          | 	add.partitions.to.txn.retry.backoff.ms = 20
kafka-1          | 	advertised.listeners = PLAINTEXT://kafka-1:19092, EXTERNAL://localhost:9091
kafka-1          | 	alter.config.policy.class.name = null
kafka-1          | 	alter.log.dirs.replication.quota.window.num = 11
kafka-1          | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka-1          | 	authorizer.class.name = 
kafka-1          | 	auto.create.topics.enable = true
kafka-1          | 	auto.leader.rebalance.enable = true
kafka-1          | 	background.threads = 10
kafka-1          | 	broker.heartbeat.interval.ms = 2000
kafka-1          | 	broker.id = 2
kafka-1          | 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
kafka-1          | 	broker.rack = rack-0
kafka-1          | 	broker.session.timeout.ms = 9000
kafka-1          | 	broker.session.uuid = Cq1QTtEwT2CoFqEpv4E8ZA
kafka-1          | 	client.quota.callback.class = null
kafka-1          | 	client.quota.max.throttle.time.in.response.ms = 60000
kafka-1          | 	client.quota.max.throttle.time.ms = 5000
kafka-1          | 	compression.gzip.level = -1
kafka-1          | 	compression.lz4.level = 9
kafka-1          | 	compression.type = producer
kafka-1          | 	compression.zstd.level = 3
kafka-1          | 	confluent.accp.enabled = false
kafka-1          | 	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
kafka-1          | 	confluent.alter.broker.health.max.demoted.brokers = 2147483647
kafka-1          | 	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
kafka-1          | 	confluent.ansible.managed = false
kafka-1          | 	confluent.api.visibility = DEFAULT
kafka-1          | 	confluent.append.record.interceptor.classes = []
kafka-1          | 	confluent.apply.create.topic.policy.to.create.partitions = false
kafka-1          | 	confluent.authorizer.authority.name = 
kafka-1          | 	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
kafka-1          | 	confluent.backpressure.disk.enable = false
kafka-1          | 	confluent.backpressure.disk.free.threshold.bytes = 21474836480
kafka-1          | 	confluent.backpressure.disk.produce.bytes.per.second = 131072
kafka-1          | 	confluent.backpressure.disk.threshold.recovery.factor = 1.5
kafka-1          | 	confluent.backpressure.request.min.broker.limit = 200
kafka-1          | 	confluent.backpressure.request.queue.size.percentile = p95
kafka-1          | 	confluent.backpressure.types = null
kafka-1          | 	confluent.balancer.api.state.topic = _confluent_balancer_api_state
kafka-1          | 	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
kafka-1          | 	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
kafka-1          | 	confluent.balancer.capacity.threshold.upper.limit = 0.95
kafka-1          | 	confluent.balancer.cell.load.upper.bound = 0.7
kafka-1          | 	confluent.balancer.cell.overload.detection.interval.ms = 3600000
kafka-1          | 	confluent.balancer.cell.overload.duration.ms = 86400000
kafka-1          | 	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
kafka-1          | 	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.cpu.balance.threshold = 1.1
kafka-1          | 	confluent.balancer.cpu.goal.act.as.capacity.goal = false
kafka-1          | 	confluent.balancer.cpu.low.utilization.threshold = 0.2
kafka-1          | 	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
kafka-1          | 	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
kafka-1          | 	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
kafka-1          | 	confluent.balancer.disk.max.load = 0.85
kafka-1          | 	confluent.balancer.disk.min.free.space.gb = 0
kafka-1          | 	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
kafka-1          | 	confluent.balancer.disk.utilization.detector.duration.ms = 600000
kafka-1          | 	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
kafka-1          | 	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
kafka-1          | 	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
kafka-1          | 	confluent.balancer.enable = true
kafka-1          | 	confluent.balancer.enable.network.capacity.metric.ingestion = false
kafka-1          | 	confluent.balancer.exclude.topic.names = []
kafka-1          | 	confluent.balancer.exclude.topic.prefixes = []
kafka-1          | 	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
kafka-1          | 	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
kafka-1          | 	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
kafka-1          | 	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
kafka-1          | 	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
kafka-1          | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
kafka-1          | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
kafka-1          | 	confluent.balancer.incremental.balancing.enabled = false
kafka-1          | 	confluent.balancer.incremental.balancing.goals = []
kafka-1          | 	confluent.balancer.incremental.balancing.lower.bound = 0.02
kafka-1          | 	confluent.balancer.incremental.balancing.min.valid.windows = 5
kafka-1          | 	confluent.balancer.incremental.balancing.step.ratio = 0.2
kafka-1          | 	confluent.balancer.inter.cell.balancing.enabled = false
kafka-1          | 	confluent.balancer.inter.cell.movements.excluded.tenant.ids = []
kafka-1          | 	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
kafka-1          | 	confluent.balancer.max.replicas = 2147483647
kafka-1          | 	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
kafka-1          | 	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
kafka-1          | 	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
kafka-1          | 	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
kafka-1          | 	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.rebalancing.goals = []
kafka-1          | 	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.resource.utilization.detector.interval.ms = 60000
kafka-1          | 	confluent.balancer.sbc.metrics.parser.enabled = false
kafka-1          | 	confluent.balancer.self.healing.maximum.rounds = 1
kafka-1          | 	confluent.balancer.task.history.retention.days = 30
kafka-1          | 	confluent.balancer.tenant.maximum.movements = 0
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.consume_out = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.cpu = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.nw_in = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.nw_out = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.produce_in = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.replica_count = 3
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.consume_out = 614400.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.cpu = 300.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_in = 204800.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_out = 614400.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.produce_in = 204800.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.replica_count = 45000.0
kafka-1          | 	confluent.balancer.tenant.striping.enable.dry.run.mode = true
kafka-1          | 	confluent.balancer.tenant.striping.enabled = false
kafka-1          | 	confluent.balancer.tenant.striping.expiry.counter.threshold = 10
kafka-1          | 	confluent.balancer.tenant.striping.rate.limit = 3
kafka-1          | 	confluent.balancer.tenant.striping.resource.usage.expiry.ms = 3600000
kafka-1          | 	confluent.balancer.tenant.suspension.ms = 86400000
kafka-1          | 	confluent.balancer.throttle.bytes.per.second = 10485760
kafka-1          | 	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
kafka-1          | 	confluent.balancer.topic.partition.maximum.movements = 3
kafka-1          | 	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
kafka-1          | 	confluent.balancer.topic.partition.movements.history.limit = 900
kafka-1          | 	confluent.balancer.topic.partition.suspension.ms = 3600000
kafka-1          | 	confluent.balancer.topic.replication.factor = 3
kafka-1          | 	confluent.balancer.triggering.goals = []
kafka-1          | 	confluent.balancer.v2.addition.enabled = false
kafka-1          | 	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
kafka-1          | 	confluent.balancer.v2.executor.enabled = false
kafka-1          | 	confluent.basic.auth.credentials.source = null
kafka-1          | 	confluent.basic.auth.user.info = null
kafka-1          | 	confluent.bearer.assertion.claim.aud = null
kafka-1          | 	confluent.bearer.assertion.claim.exp.minutes = null
kafka-1          | 	confluent.bearer.assertion.claim.iss = null
kafka-1          | 	confluent.bearer.assertion.claim.jti.include = null
kafka-1          | 	confluent.bearer.assertion.claim.nbf.include = null
kafka-1          | 	confluent.bearer.assertion.claim.sub = null
kafka-1          | 	confluent.bearer.assertion.file = null
kafka-1          | 	confluent.bearer.assertion.private.key.file = null
kafka-1          | 	confluent.bearer.assertion.private.key.passphrase = null
kafka-1          | 	confluent.bearer.assertion.template.file = null
kafka-1          | 	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
kafka-1          | 	confluent.bearer.auth.client.id = null
kafka-1          | 	confluent.bearer.auth.client.secret = null
kafka-1          | 	confluent.bearer.auth.credentials.source = null
kafka-1          | 	confluent.bearer.auth.identity.pool.id = null
kafka-1          | 	confluent.bearer.auth.issuer.endpoint.url = null
kafka-1          | 	confluent.bearer.auth.logical.cluster = null
kafka-1          | 	confluent.bearer.auth.scope = null
kafka-1          | 	confluent.bearer.auth.scope.claim.name = scope
kafka-1          | 	confluent.bearer.auth.sub.claim.name = sub
kafka-1          | 	confluent.bearer.auth.token = null
kafka-1          | 	confluent.broker.health.manager.enabled = true
kafka-1          | 	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
kafka-1          | 	confluent.broker.health.manager.hard.kill.duration.ms = 60000
kafka-1          | 	confluent.broker.health.manager.mitigation.enabled = false
kafka-1          | 	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
kafka-1          | 	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
kafka-1          | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
kafka-1          | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
kafka-1          | 	confluent.broker.health.manager.sample.duration.ms = 1000
kafka-1          | 	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.broker.load.advertised.limit.load = 0.8
kafka-1          | 	confluent.broker.load.average.service.request.time.ms = 0.1
kafka-1          | 	confluent.broker.load.delay.metric.start.ms = 180000
kafka-1          | 	confluent.broker.load.enabled = false
kafka-1          | 	confluent.broker.load.num.samples = 60
kafka-1          | 	confluent.broker.load.tenant.metric.enable = false
kafka-1          | 	confluent.broker.load.update.metric.tags.interval.ms = 60000
kafka-1          | 	confluent.broker.load.window.size.ms = 60000
kafka-1          | 	confluent.broker.load.workload.coefficient = 20.0
kafka-1          | 	confluent.broker.registration.delay.ms = 0
kafka-1          | 	confluent.broker.type = confluent_platform
kafka-1          | 	confluent.broker.type.topic.enabled = true
kafka-1          | 	confluent.calling.resource.identity.type.map = 
kafka-1          | 	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
kafka-1          | 	confluent.catalog.collector.enable = false
kafka-1          | 	confluent.catalog.collector.full.configs.enable = false
kafka-1          | 	confluent.catalog.collector.max.bytes.per.snapshot = 850000
kafka-1          | 	confluent.catalog.collector.max.topics.process = 500
kafka-1          | 	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
kafka-1          | 	confluent.catalog.collector.multitenant.topics.enable = true
kafka-1          | 	confluent.catalog.collector.snapshot.init.delay.sec = 60
kafka-1          | 	confluent.catalog.collector.snapshot.interval.sec = 300
kafka-1          | 	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
kafka-1          | 	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
kafka-1          | 	confluent.cdc.api.keys.topic = 
kafka-1          | 	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
kafka-1          | 	confluent.cdc.client.quotas.enable = false
kafka-1          | 	confluent.cdc.client.quotas.topic.name = 
kafka-1          | 	confluent.cdc.lkc.metadata.topic = 
kafka-1          | 	confluent.cdc.user.metadata.enable = false
kafka-1          | 	confluent.cdc.user.metadata.topic = _confluent-user_metadata
kafka-1          | 	confluent.cell.metrics.refresh.period.ms = 60000
kafka-1          | 	confluent.cells.default.size = 15
kafka-1          | 	confluent.cells.enable = false
kafka-1          | 	confluent.cells.implicit.creation.enable = false
kafka-1          | 	confluent.cells.k2.base.broker.index = -1
kafka-1          | 	confluent.cells.load.refresher.enable = true
kafka-1          | 	confluent.cells.max.size = 15
kafka-1          | 	confluent.cells.min.size = 6
kafka-1          | 	confluent.checksum.enabled.files = [none]
kafka-1          | 	confluent.client.topic.max.metrics.count = 1000
kafka-1          | 	confluent.client.topic.metrics.expiry.sec = 3600
kafka-1          | 	confluent.client.topic.metrics.ignore_client_id_pattern = (?:link-.*-)?broker-\d+-fetcher-\d+(?:-pool-.*)?
kafka-1          | 	confluent.client.topic.metrics.ignore_internal_topic_pattern = _.*
kafka-1          | 	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
kafka-1          | 	confluent.clm.enabled = false
kafka-1          | 	confluent.clm.frequency.in.hours = 6
kafka-1          | 	confluent.clm.list.object.thread_pool.size = 1
kafka-1          | 	confluent.clm.max.backup.days = 3
kafka-1          | 	confluent.clm.min.delay.in.minutes = 30
kafka-1          | 	confluent.clm.thread.pool.size = 2
kafka-1          | 	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
kafka-1          | 	confluent.close.connections.on.credential.delete = false
kafka-1          | 	confluent.cluster.link.admin.max.in.flight.requests = 1000
kafka-1          | 	confluent.cluster.link.admin.request.batch.size = 1
kafka-1          | 	confluent.cluster.link.allow.config.providers = true
kafka-1          | 	confluent.cluster.link.allow.legacy.message.format = false
kafka-1          | 	confluent.cluster.link.allow.truncation.below.hwm = false
kafka-1          | 	confluent.cluster.link.availability.check.mode = ALL
kafka-1          | 	confluent.cluster.link.background.thread.affinity = LINK
kafka-1          | 	confluent.cluster.link.bootstrap.translation.feature.enable = true
kafka-1          | 	confluent.cluster.link.clients.max.idle.ms = 3153600000000
kafka-1          | 	confluent.cluster.link.enable = false
kafka-1          | 	confluent.cluster.link.enable.local.admin = false
kafka-1          | 	confluent.cluster.link.enable.metrics.reduction = false
kafka-1          | 	confluent.cluster.link.enable.metrics.reduction.advanced = false
kafka-1          | 	confluent.cluster.link.fetch.response.min.bytes = 1
kafka-1          | 	confluent.cluster.link.fetch.response.total.bytes = 2147483647
kafka-1          | 	confluent.cluster.link.fetcher.auto.tune.enable = false
kafka-1          | 	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
kafka-1          | 	confluent.cluster.link.insync.fetch.response.min.bytes = 1
kafka-1          | 	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
kafka-1          | 	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
kafka-1          | 	confluent.cluster.link.intranet.connectivity.enable = false
kafka-1          | 	confluent.cluster.link.intranet.connectivity.migration.enable = false
kafka-1          | 	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.cluster.link.k1.to.k2.migration.enable = false
kafka-1          | 	confluent.cluster.link.k2.mirror.topic.metadata.enable = false
kafka-1          | 	confluent.cluster.link.local.admin.multitenant.enable = false
kafka-1          | 	confluent.cluster.link.local.reverse.connection.listener.map = null
kafka-1          | 	confluent.cluster.link.max.client.connections = 2147483647
kafka-1          | 	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
kafka-1          | 	confluent.cluster.link.metadata.topic.enable = false
kafka-1          | 	confluent.cluster.link.metadata.topic.min.isr = 2
kafka-1          | 	confluent.cluster.link.metadata.topic.partitions = 50
kafka-1          | 	confluent.cluster.link.metadata.topic.replication.factor = 3
kafka-1          | 	confluent.cluster.link.mirror.transition.batch.size = 10
kafka-1          | 	confluent.cluster.link.num.background.threads = 1
kafka-1          | 	confluent.cluster.link.num.fetchers = 1
kafka-1          | 	confluent.cluster.link.periodic.task.batch.size = 2147483647
kafka-1          | 	confluent.cluster.link.periodic.task.min.interval.ms = 1000
kafka-1          | 	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
kafka-1          | 	confluent.cluster.link.replica.fetch.connections.mode = combined
kafka-1          | 	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
kafka-1          | 	confluent.cluster.link.replication.quota.mode.per.tenant.overrides = 
kafka-1          | 	confluent.cluster.link.replication.quota.window.num = 11
kafka-1          | 	confluent.cluster.link.replication.quota.window.size.seconds = 2
kafka-1          | 	confluent.cluster.link.request.quota.capacity = 400
kafka-1          | 	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
kafka-1          | 	confluent.cluster.link.switchover.disabled.principals = []
kafka-1          | 	confluent.cluster.link.switchover.enable = false
kafka-1          | 	confluent.cluster.link.switchover.listeners = []
kafka-1          | 	confluent.cluster.link.switchover.server.states = []
kafka-1          | 	confluent.cluster.link.tenant.replication.quota.enable = false
kafka-1          | 	confluent.cluster.link.tenant.request.quota.enable = false
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.enable = false
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.upload.enable = false
kafka-1          | 	confluent.compacted.topic.prefer.tier.fetch.ms = -1
kafka-1          | 	confluent.connection.invalid.request.delay.enable = false
kafka-1          | 	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
kafka-1          | 	confluent.consumer.fetch.partition.pruning.enable = true
kafka-1          | 	confluent.consumer.lag.emitter.enabled = false
kafka-1          | 	confluent.consumer.lag.emitter.interval.ms = 60000
kafka-1          | 	confluent.dataflow.policy.watch.monitor.ms = 300000
kafka-1          | 	confluent.default.data.policy.enforcement = true
kafka-1          | 	confluent.defer.isr.shrink.enable = false
kafka-1          | 	confluent.describe.topic.partitions.enabled = true
kafka-1          | 	confluent.disk.io.manager.enable = false
kafka-1          | 	confluent.disk.throughput.headroom = 10485760
kafka-1          | 	confluent.disk.throughput.limit = 10485760000
kafka-1          | 	confluent.disk.throughput.quota.tier.archive = 1048576000
kafka-1          | 	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
kafka-1          | 	confluent.durability.audit.batch.flush.frequency.ms = 900000
kafka-1          | 	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
kafka-1          | 	confluent.durability.audit.enable = false
kafka-1          | 	confluent.durability.audit.idempotent.producer = false
kafka-1          | 	confluent.durability.audit.initial.job.delay.ms = 900000
kafka-1          | 	confluent.durability.audit.io.bytes.per.sec = 10485760
kafka-1          | 	confluent.durability.audit.log.ignored.event.types = 
kafka-1          | 	confluent.durability.audit.reporting.batch.ms = 1800000
kafka-1          | 	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
kafka-1          | 	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
kafka-1          | 	confluent.durability.topic.partition.count = 50
kafka-1          | 	confluent.durability.topic.replication.factor = 3
kafka-1          | 	confluent.e2e_checksum.protection.enabled = false
kafka-1          | 	confluent.e2e_checksum.protection.files = [none]
kafka-1          | 	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
kafka-1          | 	confluent.elastic.cku.enabled = false
kafka-1          | 	confluent.elastic.cku.scaletozero.enabled = false
kafka-1          | 	confluent.eligible.controllers = []
kafka-1          | 	confluent.emit.network.type.default = 
kafka-1          | 	confluent.emit.network.type.tag = false
kafka-1          | 	confluent.enable.broker.reporting.min.usage.mode = true
kafka-1          | 	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
kafka-1          | 	confluent.fail.unsatisfied.placement.constraints = false
kafka-1          | 	confluent.fetch.from.follower.require.leader.epoch.enable = false
kafka-1          | 	confluent.fetch.partition.pruning.enable = true
kafka-1          | 	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
kafka-1          | 	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
kafka-1          | 	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
kafka-1          | 	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
kafka-1          | 	confluent.flexible.fanout.enabled = false
kafka-1          | 	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
kafka-1          | 	confluent.flexible.fanout.mode = TENANT_QUOTA
kafka-1          | 	confluent.floor.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.floor.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.group.coordinator.dynamic.append.linger.enable = false
kafka-1          | 	confluent.group.coordinator.max.partition.queue.size = -1
kafka-1          | 	confluent.group.coordinator.offsets.batching.enable = false
kafka-1          | 	confluent.group.coordinator.offsets.writer.threads = 2
kafka-1          | 	confluent.group.coordinator.slow.event.log.count = 10
kafka-1          | 	confluent.group.coordinator.slow.event.log.interval.ms = -1
kafka-1          | 	confluent.group.coordinator.txn.offset.validation.enable = false
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.count = 10
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.enable = false
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
kafka-1          | 	confluent.group.metadata.load.threads = 32
kafka-1          | 	confluent.group.subscription.pattern.log.interval.ms = -1
kafka-1          | 	confluent.heap.tenured.notify.bytes = 0
kafka-1          | 	confluent.heap.tenured.notify.enabled = false
kafka-1          | 	confluent.hot.partition.ratio = 0.8
kafka-1          | 	confluent.http.server.start.timeout.ms = 60000
kafka-1          | 	confluent.http.server.stop.timeout.ms = 30000
kafka-1          | 	confluent.intelligent.replication.enable = false
kafka-1          | 	confluent.intelligent.replication.push.max.memory.buffer.bytes = 209715200
kafka-1          | 	confluent.intelligent.replication.push.max.threads = 4
kafka-1          | 	confluent.intelligent.replication.push.threads.per.remote.broker = 1
kafka-1          | 	confluent.internal.metrics.enable = false
kafka-1          | 	confluent.internal.rest.server.bind.port = null
kafka-1          | 	confluent.internal.rest.server.ssl.enable = false
kafka-1          | 	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
kafka-1          | 	confluent.lat.network.context.verification.enable = false
kafka-1          | 	confluent.leader.epoch.checkpoint.checksum.enabled = false
kafka-1          | 	confluent.listener.protocol = TCP
kafka-1          | 	confluent.log.cleaner.timestamp.validation.enable = true
kafka-1          | 	confluent.log.placement.constraints = 
kafka-1          | 	confluent.max.broker.load = 1.0
kafka-1          | 	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
kafka-1          | 	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
kafka-1          | 	confluent.max.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.max.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.max.connection.throttle.ms = null
kafka-1          | 	confluent.max.segment.ms = 9223372036854775807
kafka-1          | 	confluent.metadata.active.encryptor = null
kafka-1          | 	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
kafka-1          | 	confluent.metadata.encryptor.classes = null
kafka-1          | 	confluent.metadata.encryptor.required = false
kafka-1          | 	confluent.metadata.encryptor.secret.file = null
kafka-1          | 	confluent.metadata.encryptor.secrets = null
kafka-1          | 	confluent.metadata.jvm.warmup.ms = 60000
kafka-1          | 	confluent.metadata.leader.balance.slice.delay.ms = 100
kafka-1          | 	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
kafka-1          | 	confluent.metadata.max.leader.balance.changes.per.slice = 1000
kafka-1          | 	confluent.metadata.rbac_auth.read.controller.enable = false
kafka-1          | 	confluent.metadata.rbac_auth.update.controller.enable = false
kafka-1          | 	confluent.metadata.reject.when.throttled.enable = false
kafka-1          | 	confluent.metadata.server.cluster.registry.clusters = []
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.min.acks = 0
kafka-1          | 	confluent.min.connection.throttle.ms = 0
kafka-1          | 	confluent.min.segment.ms = 1
kafka-1          | 	confluent.missing.id.cache.ttl.sec = 60
kafka-1          | 	confluent.missing.id.query.range = 20000
kafka-1          | 	confluent.missing.schema.cache.ttl.sec = 60
kafka-1          | 	confluent.mtls.build.client.cert.chain.enable = false
kafka-1          | 	confluent.mtls.enable = false
kafka-1          | 	confluent.mtls.listener.name = EXTERNAL
kafka-1          | 	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
kafka-1          | 	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
kafka-1          | 	confluent.mtls.truststore.manager.class.name = null
kafka-1          | 	confluent.multitenant.authorizer.enable.acl.state = false
kafka-1          | 	confluent.multitenant.interceptor.balancer.apis.enabled = false
kafka-1          | 	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
kafka-1          | 	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
kafka-1          | 	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
kafka-1          | 	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
kafka-1          | 	confluent.multitenant.listener.names = null
kafka-1          | 	confluent.multitenant.parse.lkc.id.enable = false
kafka-1          | 	confluent.multitenant.parse.sni.host.name.enable = false
kafka-1          | 	confluent.network.health.manager.enabled = false
kafka-1          | 	confluent.network.health.manager.external.listener.name = EXTERNAL
kafka-1          | 	confluent.network.health.manager.externalconnectivitystartup.enabled = false
kafka-1          | 	confluent.network.health.manager.min.healthy.network.samples = 3
kafka-1          | 	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
kafka-1          | 	confluent.network.health.manager.mitigation.enabled = false
kafka-1          | 	confluent.network.health.manager.network.sample.window.size = 120
kafka-1          | 	confluent.network.health.manager.sample.duration.ms = 1000
kafka-1          | 	confluent.oauth.flat.networking.verification.enable = false
kafka-1          | 	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
kafka-1          | 	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1          | 	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
kafka-1          | 	confluent.offsets.topic.max.message.bytes = -1
kafka-1          | 	confluent.offsets.topic.placement.constraints = 
kafka-1          | 	confluent.omit.network.processor.metric.tag = false
kafka-1          | 	confluent.operator.managed = false
kafka-1          | 	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
kafka-1          | 	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
kafka-1          | 	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
kafka-1          | 	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
kafka-1          | 	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
kafka-1          | 	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
kafka-1          | 	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
kafka-1          | 	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.enable = false
kafka-1          | 	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.cloud = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.domain = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.region = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variables = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.templates = 
kafka-1          | 	confluent.prefer.tier.fetch.ms = -1
kafka-1          | 	confluent.produce.throttle.pre.check.enable = false
kafka-1          | 	confluent.produce.throttle.pre.check.for.new.connection.enable = false
kafka-1          | 	confluent.producer.id.cache.broker.hard.limit = -1
kafka-1          | 	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
kafka-1          | 	confluent.producer.id.cache.extra.eviction.percentage = 0
kafka-1          | 	confluent.producer.id.cache.limit = 2147483647
kafka-1          | 	confluent.producer.id.cache.partition.hard.limit = -1
kafka-1          | 	confluent.producer.id.cache.tenant.hard.limit = -1
kafka-1          | 	confluent.producer.id.quota.manager.enable = false
kafka-1          | 	confluent.producer.id.quota.window.num = 11
kafka-1          | 	confluent.producer.id.quota.window.size.seconds = 1
kafka-1          | 	confluent.producer.id.throttle.enable = false
kafka-1          | 	confluent.producer.id.throttle.enable.threshold.percentage = 100
kafka-1          | 	confluent.protocol.netty.http2.connection.window.size = 31457280
kafka-1          | 	confluent.protocol.netty.http2.flow.control.enabled = true
kafka-1          | 	confluent.protocol.netty.http2.initial.window.size = 153600
kafka-1          | 	confluent.protocol.netty.http2.max.frame.size = 16384
kafka-1          | 	confluent.protocol.netty.http2.stream.graceful.close.timeout.ms = 60000
kafka-1          | 	confluent.protocol.netty.num.boss.threads = 1
kafka-1          | 	confluent.protocol.netty.num.worker.threads = 4
kafka-1          | 	confluent.proxy.mode.local.default = false
kafka-1          | 	confluent.proxy.protocol.fallback.enabled = false
kafka-1          | 	confluent.proxy.protocol.parser = class io.confluent.kafka.common.network.CloudProxyTlvParser
kafka-1          | 	confluent.proxy.protocol.version = NONE
kafka-1          | 	confluent.quota.computing.usage.adjustment = 0.5
kafka-1          | 	confluent.quota.dynamic.adjustment.min.usage = 102400
kafka-1          | 	confluent.quota.dynamic.enable = false
kafka-1          | 	confluent.quota.dynamic.publishing.interval.ms = 60000
kafka-1          | 	confluent.quota.dynamic.reporting.interval.ms = 30000
kafka-1          | 	confluent.quota.tenant.broker.max.consumer.rate = 13107200
kafka-1          | 	confluent.quota.tenant.broker.max.producer.rate = 13107200
kafka-1          | 	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
kafka-1          | 	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
kafka-1          | 	confluent.quota.tenant.fetch.multiplier = 1.0
kafka-1          | 	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
kafka-1          | 	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
kafka-1          | 	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.broker.max.controller.mutation.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.throttling.enable = false
kafka-1          | 	confluent.quota.tenant.produce.multiplier = 1.0
kafka-1          | 	confluent.quota.tenant.user.quotas.enable = false
kafka-1          | 	confluent.rack.id.mapping = null
kafka-1          | 	confluent.regional.metadata.client.class = null
kafka-1          | 	confluent.regional.resource.manager.client.scheduler.threads = 2
kafka-1          | 	confluent.regional.resource.manager.endpoint = null
kafka-1          | 	confluent.regional.resource.manager.grpc.endpoint = null
kafka-1          | 	confluent.reject.invalid.sni.hostnames = false
kafka-1          | 	confluent.replica.fetch.backoff.max.ms = 1000
kafka-1          | 	confluent.replica.fetch.connections.mode = combined
kafka-1          | 	confluent.replication.mode = PULL
kafka-1          | 	confluent.replication.push.feature.enable = false
kafka-1          | 	confluent.reporters.telemetry.auto.enable = false
kafka-1          | 	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
kafka-1          | 	confluent.request.pipelining.enable = true
kafka-1          | 	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
kafka-1          | 	confluent.require.calling.resource.identity = false
kafka-1          | 	confluent.require.compatible.keystore.updates = true
kafka-1          | 	confluent.require.confluent.issuer = false
kafka-1          | 	confluent.roll.check.interval.ms = 300000
kafka-1          | 	confluent.schema.registry.max.cache.size = 10000
kafka-1          | 	confluent.schema.registry.max.retries = 1
kafka-1          | 	confluent.schema.registry.retries.wait.ms = 0
kafka-1          | 	confluent.schema.registry.url = null
kafka-1          | 	confluent.schema.validation.context.name.enable = false
kafka-1          | 	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
kafka-1          | 	confluent.schema.validator.multitenant.enable = false
kafka-1          | 	confluent.schema.validator.samples.per.min = 0
kafka-1          | 	confluent.security.bc.approved.mode.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.authorization.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
kafka-1          | 	confluent.security.event.logger.enable = true
kafka-1          | 	confluent.security.event.logger.kafka.request.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.physical.cluster.id = 
kafka-1          | 	confluent.security.event.router.config = 
kafka-1          | 	confluent.security.revoked.certificate.ids = 
kafka-1          | 	confluent.segment.eager.roll.enable = false
kafka-1          | 	confluent.segment.speculative.prefetch.enable = false
kafka-1          | 	confluent.share.coordinator.slow.event.log.count = 10
kafka-1          | 	confluent.share.coordinator.slow.event.log.interval.ms = -1
kafka-1          | 	confluent.share.metadata.load.threads = 32
kafka-1          | 	confluent.spiffe.id.principal.extraction.rules = 
kafka-1          | 	confluent.ssl.key.password = null
kafka-1          | 	confluent.ssl.keystore.location = null
kafka-1          | 	confluent.ssl.keystore.password = null
kafka-1          | 	confluent.ssl.keystore.type = null
kafka-1          | 	confluent.ssl.protocol = null
kafka-1          | 	confluent.ssl.truststore.location = null
kafka-1          | 	confluent.ssl.truststore.password = null
kafka-1          | 	confluent.ssl.truststore.type = null
kafka-1          | 	confluent.step.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.step.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.storage.probe.disk.metrics.collection.enabled = false
kafka-1          | 	confluent.storage.probe.period.ms = -1
kafka-1          | 	confluent.storage.probe.slow.write.threshold.ms = 5000
kafka-1          | 	confluent.stray.log.delete.delay.ms = 604800000
kafka-1          | 	confluent.stray.log.max.deletions.per.run = 72
kafka-1          | 	confluent.subdomain.prefix = null
kafka-1          | 	confluent.subdomain.separator.map = null
kafka-1          | 	confluent.subdomain.separator.variable = %sep
kafka-1          | 	confluent.system.time.roll.enable = false
kafka-1          | 	confluent.telemetry.enabled = false
kafka-1          | 	confluent.telemetry.external.client.metrics.delta.temporality = true
kafka-1          | 	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
kafka-1          | 	confluent.telemetry.external.client.metrics.push.enabled = false
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.match.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.supported.compression.types = [zstd, lz4, gzip, snappy]
kafka-1          | 	confluent.tenant.latency.metric.enabled = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.enable = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.proactive.key.generation.enable = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
kafka-1          | 	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
kafka-1          | 	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
kafka-1          | 	confluent.tier.archiver.num.threads = 2
kafka-1          | 	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
kafka-1          | 	confluent.tier.azure.block.blob.container = null
kafka-1          | 	confluent.tier.azure.block.blob.cred.file.path = null
kafka-1          | 	confluent.tier.azure.block.blob.endpoint = null
kafka-1          | 	confluent.tier.azure.block.blob.prefix = 
kafka-1          | 	confluent.tier.backend = 
kafka-1          | 	confluent.tier.bucket.probe.period.ms = -1
kafka-1          | 	confluent.tier.cleaner.compact.min.efficiency = 0.5
kafka-1          | 	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
kafka-1          | 	confluent.tier.cleaner.dedupe.buffer.size = 134217728
kafka-1          | 	confluent.tier.cleaner.dual.compaction = false
kafka-1          | 	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
kafka-1          | 	confluent.tier.cleaner.dual.compaction.validation.percent = 0
kafka-1          | 	confluent.tier.cleaner.enable = false
kafka-1          | 	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
kafka-1          | 	confluent.tier.cleaner.feature.enable = false
kafka-1          | 	confluent.tier.cleaner.io.buffer.load.factor = 0.9
kafka-1          | 	confluent.tier.cleaner.io.buffer.size = 10485760
kafka-1          | 	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1          | 	confluent.tier.cleaner.min.cleanable.ratio = 0.75
kafka-1          | 	confluent.tier.cleaner.num.threads = 2
kafka-1          | 	confluent.tier.enable = false
kafka-1          | 	confluent.tier.feature = false
kafka-1          | 	confluent.tier.fenced.segment.delete.delay.ms = 600000
kafka-1          | 	confluent.tier.fetcher.async.enable = false
kafka-1          | 	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
kafka-1          | 	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
kafka-1          | 	confluent.tier.fetcher.memorypool.bytes = 0
kafka-1          | 	confluent.tier.fetcher.num.threads = 4
kafka-1          | 	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
kafka-1          | 	confluent.tier.fetcher.offset.cache.period.ms = 60000
kafka-1          | 	confluent.tier.fetcher.offset.cache.size = 200000
kafka-1          | 	confluent.tier.gcs.bucket = null
kafka-1          | 	confluent.tier.gcs.cred.file.path = null
kafka-1          | 	confluent.tier.gcs.prefix = 
kafka-1          | 	confluent.tier.gcs.region = null
kafka-1          | 	confluent.tier.gcs.sse.customer.encryption.key = null
kafka-1          | 	confluent.tier.gcs.write.chunk.size = 0
kafka-1          | 	confluent.tier.local.hotset.bytes = -1
kafka-1          | 	confluent.tier.local.hotset.ms = 86400000
kafka-1          | 	confluent.tier.max.partition.fetch.bytes.override = 0
kafka-1          | 	confluent.tier.metadata.bootstrap.servers = null
kafka-1          | 	confluent.tier.metadata.catchup.max.poll.ms = 0
kafka-1          | 	confluent.tier.metadata.max.poll.ms = 100
kafka-1          | 	confluent.tier.metadata.namespace = null
kafka-1          | 	confluent.tier.metadata.num.partitions = 50
kafka-1          | 	confluent.tier.metadata.replication.factor = 3
kafka-1          | 	confluent.tier.metadata.request.timeout.ms = 30000
kafka-1          | 	confluent.tier.metadata.snapshots.enable = false
kafka-1          | 	confluent.tier.metadata.snapshots.interval.ms = 86400000
kafka-1          | 	confluent.tier.metadata.snapshots.retention.days = 7
kafka-1          | 	confluent.tier.metadata.snapshots.threads = 2
kafka-1          | 	confluent.tier.object.fetcher.num.threads = 1
kafka-1          | 	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
kafka-1          | 	confluent.tier.partition.state.cleanup.enable = false
kafka-1          | 	confluent.tier.partition.state.cleanup.interval.ms = 86400000
kafka-1          | 	confluent.tier.partition.state.commit.interval.ms = 15000
kafka-1          | 	confluent.tier.prefetch.cache.enable = false
kafka-1          | 	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
kafka-1          | 	confluent.tier.prefetch.cache.range.bytes = 5242880
kafka-1          | 	confluent.tier.prefetch.cache.total.size.bytes = 209715200
kafka-1          | 	confluent.tier.s3.assumerole.arn = null
kafka-1          | 	confluent.tier.s3.auto.abort.threshold.bytes = 500000
kafka-1          | 	confluent.tier.s3.aws.endpoint.override = null
kafka-1          | 	confluent.tier.s3.aws.signer.override = null
kafka-1          | 	confluent.tier.s3.bucket = null
kafka-1          | 	confluent.tier.s3.cred.file.path = null
kafka-1          | 	confluent.tier.s3.force.path.style.access = false
kafka-1          | 	confluent.tier.s3.ipv6.enabled = true
kafka-1          | 	confluent.tier.s3.prefix = 
kafka-1          | 	confluent.tier.s3.region = null
kafka-1          | 	confluent.tier.s3.security.providers = null
kafka-1          | 	confluent.tier.s3.sse.algorithm = AES256
kafka-1          | 	confluent.tier.s3.sse.customer.encryption.key = null
kafka-1          | 	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	confluent.tier.s3.ssl.key.password = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.location = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.password = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.type = null
kafka-1          | 	confluent.tier.s3.ssl.protocol = TLSv1.3
kafka-1          | 	confluent.tier.s3.ssl.provider = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.location = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.password = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.type = null
kafka-1          | 	confluent.tier.s3.storage.class.override = 
kafka-1          | 	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
kafka-1          | 	confluent.tier.s3.v2.enabled = false
kafka-1          | 	confluent.tier.segment.hotset.roll.min.bytes = 104857600
kafka-1          | 	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
kafka-1          | 	confluent.tier.topic.data.loss.validation.fencing.enable = false
kafka-1          | 	confluent.tier.topic.delete.backoff.ms = 21600000
kafka-1          | 	confluent.tier.topic.delete.check.interval.ms = 300000
kafka-1          | 	confluent.tier.topic.delete.max.inprogress.partitions = 100
kafka-1          | 	confluent.tier.topic.head.data.loss.validation.enable = true
kafka-1          | 	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
kafka-1          | 	confluent.tier.topic.materialization.from.snapshot.enable = false
kafka-1          | 	confluent.tier.topic.producer.enable.idempotence = true
kafka-1          | 	confluent.tier.topic.snapshots.enable = false
kafka-1          | 	confluent.tier.topic.snapshots.interval.ms = 300000
kafka-1          | 	confluent.tier.topic.snapshots.max.records = 100000
kafka-1          | 	confluent.tier.topic.snapshots.retention.hours = 168
kafka-1          | 	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
kafka-1          | 	confluent.topic.partition.default.placement = 2
kafka-1          | 	confluent.topic.policy.use.computed.assignments = false
kafka-1          | 	confluent.topic.replica.assignor.builder.class = 
kafka-1          | 	confluent.track.api.key.per.ip = false
kafka-1          | 	confluent.track.per.ip.max.size = 100000
kafka-1          | 	confluent.track.tenant.id.per.ip = false
kafka-1          | 	confluent.traffic.cdc.network.id.routes.enable = false
kafka-1          | 	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
kafka-1          | 	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
kafka-1          | 	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
kafka-1          | 	confluent.traffic.network.id = 
kafka-1          | 	confluent.traffic.network.type = 
kafka-1          | 	confluent.transaction.2pc.timeout.ms = -1
kafka-1          | 	confluent.transaction.logging.verbosity = 0
kafka-1          | 	confluent.transaction.state.log.placement.constraints = 
kafka-1          | 	confluent.unique.deprecated.request.metrics.per.tenant = 1000
kafka-1          | 	confluent.valid.broker.rack.set = null
kafka-1          | 	confluent.valid.sni.hostnames = 
kafka-1          | 	confluent.valid.sni.hostnames.exclude.suffix = 
kafka-1          | 	confluent.verify.group.subscription.prefix = false
kafka-1          | 	confluent.virtual.topic.creation.enabled = false
kafka-1          | 	confluent.zone.tagged.request.metrics.enable = false
kafka-1          | 	connection.failed.authentication.delay.ms = 100
kafka-1          | 	connection.min.expire.interval.ms = 250
kafka-1          | 	connections.max.age.ms = 3153600000000
kafka-1          | 	connections.max.idle.ms = 600000
kafka-1          | 	connections.max.reauth.ms = 0
kafka-1          | 	controlled.shutdown.enable = true
kafka-1          | 	controller.listener.names = CONTROLLER
kafka-1          | 	controller.performance.always.log.threshold.ms = 2000
kafka-1          | 	controller.performance.sample.period.ms = 60000
kafka-1          | 	controller.quorum.append.linger.ms = 25
kafka-1          | 	controller.quorum.bootstrap.servers = []
kafka-1          | 	controller.quorum.election.backoff.max.ms = 1000
kafka-1          | 	controller.quorum.election.timeout.ms = 1000
kafka-1          | 	controller.quorum.fetch.timeout.ms = 2000
kafka-1          | 	controller.quorum.request.timeout.ms = 2000
kafka-1          | 	controller.quorum.retry.backoff.ms = 20
kafka-1          | 	controller.quorum.voters = [1@controller-1:19091]
kafka-1          | 	controller.quota.window.num = 11
kafka-1          | 	controller.quota.window.size.seconds = 1
kafka-1          | 	controller.socket.timeout.ms = 30000
kafka-1          | 	create.cluster.link.policy.class.name = null
kafka-1          | 	create.topic.policy.class.name = null
kafka-1          | 	default.replication.factor = 1
kafka-1          | 	delegation.token.expiry.check.interval.ms = 3600000
kafka-1          | 	delegation.token.expiry.time.ms = 86400000
kafka-1          | 	delegation.token.max.lifetime.ms = 604800000
kafka-1          | 	delegation.token.secret.key = null
kafka-1          | 	delete.records.purgatory.purge.interval.requests = 1
kafka-1          | 	delete.topic.enable = true
kafka-1          | 	early.start.listeners = null
kafka-1          | 	enable.fips = false
kafka-1          | 	fetch.max.bytes = 57671680
kafka-1          | 	fetch.purgatory.purge.interval.requests = 1000
kafka-1          | 	floor.max.connection.creation.rate = null
kafka-1          | 	follower.replication.throttled.rate = 9223372036854775807
kafka-1          | 	follower.replication.throttled.replicas = none
kafka-1          | 	group.consumer.assignors = [uniform, range]
kafka-1          | 	group.consumer.heartbeat.interval.ms = 5000
kafka-1          | 	group.consumer.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.consumer.max.session.timeout.ms = 60000
kafka-1          | 	group.consumer.max.size = 2147483647
kafka-1          | 	group.consumer.migration.policy = bidirectional
kafka-1          | 	group.consumer.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.consumer.min.session.timeout.ms = 45000
kafka-1          | 	group.consumer.regex.refresh.interval.ms = 600000
kafka-1          | 	group.consumer.session.timeout.ms = 45000
kafka-1          | 	group.coordinator.append.linger.ms = 5
kafka-1          | 	group.coordinator.rebalance.protocols = [classic, consumer, share, streams]
kafka-1          | 	group.coordinator.threads = 4
kafka-1          | 	group.initial.rebalance.delay.ms = 0
kafka-1          | 	group.max.session.timeout.ms = 1800000
kafka-1          | 	group.max.size = 2147483647
kafka-1          | 	group.min.session.timeout.ms = 6000
kafka-1          | 	group.share.assignors = [simple]
kafka-1          | 	group.share.delivery.count.limit = 5
kafka-1          | 	group.share.enable = false
kafka-1          | 	group.share.heartbeat.interval.ms = 5000
kafka-1          | 	group.share.initialize.retry.interval.ms = 30000
kafka-1          | 	group.share.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.share.max.record.lock.duration.ms = 60000
kafka-1          | 	group.share.max.session.timeout.ms = 60000
kafka-1          | 	group.share.max.share.sessions = 2000
kafka-1          | 	group.share.max.size = 200
kafka-1          | 	group.share.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.share.min.record.lock.duration.ms = 15000
kafka-1          | 	group.share.min.session.timeout.ms = 45000
kafka-1          | 	group.share.partition.max.record.locks = 2000
kafka-1          | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafka-1          | 	group.share.record.lock.duration.ms = 30000
kafka-1          | 	group.share.rollout.ready = true
kafka-1          | 	group.share.session.timeout.ms = 45000
kafka-1          | 	group.streams.heartbeat.interval.ms = 5000
kafka-1          | 	group.streams.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.streams.max.session.timeout.ms = 60000
kafka-1          | 	group.streams.max.size = 2147483647
kafka-1          | 	group.streams.max.standby.replicas = 2
kafka-1          | 	group.streams.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.streams.min.session.timeout.ms = 45000
kafka-1          | 	group.streams.num.standby.replicas = 0
kafka-1          | 	group.streams.session.timeout.ms = 45000
kafka-1          | 	initial.broker.registration.timeout.ms = 60000
kafka-1          | 	inter.broker.listener.name = PLAINTEXT
kafka-1          | 	internal.metadata.delete.delay.millis = 60000
kafka-1          | 	internal.metadata.log.segment.bytes = null
kafka-1          | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafka-1          | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafka-1          | 	k2.stack.builder.class.name = null
kafka-1          | 	k2.startup.timeout.ms = 60000
kafka-1          | 	k2.topic.metadata.refresh.ms = 10000
kafka-1          | 	kafka.metrics.polling.interval.secs = 10
kafka-1          | 	kafka.metrics.reporters = []
kafka-1          | 	leader.imbalance.check.interval.seconds = 300
kafka-1          | 	leader.replication.throttled.rate = 9223372036854775807
kafka-1          | 	leader.replication.throttled.replicas = none
kafka-1          | 	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
kafka-1          | 	listeners = PLAINTEXT://kafka-1:19092, EXTERNAL://0.0.0.0:9091
kafka-1          | 	log.cleaner.backoff.ms = 15000
kafka-1          | 	log.cleaner.dedupe.buffer.size = 134217728
kafka-1          | 	log.cleaner.delete.retention.ms = 86400000
kafka-1          | 	log.cleaner.enable = true
kafka-1          | 	log.cleaner.hash.algorithm = MD5
kafka-1          | 	log.cleaner.io.buffer.load.factor = 0.9
kafka-1          | 	log.cleaner.io.buffer.size = 524288
kafka-1          | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1          | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1          | 	log.cleaner.min.cleanable.ratio = 0.5
kafka-1          | 	log.cleaner.min.compaction.lag.ms = 0
kafka-1          | 	log.cleaner.threads = 1
kafka-1          | 	log.cleanup.policy = [delete]
kafka-1          | 	log.cleanup.policy.empty.validation = none
kafka-1          | 	log.deletion.max.segments.per.run = 2147483647
kafka-1          | 	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
kafka-1          | 	log.dir = /tmp/kafka-logs
kafka-1          | 	log.dir.failure.timeout.ms = 30000
kafka-1          | 	log.dirs = /var/lib/kafka/data
kafka-1          | 	log.flush.interval.messages = 9223372036854775807
kafka-1          | 	log.flush.interval.ms = null
kafka-1          | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka-1          | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka-1          | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka-1          | 	log.index.interval.bytes = 4096
kafka-1          | 	log.index.size.max.bytes = 10485760
kafka-1          | 	log.initial.task.delay.ms = 30000
kafka-1          | 	log.local.retention.bytes = -2
kafka-1          | 	log.local.retention.ms = -2
kafka-1          | 	log.message.timestamp.after.max.ms = 3600000
kafka-1          | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafka-1          | 	log.message.timestamp.type = CreateTime
kafka-1          | 	log.preallocate = false
kafka-1          | 	log.retention.bytes = -1
kafka-1          | 	log.retention.check.interval.ms = 300000
kafka-1          | 	log.retention.hours = 168
kafka-1          | 	log.retention.minutes = null
kafka-1          | 	log.retention.ms = null
kafka-1          | 	log.roll.hours = 168
kafka-1          | 	log.roll.jitter.hours = 0
kafka-1          | 	log.roll.jitter.ms = null
kafka-1          | 	log.roll.ms = null
kafka-1          | 	log.segment.bytes = 1073741824
kafka-1          | 	log.segment.delete.delay.ms = 60000
kafka-1          | 	max.connection.creation.rate = 1.7976931348623157E308
kafka-1          | 	max.connection.creation.rate.per.ip.enable.threshold = 0.0
kafka-1          | 	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
kafka-1          | 	max.connections = 2147483647
kafka-1          | 	max.connections.per.ip = 2147483647
kafka-1          | 	max.connections.per.ip.overrides = 
kafka-1          | 	max.connections.per.tenant = 0
kafka-1          | 	max.connections.protected.listeners = []
kafka-1          | 	max.connections.reap.amount = 0
kafka-1          | 	max.incremental.fetch.session.cache.slots = 1000
kafka-1          | 	max.request.partition.size.limit = 2000
kafka-1          | 	message.max.bytes = 1048588
kafka-1          | 	metadata.log.dir = null
kafka-1          | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafka-1          | 	metadata.log.max.snapshot.interval.ms = 3600000
kafka-1          | 	metadata.log.segment.bytes = 1073741824
kafka-1          | 	metadata.log.segment.ms = 604800000
kafka-1          | 	metadata.max.idle.interval.ms = 500
kafka-1          | 	metadata.max.retention.bytes = 104857600
kafka-1          | 	metadata.max.retention.ms = 604800000
kafka-1          | 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	min.insync.replicas = 1
kafka-1          | 	multitenant.authorizer.support.resource.ids = false
kafka-1          | 	multitenant.metadata.class = null
kafka-1          | 	multitenant.metadata.dir = null
kafka-1          | 	multitenant.metadata.reload.delay.ms = 120000
kafka-1          | 	multitenant.metadata.ssl.certs.path = null
kafka-1          | 	multitenant.tenant.delete.batch.size = 10
kafka-1          | 	multitenant.tenant.delete.check.ms = 120000
kafka-1          | 	multitenant.tenant.delete.delay = 604800000
kafka-1          | 	node.id = 2
kafka-1          | 	num.io.threads = 8
kafka-1          | 	num.network.threads = 3
kafka-1          | 	num.partitions = 1
kafka-1          | 	num.recovery.threads.per.data.dir = 2
kafka-1          | 	num.replica.alter.log.dirs.threads = null
kafka-1          | 	num.replica.fetchers = 1
kafka-1          | 	offset.metadata.max.bytes = 4096
kafka-1          | 	offsets.commit.timeout.ms = 5000
kafka-1          | 	offsets.load.buffer.size = 5242880
kafka-1          | 	offsets.retention.check.interval.ms = 600000
kafka-1          | 	offsets.retention.minutes = 10080
kafka-1          | 	offsets.topic.compression.codec = 0
kafka-1          | 	offsets.topic.num.partitions = 50
kafka-1          | 	offsets.topic.replication.factor = 3
kafka-1          | 	offsets.topic.segment.bytes = 104857600
kafka-1          | 	otel.exporter.otlp.custom.endpoint = default
kafka-1          | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka-1          | 	process.roles = [broker]
kafka-1          | 	producer.id.expiration.check.interval.ms = 600000
kafka-1          | 	producer.id.expiration.ms = 86400000
kafka-1          | 	producer.purgatory.purge.interval.requests = 1000
kafka-1          | 	queued.max.request.bytes = -1
kafka-1          | 	queued.max.requests = 500
kafka-1          | 	quota.window.num = 11
kafka-1          | 	quota.window.size.seconds = 1
kafka-1          | 	quotas.consumption.expiration.time.ms = 600000
kafka-1          | 	quotas.expiration.interval.ms = 3600000
kafka-1          | 	quotas.expiration.time.ms = 604800000
kafka-1          | 	quotas.lazy.evaluation.threshold = 0.5
kafka-1          | 	quotas.topic.append.timeout.ms = 5000
kafka-1          | 	quotas.topic.compression.codec = 3
kafka-1          | 	quotas.topic.load.buffer.size = 5242880
kafka-1          | 	quotas.topic.num.partitions = 50
kafka-1          | 	quotas.topic.placement.constraints = 
kafka-1          | 	quotas.topic.replication.factor = 3
kafka-1          | 	quotas.topic.segment.bytes = 104857600
kafka-1          | 	remote.fetch.max.wait.ms = 500
kafka-1          | 	remote.list.offsets.request.timeout.ms = 30000
kafka-1          | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafka-1          | 	remote.log.manager.copier.thread.pool.size = 10
kafka-1          | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafka-1          | 	remote.log.manager.copy.quota.window.num = 11
kafka-1          | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafka-1          | 	remote.log.manager.expiration.thread.pool.size = 10
kafka-1          | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafka-1          | 	remote.log.manager.fetch.quota.window.num = 11
kafka-1          | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafka-1          | 	remote.log.manager.task.interval.ms = 30000
kafka-1          | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafka-1          | 	remote.log.manager.task.retry.backoff.ms = 500
kafka-1          | 	remote.log.manager.task.retry.jitter = 0.2
kafka-1          | 	remote.log.manager.thread.pool.size = 2
kafka-1          | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafka-1          | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafka-1          | 	remote.log.metadata.manager.class.path = null
kafka-1          | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafka-1          | 	remote.log.metadata.manager.listener.name = null
kafka-1          | 	remote.log.reader.max.pending.tasks = 100
kafka-1          | 	remote.log.reader.threads = 10
kafka-1          | 	remote.log.storage.manager.class.name = null
kafka-1          | 	remote.log.storage.manager.class.path = null
kafka-1          | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafka-1          | 	remote.log.storage.system.enable = false
kafka-1          | 	replica.fetch.backoff.ms = 1000
kafka-1          | 	replica.fetch.max.bytes = 1048576
kafka-1          | 	replica.fetch.min.bytes = 1
kafka-1          | 	replica.fetch.response.max.bytes = 10485760
kafka-1          | 	replica.fetch.wait.max.ms = 500
kafka-1          | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka-1          | 	replica.lag.time.max.ms = 30000
kafka-1          | 	replica.selector.class = null
kafka-1          | 	replica.socket.receive.buffer.bytes = 65536
kafka-1          | 	replica.socket.timeout.ms = 30000
kafka-1          | 	replication.quota.window.num = 11
kafka-1          | 	replication.quota.window.size.seconds = 1
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.enabled.mechanisms = [GSSAPI]
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism.controller.protocol = GSSAPI
kafka-1          | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	sasl.server.authn.async.enable = false
kafka-1          | 	sasl.server.authn.async.max.threads = 1
kafka-1          | 	sasl.server.authn.async.timeout.ms = 30000
kafka-1          | 	sasl.server.callback.handler.class = null
kafka-1          | 	sasl.server.max.receive.size = 524288
kafka-1          | 	security.inter.broker.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	server.max.startup.time.ms = 9223372036854775807
kafka-1          | 	share.coordinator.append.linger.ms = 5
kafka-1          | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafka-1          | 	share.coordinator.load.buffer.size = 5242880
kafka-1          | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafka-1          | 	share.coordinator.state.topic.compression.codec = 0
kafka-1          | 	share.coordinator.state.topic.min.isr = 2
kafka-1          | 	share.coordinator.state.topic.num.partitions = 50
kafka-1          | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafka-1          | 	share.coordinator.state.topic.replication.factor = 3
kafka-1          | 	share.coordinator.state.topic.segment.bytes = 104857600
kafka-1          | 	share.coordinator.threads = 1
kafka-1          | 	share.coordinator.write.timeout.ms = 5000
kafka-1          | 	share.fetch.purgatory.purge.interval.requests = 1000
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	socket.listen.backlog.size = 50
kafka-1          | 	socket.receive.buffer.bytes = 102400
kafka-1          | 	socket.request.max.bytes = 104857600
kafka-1          | 	socket.send.buffer.bytes = 102400
kafka-1          | 	ssl.allow.dn.changes = false
kafka-1          | 	ssl.allow.san.changes = false
kafka-1          | 	ssl.cipher.suites = []
kafka-1          | 	ssl.client.auth = none
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.principal.mapping.rules = DEFAULT
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	telemetry.max.bytes = 1048576
kafka-1          | 	throughput.quota.window.num = 11
kafka-1          | 	token.impersonation.validation = true
kafka-1          | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka-1          | 	transaction.max.timeout.ms = 900000
kafka-1          | 	transaction.metadata.load.threads = 32
kafka-1          | 	transaction.partition.verification.enable = true
kafka-1          | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka-1          | 	transaction.state.log.load.buffer.size = 5242880
kafka-1          | 	transaction.state.log.min.isr = 2
kafka-1          | 	transaction.state.log.num.partitions = 50
kafka-1          | 	transaction.state.log.replication.factor = 3
kafka-1          | 	transaction.state.log.segment.bytes = 104857600
kafka-1          | 	transaction.two.phase.commit.enable = false
kafka-1          | 	transactional.id.expiration.ms = 604800000
kafka-1          | 	unclean.leader.election.enable = false
kafka-1          | 	unclean.leader.election.interval.ms = 300000
kafka-1          | 	unstable.api.versions.enable = false
kafka-1          | 	unstable.feature.versions.enable = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:57,937] INFO Registering metric ActiveBalancerCount (io.confluent.databalancer.KafkaDataBalanceManager)
kafka-1          | [2025-11-13 18:47:57,957] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafka-1          | [2025-11-13 18:47:57,964] INFO [BrokerServer id=2] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:47:57,964] INFO [BrokerServer id=2] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:47:57,986] INFO [SharedServer id=2] Starting SharedServer (kafka.server.SharedServer)
kafka-1          | [2025-11-13 18:47:57,986] INFO [SharedServer id=2] Starting SharedServer (kafka.server.SharedServer)
controller-1     | [2025-11-13 18:47:58,022] INFO Instantiating ClusterBalanceManager with an instance of io.confluent.databalancer.SbcDataBalanceManager (ClusterBalanceManager)
controller-1     | [2025-11-13 18:47:58,029] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
controller-1     | [2025-11-13 18:47:58,033] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:58,033] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:58,048] INFO [ControllerServer id=1] FIPS mode enabled: false (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:58,048] INFO [ControllerServer id=1] FIPS mode enabled: false (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:58,086] INFO AuditLogConfig values: 
controller-1     | 	confluent.security.event.logger.authentication.enable = false
controller-1     | 	confluent.security.event.logger.authentication.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.authorization.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.cloudevent.codec = structured
controller-1     | 	confluent.security.event.logger.enable = true
controller-1     | 	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.create = true
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
controller-1     | 	confluent.security.event.logger.kafka.request.rate.limit = -1
controller-1     | 	confluent.security.event.logger.physical.cluster.id = 
controller-1     | 	confluent.security.event.router.cache.entries = 10000
controller-1     | 	confluent.security.event.router.config = 
controller-1     | 	confluent.security.event.router.named.config.enabled = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,087] INFO CrnAuthorityConfig values: 
controller-1     | 	confluent.authorizer.authority.cache.entries = 10000
controller-1     | 	confluent.authorizer.authority.name = 
controller-1     | 	confluent.metadata.server.api.flavor = CP
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,091] INFO NamedConfigEnabled: false (io.confluent.security.audit.provider.ConfluentAuditLogProvider)
controller-1     | [2025-11-13 18:47:58,092] INFO AuditLogConfig values: 
controller-1     | 	confluent.security.event.logger.authentication.enable = false
controller-1     | 	confluent.security.event.logger.authentication.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.authorization.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.cloudevent.codec = structured
controller-1     | 	confluent.security.event.logger.enable = true
controller-1     | 	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.create = true
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
controller-1     | 	confluent.security.event.logger.kafka.request.rate.limit = -1
controller-1     | 	confluent.security.event.logger.physical.cluster.id = 
controller-1     | 	confluent.security.event.router.cache.entries = 10000
controller-1     | 	confluent.security.event.router.config = 
controller-1     | 	confluent.security.event.router.named.config.enabled = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,136] INFO CrnAuthorityConfig values: 
controller-1     | 	confluent.authorizer.authority.cache.entries = 10000
controller-1     | 	confluent.authorizer.authority.name = 
controller-1     | 	confluent.metadata.server.api.flavor = CP
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,138] INFO MultiTenantAuditLogConfig values: 
controller-1     | 	confluent.security.event.logger.client.ip.enable = false
controller-1     | 	confluent.security.event.logger.multitenant.enable = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,139] INFO AuditLogConfig values: 
controller-1     | 	confluent.security.event.logger.authentication.enable = false
controller-1     | 	confluent.security.event.logger.authentication.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.authorization.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.cloudevent.codec = structured
controller-1     | 	confluent.security.event.logger.enable = true
controller-1     | 	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.create = true
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
controller-1     | 	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
controller-1     | 	confluent.security.event.logger.kafka.request.rate.limit = -1
controller-1     | 	confluent.security.event.logger.physical.cluster.id = 
controller-1     | 	confluent.security.event.router.cache.entries = 10000
controller-1     | 	confluent.security.event.router.config = 
controller-1     | 	confluent.security.event.router.named.config.enabled = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,139] INFO Audit Log rate limiter reconfigured: Authn: -1, Authz: -1, Kafka request: -1 (io.confluent.security.audit.provider.AuditLogRateLimiter)
kafka-1          | [2025-11-13 18:47:58,282] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
kafka-1          | [2025-11-13 18:47:58,283] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
kafka-1          | [2025-11-13 18:47:58,283] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset $lastOffset (org.apache.kafka.storage.internals.log.MergedLogUtils)
kafka-1          | [2025-11-13 18:47:58,305] INFO Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
kafka-1          | [2025-11-13 18:47:58,305] INFO Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
kafka-1          | [2025-11-13 18:47:58,357] INFO [raft-expiration-reaper]: Starting (org.apache.kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
kafka-1          | [2025-11-13 18:47:58,389] INFO [RaftManager id=2] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
kafka-1          | [2025-11-13 18:47:58,395] INFO [RaftManager id=2] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=controller-1/172.23.0.3:19091}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
kafka-1          | [2025-11-13 18:47:58,405] INFO [RaftManager id=2] Starting request manager with static voters: [controller-1:19091 (id: 1 rack: null isFenced: false)] (org.apache.kafka.raft.KafkaRaftClient)
kafka-1          | [2025-11-13 18:47:58,414] INFO [RaftManager id=2] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1427, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
kafka-1          | [2025-11-13 18:47:58,456] INFO [RaftManager id=2] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1427, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
kafka-1          | [2025-11-13 18:47:58,468] INFO [kafka-2-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
kafka-1          | [2025-11-13 18:47:58,469] INFO [kafka-2-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
kafka-1          | [2025-11-13 18:47:58,515] INFO [RaftManager id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:47:58,516] WARN [RaftManager id=2] Connection to node 1 (controller-1/172.23.0.3:19091) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:47:58,556] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:58,559] INFO [BrokerServer id=2] Starting broker (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:47:58,559] INFO [RaftManager id=2] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1388627206 (org.apache.kafka.raft.KafkaRaftClient)
kafka-1          | [2025-11-13 18:47:58,559] INFO [BrokerServer id=2] Starting broker (kafka.server.BrokerServer)
controller-1     | [2025-11-13 18:47:58,569] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
controller-1     | [2025-11-13 18:47:58,569] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:47:58,600] INFO [BrokerServer id=2] FIPS mode enabled: false (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:47:58,600] INFO [BrokerServer id=2] FIPS mode enabled: false (kafka.server.BrokerServer)
controller-1     | [2025-11-13 18:47:58,622] INFO Quota CONTROLLER-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
controller-1     | [2025-11-13 18:47:58,622] INFO Quota CONTROLLER-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:58,628] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
controller-1     | [2025-11-13 18:47:58,628] INFO Quota CONTROLLER-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
controller-1     | [2025-11-13 18:47:58,628] INFO Quota CONTROLLER-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:58,630] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
controller-1     | [2025-11-13 18:47:58,631] INFO Quota CONTROLLER-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
controller-1     | [2025-11-13 18:47:58,631] INFO Quota CONTROLLER-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
controller-1     | [2025-11-13 18:47:58,638] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
controller-1     | [2025-11-13 18:47:58,638] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
kafka-1          | [2025-11-13 18:47:58,651] INFO [broker-2-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,651] INFO [broker-2-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,651] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
kafka-1          | [2025-11-13 18:47:58,655] INFO [broker-2-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,655] INFO [broker-2-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,657] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
kafka-1          | [2025-11-13 18:47:58,657] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:58,661] INFO [broker-2-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,661] INFO [broker-2-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,673] INFO [RaftManager id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:47:58,673] WARN [RaftManager id=2] Connection to node 1 (controller-1/172.23.0.3:19091) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:47:58,673] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
kafka-1          | [2025-11-13 18:47:58,673] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
kafka-1          | [2025-11-13 18:47:58,692] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
kafka-1          | [2025-11-13 18:47:58,694] INFO [broker-2-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,694] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
controller-1     | [2025-11-13 18:47:58,695] INFO Config values: 
controller-1     | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
controller-1     | 	confluent.security.event.logger.enable.detailed.audit.logs = false
controller-1     | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:58,694] INFO [broker-2-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,694] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
kafka-1          | [2025-11-13 18:47:58,708] INFO [broker-2-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,708] INFO [broker-2-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:58,715] INFO FlexFanout is not enabled or there is no ClientQuotaCallback so does not start FlexFanoutQuotaManager. (kafka.server.FlexFanoutQuotaManager)
kafka-1          | [2025-11-13 18:47:58,715] INFO FlexFanout is not enabled or there is no ClientQuotaCallback so does not start FlexFanoutQuotaManager. (kafka.server.FlexFanoutQuotaManager)
controller-1     | [2025-11-13 18:47:58,738] INFO Config values: 
controller-1     | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
controller-1     | 	confluent.security.event.logger.enable.detailed.audit.logs = false
controller-1     | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,748] INFO Config values: 
controller-1     | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
controller-1     | 	confluent.security.event.logger.enable.detailed.audit.logs = false
controller-1     | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,759] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) used TCP protocol (kafka.network.SocketServer)
controller-1     | [2025-11-13 18:47:58,759] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) used TCP protocol (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:47:58,759] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:58,772] INFO Skip DiskIOManager init: confluent.disk.io.manager.enable = false (kafka.server.resource.DiskIOManager)
kafka-1          | [2025-11-13 18:47:58,772] INFO Skip DiskIOManager init: confluent.disk.io.manager.enable = false (kafka.server.resource.DiskIOManager)
kafka-1          | [2025-11-13 18:47:58,783] INFO [RaftManager id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:47:58,783] WARN [RaftManager id=2] Connection to node 1 (controller-1/172.23.0.3:19091) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:47:58,790] INFO AuditLogConfig values: 
kafka-1          | 	confluent.security.event.logger.authentication.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.authorization.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.cloudevent.codec = structured
kafka-1          | 	confluent.security.event.logger.enable = true
kafka-1          | 	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.create = true
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
kafka-1          | 	confluent.security.event.logger.kafka.request.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.physical.cluster.id = 
kafka-1          | 	confluent.security.event.router.cache.entries = 10000
kafka-1          | 	confluent.security.event.router.config = 
kafka-1          | 	confluent.security.event.router.named.config.enabled = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:58,792] INFO CrnAuthorityConfig values: 
kafka-1          | 	confluent.authorizer.authority.cache.entries = 10000
kafka-1          | 	confluent.authorizer.authority.name = 
kafka-1          | 	confluent.metadata.server.api.flavor = CP
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:58,797] INFO NamedConfigEnabled: false (io.confluent.security.audit.provider.ConfluentAuditLogProvider)
kafka-1          | [2025-11-13 18:47:58,797] INFO AuditLogConfig values: 
kafka-1          | 	confluent.security.event.logger.authentication.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.authorization.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.cloudevent.codec = structured
kafka-1          | 	confluent.security.event.logger.enable = true
kafka-1          | 	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.create = true
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
kafka-1          | 	confluent.security.event.logger.kafka.request.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.physical.cluster.id = 
kafka-1          | 	confluent.security.event.router.cache.entries = 10000
kafka-1          | 	confluent.security.event.router.config = 
kafka-1          | 	confluent.security.event.router.named.config.enabled = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:58,800] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
controller-1     | [2025-11-13 18:47:58,800] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
kafka-1          | [2025-11-13 18:47:58,834] INFO CrnAuthorityConfig values: 
kafka-1          | 	confluent.authorizer.authority.cache.entries = 10000
kafka-1          | 	confluent.authorizer.authority.name = 
kafka-1          | 	confluent.metadata.server.api.flavor = CP
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:58,835] INFO MultiTenantAuditLogConfig values: 
kafka-1          | 	confluent.security.event.logger.client.ip.enable = false
kafka-1          | 	confluent.security.event.logger.multitenant.enable = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:58,837] INFO AuditLogConfig values: 
kafka-1          | 	confluent.security.event.logger.authentication.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.authorization.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.cloudevent.codec = structured
kafka-1          | 	confluent.security.event.logger.enable = true
kafka-1          | 	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.create = true
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
kafka-1          | 	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
kafka-1          | 	confluent.security.event.logger.kafka.request.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.physical.cluster.id = 
kafka-1          | 	confluent.security.event.router.cache.entries = 10000
kafka-1          | 	confluent.security.event.router.config = 
kafka-1          | 	confluent.security.event.router.named.config.enabled = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:58,837] INFO Audit Log rate limiter reconfigured: Authn: -1, Authz: -1, Kafka request: -1 (io.confluent.security.audit.provider.AuditLogRateLimiter)
kafka-1          | [2025-11-13 18:47:58,859] INFO [BrokerServer id=2] Waiting for controller quorum voters future (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:47:58,859] INFO [BrokerServer id=2] Waiting for controller quorum voters future (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:47:58,859] INFO [BrokerServer id=2] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:47:58,859] INFO [BrokerServer id=2] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:47:58,860] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:58,876] INFO [broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:58,876] INFO [broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:58,886] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafka-1          | [2025-11-13 18:47:58,961] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,006] INFO [RaftManager id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:47:59,006] WARN [RaftManager id=2] Connection to node 1 (controller-1/172.23.0.3:19091) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:47:59,057] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
controller-1     | [2025-11-13 18:47:59,057] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
controller-1     | [2025-11-13 18:47:59,058] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset $lastOffset (org.apache.kafka.storage.internals.log.MergedLogUtils)
kafka-1          | [2025-11-13 18:47:59,062] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,067] INFO [SocketServer listenerType=BROKER, nodeId=2] Creating data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:47:59,067] INFO [SocketServer listenerType=BROKER, nodeId=2] Creating data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
controller-1     | [2025-11-13 18:47:59,084] INFO Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
controller-1     | [2025-11-13 18:47:59,084] INFO Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
kafka-1          | [2025-11-13 18:47:59,101] INFO Quota PLAINTEXT-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,101] INFO Quota PLAINTEXT-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,105] INFO Quota PLAINTEXT-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,105] INFO Quota PLAINTEXT-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,107] INFO Quota PLAINTEXT-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,107] INFO Quota PLAINTEXT-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
controller-1     | [2025-11-13 18:47:59,111] INFO [raft-expiration-reaper]: Starting (org.apache.kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
kafka-1          | [2025-11-13 18:47:59,115] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
kafka-1          | [2025-11-13 18:47:59,115] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
controller-1     | [2025-11-13 18:47:59,142] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
controller-1     | [2025-11-13 18:47:59,151] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=controller-1/172.23.0.3:19091}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
controller-1     | [2025-11-13 18:47:59,160] INFO [RaftManager id=1] Starting request manager with static voters: [controller-1:19091 (id: 1 rack: null isFenced: false)] (org.apache.kafka.raft.KafkaRaftClient)
kafka-1          | [2025-11-13 18:47:59,162] INFO Config values: 
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
kafka-1          | 	confluent.security.event.logger.enable.detailed.audit.logs = false
kafka-1          | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,164] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,170] INFO [RaftManager id=1] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1406, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
kafka-1          | [2025-11-13 18:47:59,191] INFO Config values: 
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
kafka-1          | 	confluent.security.event.logger.enable.detailed.audit.logs = false
kafka-1          | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,200] INFO Config values: 
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
kafka-1          | 	confluent.security.event.logger.enable.detailed.audit.logs = false
kafka-1          | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,208] INFO [SocketServer listenerType=BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) used TCP protocol (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:47:59,208] INFO [SocketServer listenerType=BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) used TCP protocol (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:47:59,209] INFO [SocketServer listenerType=BROKER, nodeId=2] Creating data-plane acceptor and processors for endpoint : ListenerName(EXTERNAL) (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:47:59,209] INFO [SocketServer listenerType=BROKER, nodeId=2] Creating data-plane acceptor and processors for endpoint : ListenerName(EXTERNAL) (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:47:59,213] INFO Quota EXTERNAL-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,213] INFO Quota EXTERNAL-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,215] INFO Quota EXTERNAL-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,215] INFO Quota EXTERNAL-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,216] INFO Quota EXTERNAL-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,216] INFO Quota EXTERNAL-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
kafka-1          | [2025-11-13 18:47:59,216] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
kafka-1          | [2025-11-13 18:47:59,216] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
controller-1     | [2025-11-13 18:47:59,218] INFO [RaftManager id=1] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1406, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
kafka-1          | [2025-11-13 18:47:59,220] INFO Config values: 
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
kafka-1          | 	confluent.security.event.logger.enable.detailed.audit.logs = false
kafka-1          | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,229] INFO Config values: 
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
kafka-1          | 	confluent.security.event.logger.enable.detailed.audit.logs = false
kafka-1          | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,236] INFO [RaftManager id=1] Completed transition to ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1536, highWatermark=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1406, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafka-1          | [2025-11-13 18:47:59,235] INFO Config values: 
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.disabled.apis = 
kafka-1          | 	confluent.security.event.logger.enable.detailed.audit.logs = false
kafka-1          | 	confluent.security.event.logger.enable.produce.consume.audit.logs = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,240] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=oPBJuu4DCHMazUx1rv77zA, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1137) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1536, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafka-1          | [2025-11-13 18:47:59,243] INFO [SocketServer listenerType=BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(EXTERNAL) used TCP protocol (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:47:59,243] INFO [SocketServer listenerType=BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(EXTERNAL) used TCP protocol (kafka.network.SocketServer)
controller-1     | [2025-11-13 18:47:59,244] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=oPBJuu4DCHMazUx1rv77zA, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1137) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1536, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
controller-1     | [2025-11-13 18:47:59,256] INFO [RaftManager id=1] Attempting durable transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=oPBJuu4DCHMazUx1rv77zA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=controller-1/<unresolved>:19091}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=oPBJuu4DCHMazUx1rv77zA, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1137) (org.apache.kafka.raft.QuorumState)
controller-1     | [2025-11-13 18:47:59,260] INFO [RaftManager id=1] Completed transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=oPBJuu4DCHMazUx1rv77zA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=controller-1/<unresolved>:19091}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=oPBJuu4DCHMazUx1rv77zA, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1137) (org.apache.kafka.raft.QuorumState)
kafka-1          | [2025-11-13 18:47:59,261] INFO [broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:59,261] INFO [broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:59,265] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,284] INFO [broker-2-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:59,284] INFO [broker-2-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:59,296] INFO [BrokerHealthManager]: Starting (kafka.availability.BrokerHealthManager)
kafka-1          | [2025-11-13 18:47:59,296] INFO [BrokerHealthManager]: Starting (kafka.availability.BrokerHealthManager)
controller-1     | [2025-11-13 18:47:59,301] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
controller-1     | [2025-11-13 18:47:59,301] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
kafka-1          | [2025-11-13 18:47:59,337] INFO [ExpirationReaper-2-Produce]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1          | [2025-11-13 18:47:59,339] INFO [ExpirationReaper-2-Fetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1          | [2025-11-13 18:47:59,342] INFO [ExpirationReaper-2-DeleteRecords]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1          | [2025-11-13 18:47:59,344] INFO [ExpirationReaper-2-ShareFetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1          | [2025-11-13 18:47:59,347] INFO [ExpirationReaper-2-ListOffsets]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
controller-1     | [2025-11-13 18:47:59,356] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,360] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
controller-1     | [2025-11-13 18:47:59,364] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,364] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,364] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,364] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
kafka-1          | [2025-11-13 18:47:59,366] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,376] INFO ReplicationConfig values: 
kafka-1          | 	confluent.intelligent.replication.enable = false
kafka-1          | 	confluent.intelligent.replication.push.linger.ms = 0
kafka-1          | 	confluent.intelligent.replication.push.max.in.flight.requests = 1
kafka-1          | 	confluent.intelligent.replication.push.max.memory.buffer.bytes = 209715200
kafka-1          | 	confluent.intelligent.replication.push.max.threads = 4
kafka-1          | 	confluent.intelligent.replication.push.metadata.max.wait.ms = 500
kafka-1          | 	confluent.intelligent.replication.push.request.max.bytes = 52428800
kafka-1          | 	confluent.intelligent.replication.push.request.max.partition.bytes = 52428800
kafka-1          | 	confluent.intelligent.replication.push.request.timeout.ms = 5000
kafka-1          | 	confluent.intelligent.replication.push.retry.timeout.ms = 10000
kafka-1          | 	confluent.intelligent.replication.push.socket.buffer.bytes = 1048576
kafka-1          | 	confluent.intelligent.replication.push.threads.per.remote.broker = 1
kafka-1          | 	confluent.replication.push.internal.topics.enable = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,394] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@352768085 (org.apache.kafka.raft.KafkaRaftClient)
controller-1     | [2025-11-13 18:47:59,397] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@352768085 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
controller-1     | [2025-11-13 18:47:59,402] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,419] INFO [share-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafka-1          | [2025-11-13 18:47:59,423] INFO [RaftManager id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:47:59,423] WARN [RaftManager id=2] Connection to node 1 (controller-1/172.23.0.3:19091) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:47:59,457] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,467] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,479] INFO [share-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafka-1          | [2025-11-13 18:47:59,499] INFO [persister-state-manager-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafka-1          | [2025-11-13 18:47:59,503] INFO [PersisterStateManager]: Starting (org.apache.kafka.server.share.persister.PersisterStateManager$SendThread)
kafka-1          | [2025-11-13 18:47:59,506] INFO [group-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
controller-1     | [2025-11-13 18:47:59,515] INFO [ControllerServer id=1] Registering periodic task writeNoOpRecord to run every 500 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
controller-1     | [2025-11-13 18:47:59,517] INFO [ControllerServer id=1] Registering periodic task maybeFenceStaleBroker to run every 1125 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
controller-1     | [2025-11-13 18:47:59,518] INFO [ControllerServer id=1] Registering periodic task electUnclean to run every 300000 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
controller-1     | [2025-11-13 18:47:59,519] INFO [ControllerServer id=1] Registering periodic task expireDelegationTokens to run every 3600000 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
controller-1     | [2025-11-13 18:47:59,520] INFO [ControllerServer id=1] Registering periodic task generatePeriodicPerformanceMessage to run every 60000 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
controller-1     | [2025-11-13 18:47:59,524] INFO [ControllerServer id=1] Creating new QuorumController with clusterId Nk018hRAQFytWskYqtQduw (org.apache.kafka.controller.QuorumController)
controller-1     | [2025-11-13 18:47:59,525] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@1204544382 (org.apache.kafka.raft.KafkaRaftClient)
controller-1     | [2025-11-13 18:47:59,526] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@1204544382 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
controller-1     | [2025-11-13 18:47:59,533] INFO [ControllerServer id=1] [ConfluentKeyValueStreams id=1]finish configuring initial offsets, current offsets: {} (org.apache.kafka.controller.ConfluentKeyValueStreamsControlManager)
controller-1     | [2025-11-13 18:47:59,534] INFO [ControllerServer id=1] Becoming the active controller at epoch 1, next write offset 1. (org.apache.kafka.controller.QuorumController)
kafka-1          | [2025-11-13 18:47:59,542] INFO [group-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafka-1          | [2025-11-13 18:47:59,544] INFO [group-coordinator-event-processor-1]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafka-1          | [2025-11-13 18:47:59,545] INFO [group-coordinator-event-processor-3]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafka-1          | [2025-11-13 18:47:59,544] INFO [group-coordinator-event-processor-2]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
controller-1     | [2025-11-13 18:47:59,556] WARN [ControllerServer id=1] Performing controller activation. The metadata log appears to be empty. Appending 4 bootstrap record(s) in metadata transaction at metadata.version 4.1-IV1A from bootstrap source 'the binary bootstrap metadata file: /var/lib/kafka/data/bootstrap.checkpoint'. (org.apache.kafka.controller.QuorumController)
controller-1     | [2025-11-13 18:47:59,558] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,559] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
controller-1     | [2025-11-13 18:47:59,561] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
controller-1     | [2025-11-13 18:47:59,566] INFO [ControllerServer id=1] Replayed BeginTransactionRecord(name='Bootstrap records') at offset 1. (org.apache.kafka.controller.OffsetControlManager)
controller-1     | [2025-11-13 18:47:59,566] INFO [ControllerServer id=1] Replayed a Confluent FeatureLevelRecord setting metadata version to 4.1-IV1A (org.apache.kafka.controller.FeatureControlManager)
kafka-1          | [2025-11-13 18:47:59,569] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,569] INFO [ControllerServer id=1] Replayed a FeatureLevelRecord setting feature eligible.leader.replicas.version to 1 (org.apache.kafka.controller.FeatureControlManager)
controller-1     | [2025-11-13 18:47:59,570] INFO [ControllerServer id=1] Replayed a FeatureLevelRecord setting feature group.version to 1 (org.apache.kafka.controller.FeatureControlManager)
controller-1     | [2025-11-13 18:47:59,571] INFO [ControllerServer id=1] Replayed a FeatureLevelRecord setting feature transaction.version to 2 (org.apache.kafka.controller.FeatureControlManager)
controller-1     | [2025-11-13 18:47:59,572] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=BROKER, name='') which set configuration min.insync.replicas to 1 (org.apache.kafka.controller.ConfigurationControlManager)
controller-1     | [2025-11-13 18:47:59,572] INFO [ControllerServer id=1] Replayed EndTransactionRecord() at offset 7. (org.apache.kafka.controller.OffsetControlManager)
controller-1     | [2025-11-13 18:47:59,576] INFO [ControllerServer id=1] Activated periodic tasks: electUnclean, expireDelegationTokens, generatePeriodicPerformanceMessage, maybeFenceStaleBroker, writeNoOpRecord (org.apache.kafka.controller.PeriodicTaskControlManager)
controller-1     | [2025-11-13 18:47:59,581] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
controller-1     | [2025-11-13 18:47:59,581] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
controller-1     | [2025-11-13 18:47:59,582] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
controller-1     | [2025-11-13 18:47:59,584] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
controller-1     | [2025-11-13 18:47:59,584] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
controller-1     | [2025-11-13 18:47:59,587] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
controller-1     | [2025-11-13 18:47:59,595] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
controller-1     | [2025-11-13 18:47:59,595] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
controller-1     | [2025-11-13 18:47:59,604] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
controller-1     | [2025-11-13 18:47:59,604] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
controller-1     | [2025-11-13 18:47:59,609] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 8 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,619] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
kafka-1          | [2025-11-13 18:47:59,622] INFO Unable to read the broker epoch in /var/lib/kafka/data. (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:47:59,622] INFO Unable to read the broker epoch in /var/lib/kafka/data. (kafka.log.LogManager)
controller-1     | [2025-11-13 18:47:59,622] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
controller-1     | [2025-11-13 18:47:59,621] INFO [controller-1-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
controller-1     | [2025-11-13 18:47:59,622] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
controller-1     | [2025-11-13 18:47:59,621] INFO [controller-1-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:59,625] INFO [broker-2-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:59,625] INFO [broker-2-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:59,633] INFO [BrokerLifecycleManager id=2] Incarnation 2EtBPz5qRnCYVvxEMpfzDw of broker 2 in cluster Nk018hRAQFytWskYqtQduw is now STARTING. (kafka.server.BrokerLifecycleManager)
kafka-1          | [2025-11-13 18:47:59,633] INFO [BrokerLifecycleManager id=2] Incarnation 2EtBPz5qRnCYVvxEMpfzDw of broker 2 in cluster Nk018hRAQFytWskYqtQduw is now STARTING. (kafka.server.BrokerLifecycleManager)
controller-1     | [2025-11-13 18:47:59,633] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,635] INFO [SharedServer id=2] Using kafka-1:19092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
kafka-1          | [2025-11-13 18:47:59,635] INFO [SharedServer id=2] Using kafka-1:19092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
controller-1     | [2025-11-13 18:47:59,637] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
controller-1     | [2025-11-13 18:47:59,637] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1          | [2025-11-13 18:47:59,640] INFO [SharedServer id=2] Using kafka-1:19092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
kafka-1          | [2025-11-13 18:47:59,640] INFO [SharedServer id=2] Using kafka-1:19092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
kafka-1          | [2025-11-13 18:47:59,667] INFO [share-group-lock-timeout-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafka-1          | [2025-11-13 18:47:59,672] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,680] INFO [ExpirationReaper-1-AlterAcls]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
controller-1     | [2025-11-13 18:47:59,693] INFO Config values: 
controller-1     | 	confluent.request.log.api.samples.per.min = 
controller-1     | 	confluent.request.log.enable.admin.apis = true
controller-1     | 	confluent.request.log.enable.per.connection = false
controller-1     | 	confluent.request.log.enable.slowlog = false
controller-1     | 	confluent.request.log.samples.per.min = 0
controller-1     | 	confluent.request.slowlog.threshold.override = -1.0
controller-1     | 	confluent.request.slowlog.threshold.p99.min = -1.0
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,698] INFO Config values: 
controller-1     | 	confluent.request.log.api.samples.per.min = 
controller-1     | 	confluent.request.log.enable.admin.apis = true
controller-1     | 	confluent.request.log.enable.per.connection = false
controller-1     | 	confluent.request.log.enable.slowlog = false
controller-1     | 	confluent.request.log.samples.per.min = 0
controller-1     | 	confluent.request.slowlog.threshold.override = -1.0
controller-1     | 	confluent.request.slowlog.threshold.p99.min = -1.0
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,700] INFO Config values: 
controller-1     | 	confluent.request.log.api.samples.per.min = 
controller-1     | 	confluent.request.log.enable.admin.apis = true
controller-1     | 	confluent.request.log.enable.per.connection = false
controller-1     | 	confluent.request.log.enable.slowlog = false
controller-1     | 	confluent.request.log.samples.per.min = 0
controller-1     | 	confluent.request.slowlog.threshold.override = -1.0
controller-1     | 	confluent.request.slowlog.threshold.p99.min = -1.0
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,702] INFO Config values: 
controller-1     | 	confluent.request.log.api.samples.per.min = 
controller-1     | 	confluent.request.log.enable.admin.apis = true
controller-1     | 	confluent.request.log.enable.per.connection = false
controller-1     | 	confluent.request.log.enable.slowlog = false
controller-1     | 	confluent.request.log.samples.per.min = 0
controller-1     | 	confluent.request.slowlog.threshold.override = -1.0
controller-1     | 	confluent.request.slowlog.threshold.p99.min = -1.0
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,703] INFO Config values: 
controller-1     | 	confluent.request.log.api.samples.per.min = 
controller-1     | 	confluent.request.log.enable.admin.apis = true
controller-1     | 	confluent.request.log.enable.per.connection = false
controller-1     | 	confluent.request.log.enable.slowlog = false
controller-1     | 	confluent.request.log.samples.per.min = 0
controller-1     | 	confluent.request.slowlog.threshold.override = -1.0
controller-1     | 	confluent.request.slowlog.threshold.p99.min = -1.0
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,705] INFO Config values: 
controller-1     | 	confluent.request.log.api.samples.per.min = 
controller-1     | 	confluent.request.log.enable.admin.apis = true
controller-1     | 	confluent.request.log.enable.per.connection = false
controller-1     | 	confluent.request.log.enable.slowlog = false
controller-1     | 	confluent.request.log.samples.per.min = 0
controller-1     | 	confluent.request.slowlog.threshold.override = -1.0
controller-1     | 	confluent.request.slowlog.threshold.p99.min = -1.0
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,707] INFO Config values: 
controller-1     | 	confluent.request.log.api.samples.per.min = 
controller-1     | 	confluent.request.log.enable.admin.apis = true
controller-1     | 	confluent.request.log.enable.per.connection = false
controller-1     | 	confluent.request.log.enable.slowlog = false
controller-1     | 	confluent.request.log.samples.per.min = 0
controller-1     | 	confluent.request.slowlog.threshold.override = -1.0
controller-1     | 	confluent.request.slowlog.threshold.p99.min = -1.0
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,708] INFO Config values: 
controller-1     | 	confluent.request.log.api.samples.per.min = 
controller-1     | 	confluent.request.log.enable.admin.apis = true
controller-1     | 	confluent.request.log.enable.per.connection = false
controller-1     | 	confluent.request.log.enable.slowlog = false
controller-1     | 	confluent.request.log.samples.per.min = 0
controller-1     | 	confluent.request.slowlog.threshold.override = -1.0
controller-1     | 	confluent.request.slowlog.threshold.p99.min = -1.0
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,723] INFO Starting DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
controller-1     | [2025-11-13 18:47:59,723] INFO Starting DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
controller-1     | [2025-11-13 18:47:59,726] INFO Attempting to initiate DynamicMetricsReporters. Attempt: 1 (kafka.server.DynamicMetricsReportersScheduler)
controller-1     | [2025-11-13 18:47:59,726] INFO Attempting to initiate DynamicMetricsReporters. Attempt: 1 (kafka.server.DynamicMetricsReportersScheduler)
springcoreapi-1  | [INFO] Running com.joey.stanley.group.project.feedback_api.FeedbackApiApplicationTests
kafka-1          | [2025-11-13 18:47:59,746] INFO [ExpirationReaper-2-AlterAcls]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
controller-1     | [2025-11-13 18:47:59,754] INFO [ControllerServer id=1] Self-Balancing Kafka is enabled and will be installed as a metadata publisher. (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,754] INFO [ControllerServer id=1] Self-Balancing Kafka is enabled and will be installed as a metadata publisher. (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,759] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,759] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,759] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,759] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,761] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,761] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,762] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
controller-1     | [2025-11-13 18:47:59,762] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
controller-1     | [2025-11-13 18:47:59,768] INFO Awaiting socket connections on controller-1:19091. (kafka.network.DataPlaneAcceptor)
controller-1     | [2025-11-13 18:47:59,768] INFO Awaiting socket connections on controller-1:19091. (kafka.network.DataPlaneAcceptor)
kafka-1          | [2025-11-13 18:47:59,772] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,782] INFO Config values: 
kafka-1          | 	confluent.request.log.api.samples.per.min = 
kafka-1          | 	confluent.request.log.enable.admin.apis = true
kafka-1          | 	confluent.request.log.enable.per.connection = false
kafka-1          | 	confluent.request.log.enable.slowlog = false
kafka-1          | 	confluent.request.log.samples.per.min = 0
kafka-1          | 	confluent.request.slowlog.threshold.override = -1.0
kafka-1          | 	confluent.request.slowlog.threshold.p99.min = -1.0
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,786] INFO Config values: 
kafka-1          | 	confluent.request.log.api.samples.per.min = 
kafka-1          | 	confluent.request.log.enable.admin.apis = true
kafka-1          | 	confluent.request.log.enable.per.connection = false
kafka-1          | 	confluent.request.log.enable.slowlog = false
kafka-1          | 	confluent.request.log.samples.per.min = 0
kafka-1          | 	confluent.request.slowlog.threshold.override = -1.0
kafka-1          | 	confluent.request.slowlog.threshold.p99.min = -1.0
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,788] INFO Config values: 
kafka-1          | 	confluent.request.log.api.samples.per.min = 
kafka-1          | 	confluent.request.log.enable.admin.apis = true
kafka-1          | 	confluent.request.log.enable.per.connection = false
kafka-1          | 	confluent.request.log.enable.slowlog = false
kafka-1          | 	confluent.request.log.samples.per.min = 0
kafka-1          | 	confluent.request.slowlog.threshold.override = -1.0
kafka-1          | 	confluent.request.slowlog.threshold.p99.min = -1.0
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,788] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
controller-1     | [2025-11-13 18:47:59,788] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
controller-1     | [2025-11-13 18:47:59,788] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,788] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,789] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,789] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,790] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] initialized channel manager. (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:47:59,790] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] initialized channel manager. (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:47:59,789] INFO [ControllerServer id=1] Waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,791] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:47:59,791] INFO Config values: 
kafka-1          | 	confluent.request.log.api.samples.per.min = 
kafka-1          | 	confluent.request.log.enable.admin.apis = true
kafka-1          | 	confluent.request.log.enable.per.connection = false
kafka-1          | 	confluent.request.log.enable.slowlog = false
kafka-1          | 	confluent.request.log.samples.per.min = 0
kafka-1          | 	confluent.request.slowlog.threshold.override = -1.0
kafka-1          | 	confluent.request.slowlog.threshold.p99.min = -1.0
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,789] INFO [ControllerServer id=1] Waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,791] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
controller-1     | [2025-11-13 18:47:59,791] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] maybeSendControllerRegistration: cannot register yet because the metadata.version is not known yet. (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:47:59,791] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] maybeSendControllerRegistration: cannot register yet because the metadata.version is not known yet. (kafka.server.ControllerRegistrationManager)
kafka-1          | [2025-11-13 18:47:59,793] INFO Config values: 
controller-1     | [2025-11-13 18:47:59,793] INFO [ControllerServer id=1] Finished waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,793] INFO [ControllerServer id=1] Finished waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,793] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,793] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafka-1          | 	confluent.request.log.api.samples.per.min = 
kafka-1          | 	confluent.request.log.enable.admin.apis = true
kafka-1          | 	confluent.request.log.enable.per.connection = false
kafka-1          | 	confluent.request.log.enable.slowlog = false
kafka-1          | 	confluent.request.log.samples.per.min = 0
kafka-1          | 	confluent.request.slowlog.threshold.override = -1.0
kafka-1          | 	confluent.request.slowlog.threshold.p99.min = -1.0
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,793] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,793] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,794] INFO [ControllerServer id=1] Waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,794] INFO [ControllerServer id=1] Waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,794] INFO [ControllerServer id=1] Finished waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
controller-1     | [2025-11-13 18:47:59,794] INFO [ControllerServer id=1] Finished waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
kafka-1          | [2025-11-13 18:47:59,796] INFO Config values: 
kafka-1          | 	confluent.request.log.api.samples.per.min = 
kafka-1          | 	confluent.request.log.enable.admin.apis = true
kafka-1          | 	confluent.request.log.enable.per.connection = false
kafka-1          | 	confluent.request.log.enable.slowlog = false
kafka-1          | 	confluent.request.log.samples.per.min = 0
kafka-1          | 	confluent.request.slowlog.threshold.override = -1.0
kafka-1          | 	confluent.request.slowlog.threshold.p99.min = -1.0
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,798] INFO Config values: 
kafka-1          | 	confluent.request.log.api.samples.per.min = 
kafka-1          | 	confluent.request.log.enable.admin.apis = true
kafka-1          | 	confluent.request.log.enable.per.connection = false
kafka-1          | 	confluent.request.log.enable.slowlog = false
kafka-1          | 	confluent.request.log.samples.per.min = 0
kafka-1          | 	confluent.request.slowlog.threshold.override = -1.0
kafka-1          | 	confluent.request.slowlog.threshold.p99.min = -1.0
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,800] INFO Config values: 
kafka-1          | 	confluent.request.log.api.samples.per.min = 
kafka-1          | 	confluent.request.log.enable.admin.apis = true
kafka-1          | 	confluent.request.log.enable.per.connection = false
kafka-1          | 	confluent.request.log.enable.slowlog = false
kafka-1          | 	confluent.request.log.samples.per.min = 0
kafka-1          | 	confluent.request.slowlog.threshold.override = -1.0
kafka-1          | 	confluent.request.slowlog.threshold.p99.min = -1.0
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:47:59,801] INFO [BrokerServer id=2] Waiting for broker metadata to catch up (kafka.server.BrokerServer)
controller-1     | [2025-11-13 18:47:59,800] INFO [ControllerServer id=1] Loaded new metadata FinalizedFeatures[metadataVersion=4.1-IV1A, finalizedFeatures={group.version=1, transaction.version=2, confluent.metadata.version=131, eligible.leader.replicas.version=1}, finalizedFeaturesEpoch=7]. (org.apache.kafka.metadata.publisher.FeaturesPublisher)
kafka-1          | [2025-11-13 18:47:59,801] INFO [BrokerServer id=2] Waiting for broker metadata to catch up (kafka.server.BrokerServer)
controller-1     | [2025-11-13 18:47:59,801] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,801] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,802] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,812] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:47:59,812] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:47:59,813] INFO Kafka startTimeMs: 1763059679811 (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:47:59,814] INFO [DynamicConfigPublisher controller id=1] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
controller-1     | [2025-11-13 18:47:59,814] INFO [DynamicConfigPublisher controller id=1] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
controller-1     | [2025-11-13 18:47:59,816] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
controller-1     | [2025-11-13 18:47:59,816] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
controller-1     | [2025-11-13 18:47:59,829] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=9-8ijVEERFCkIjmAEBX7CA, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='controller-1', port=19091, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='confluent.metadata.version', minSupportedVersion=7, maxSupportedVersion=131), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=27), Feature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='streams.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1)], metadataEncryptors=[]) (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:47:59,829] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=9-8ijVEERFCkIjmAEBX7CA, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='controller-1', port=19091, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='confluent.metadata.version', minSupportedVersion=7, maxSupportedVersion=131), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=27), Feature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='streams.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1)], metadataEncryptors=[]) (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:47:59,829] INFO KafkaConfig values: 
controller-1     | 	add.partitions.to.txn.retry.backoff.max.ms = 100
controller-1     | 	add.partitions.to.txn.retry.backoff.ms = 20
controller-1     | 	advertised.listeners = null
controller-1     | 	alter.config.policy.class.name = null
controller-1     | 	alter.log.dirs.replication.quota.window.num = 11
controller-1     | 	alter.log.dirs.replication.quota.window.size.seconds = 1
controller-1     | 	authorizer.class.name = 
controller-1     | 	auto.create.topics.enable = true
controller-1     | 	auto.leader.rebalance.enable = true
controller-1     | 	background.threads = 10
controller-1     | 	broker.heartbeat.interval.ms = 2000
controller-1     | 	broker.id = 1
controller-1     | 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
controller-1     | 	broker.rack = rack-0
controller-1     | 	broker.session.timeout.ms = 9000
controller-1     | 	broker.session.uuid = hLJXuen0TMSXMJfs9PSzFA
controller-1     | 	client.quota.callback.class = null
controller-1     | 	client.quota.max.throttle.time.in.response.ms = 60000
controller-1     | 	client.quota.max.throttle.time.ms = 5000
controller-1     | 	compression.gzip.level = -1
controller-1     | 	compression.lz4.level = 9
controller-1     | 	compression.type = producer
controller-1     | 	compression.zstd.level = 3
controller-1     | 	confluent.accp.enabled = false
controller-1     | 	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
controller-1     | 	confluent.alter.broker.health.max.demoted.brokers = 2147483647
controller-1     | 	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
controller-1     | 	confluent.ansible.managed = false
controller-1     | 	confluent.api.visibility = DEFAULT
controller-1     | 	confluent.append.record.interceptor.classes = []
controller-1     | 	confluent.apply.create.topic.policy.to.create.partitions = false
controller-1     | 	confluent.authorizer.authority.name = 
controller-1     | 	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
controller-1     | 	confluent.backpressure.disk.enable = false
controller-1     | 	confluent.backpressure.disk.free.threshold.bytes = 21474836480
controller-1     | 	confluent.backpressure.disk.produce.bytes.per.second = 131072
controller-1     | 	confluent.backpressure.disk.threshold.recovery.factor = 1.5
controller-1     | 	confluent.backpressure.request.min.broker.limit = 200
controller-1     | 	confluent.backpressure.request.queue.size.percentile = p95
controller-1     | 	confluent.backpressure.types = null
controller-1     | 	confluent.balancer.api.state.topic = _confluent_balancer_api_state
controller-1     | 	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
controller-1     | 	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
controller-1     | 	confluent.balancer.capacity.threshold.upper.limit = 0.95
controller-1     | 	confluent.balancer.cell.load.upper.bound = 0.7
controller-1     | 	confluent.balancer.cell.overload.detection.interval.ms = 3600000
controller-1     | 	confluent.balancer.cell.overload.duration.ms = 86400000
controller-1     | 	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
controller-1     | 	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.cpu.balance.threshold = 1.1
controller-1     | 	confluent.balancer.cpu.goal.act.as.capacity.goal = false
controller-1     | 	confluent.balancer.cpu.low.utilization.threshold = 0.2
controller-1     | 	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
controller-1     | 	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
controller-1     | 	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
controller-1     | 	confluent.balancer.disk.max.load = 0.85
controller-1     | 	confluent.balancer.disk.min.free.space.gb = 0
controller-1     | 	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
controller-1     | 	confluent.balancer.disk.utilization.detector.duration.ms = 600000
controller-1     | 	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
controller-1     | 	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
controller-1     | 	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
controller-1     | 	confluent.balancer.enable = true
controller-1     | 	confluent.balancer.enable.network.capacity.metric.ingestion = false
controller-1     | 	confluent.balancer.exclude.topic.names = []
controller-1     | 	confluent.balancer.exclude.topic.prefixes = []
controller-1     | 	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
controller-1     | 	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
controller-1     | 	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
controller-1     | 	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
controller-1     | 	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
controller-1     | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
controller-1     | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
controller-1     | 	confluent.balancer.incremental.balancing.enabled = false
controller-1     | 	confluent.balancer.incremental.balancing.goals = []
controller-1     | 	confluent.balancer.incremental.balancing.lower.bound = 0.02
controller-1     | 	confluent.balancer.incremental.balancing.min.valid.windows = 5
controller-1     | 	confluent.balancer.incremental.balancing.step.ratio = 0.2
controller-1     | 	confluent.balancer.inter.cell.balancing.enabled = false
controller-1     | 	confluent.balancer.inter.cell.movements.excluded.tenant.ids = []
controller-1     | 	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
controller-1     | 	confluent.balancer.max.replicas = 2147483647
controller-1     | 	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
controller-1     | 	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
controller-1     | 	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
controller-1     | 	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
controller-1     | 	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.rebalancing.goals = []
controller-1     | 	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.balancer.resource.utilization.detector.interval.ms = 60000
controller-1     | 	confluent.balancer.sbc.metrics.parser.enabled = false
controller-1     | 	confluent.balancer.self.healing.maximum.rounds = 1
controller-1     | 	confluent.balancer.task.history.retention.days = 30
controller-1     | 	confluent.balancer.tenant.maximum.movements = 0
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.consume_out = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.cpu = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.nw_in = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.nw_out = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.produce_in = 3
controller-1     | 	confluent.balancer.tenant.striping.counter.threshold.replica_count = 3
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.consume_out = 614400.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.cpu = 300.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_in = 204800.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_out = 614400.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.produce_in = 204800.0
controller-1     | 	confluent.balancer.tenant.striping.desired.stripe.usage.replica_count = 45000.0
controller-1     | 	confluent.balancer.tenant.striping.enable.dry.run.mode = true
controller-1     | 	confluent.balancer.tenant.striping.enabled = false
controller-1     | 	confluent.balancer.tenant.striping.expiry.counter.threshold = 10
controller-1     | 	confluent.balancer.tenant.striping.rate.limit = 3
controller-1     | 	confluent.balancer.tenant.striping.resource.usage.expiry.ms = 3600000
controller-1     | 	confluent.balancer.tenant.suspension.ms = 86400000
controller-1     | 	confluent.balancer.throttle.bytes.per.second = 10485760
controller-1     | 	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
controller-1     | 	confluent.balancer.topic.partition.maximum.movements = 3
controller-1     | 	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
controller-1     | 	confluent.balancer.topic.partition.movements.history.limit = 900
controller-1     | 	confluent.balancer.topic.partition.suspension.ms = 3600000
controller-1     | 	confluent.balancer.topic.replication.factor = 1
controller-1     | 	confluent.balancer.triggering.goals = []
controller-1     | 	confluent.balancer.v2.addition.enabled = false
controller-1     | 	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
controller-1     | 	confluent.balancer.v2.executor.enabled = false
controller-1     | 	confluent.basic.auth.credentials.source = null
controller-1     | 	confluent.basic.auth.user.info = null
controller-1     | 	confluent.bearer.assertion.claim.aud = null
controller-1     | 	confluent.bearer.assertion.claim.exp.minutes = null
controller-1     | 	confluent.bearer.assertion.claim.iss = null
controller-1     | 	confluent.bearer.assertion.claim.jti.include = null
controller-1     | 	confluent.bearer.assertion.claim.nbf.include = null
controller-1     | 	confluent.bearer.assertion.claim.sub = null
controller-1     | 	confluent.bearer.assertion.file = null
controller-1     | 	confluent.bearer.assertion.private.key.file = null
controller-1     | 	confluent.bearer.assertion.private.key.passphrase = null
controller-1     | 	confluent.bearer.assertion.template.file = null
controller-1     | 	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
controller-1     | 	confluent.bearer.auth.client.id = null
controller-1     | 	confluent.bearer.auth.client.secret = null
controller-1     | 	confluent.bearer.auth.credentials.source = null
controller-1     | 	confluent.bearer.auth.identity.pool.id = null
controller-1     | 	confluent.bearer.auth.issuer.endpoint.url = null
controller-1     | 	confluent.bearer.auth.logical.cluster = null
controller-1     | 	confluent.bearer.auth.scope = null
controller-1     | 	confluent.bearer.auth.scope.claim.name = scope
controller-1     | 	confluent.bearer.auth.sub.claim.name = sub
controller-1     | 	confluent.bearer.auth.token = null
controller-1     | 	confluent.broker.health.manager.enabled = true
controller-1     | 	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
controller-1     | 	confluent.broker.health.manager.hard.kill.duration.ms = 60000
controller-1     | 	confluent.broker.health.manager.mitigation.enabled = false
controller-1     | 	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
controller-1     | 	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
controller-1     | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
controller-1     | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
controller-1     | 	confluent.broker.health.manager.sample.duration.ms = 1000
controller-1     | 	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
controller-1     | 	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
controller-1     | 	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
controller-1     | 	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.broker.load.advertised.limit.load = 0.8
controller-1     | 	confluent.broker.load.average.service.request.time.ms = 0.1
controller-1     | 	confluent.broker.load.delay.metric.start.ms = 180000
controller-1     | 	confluent.broker.load.enabled = false
controller-1     | 	confluent.broker.load.num.samples = 60
controller-1     | 	confluent.broker.load.tenant.metric.enable = false
controller-1     | 	confluent.broker.load.update.metric.tags.interval.ms = 60000
controller-1     | 	confluent.broker.load.window.size.ms = 60000
controller-1     | 	confluent.broker.load.workload.coefficient = 20.0
controller-1     | 	confluent.broker.registration.delay.ms = 0
controller-1     | 	confluent.broker.type = confluent_platform
controller-1     | 	confluent.broker.type.topic.enabled = true
controller-1     | 	confluent.calling.resource.identity.type.map = 
controller-1     | 	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
controller-1     | 	confluent.catalog.collector.enable = false
controller-1     | 	confluent.catalog.collector.full.configs.enable = false
controller-1     | 	confluent.catalog.collector.max.bytes.per.snapshot = 850000
controller-1     | 	confluent.catalog.collector.max.topics.process = 500
controller-1     | 	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
controller-1     | 	confluent.catalog.collector.multitenant.topics.enable = true
controller-1     | 	confluent.catalog.collector.snapshot.init.delay.sec = 60
controller-1     | 	confluent.catalog.collector.snapshot.interval.sec = 300
controller-1     | 	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
controller-1     | 	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
controller-1     | 	confluent.cdc.api.keys.topic = 
controller-1     | 	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
controller-1     | 	confluent.cdc.client.quotas.enable = false
controller-1     | 	confluent.cdc.client.quotas.topic.name = 
controller-1     | 	confluent.cdc.lkc.metadata.topic = 
controller-1     | 	confluent.cdc.user.metadata.enable = false
controller-1     | 	confluent.cdc.user.metadata.topic = _confluent-user_metadata
controller-1     | 	confluent.cell.metrics.refresh.period.ms = 60000
controller-1     | 	confluent.cells.default.size = 15
controller-1     | 	confluent.cells.enable = false
controller-1     | 	confluent.cells.implicit.creation.enable = false
controller-1     | 	confluent.cells.k2.base.broker.index = -1
controller-1     | 	confluent.cells.load.refresher.enable = true
controller-1     | 	confluent.cells.max.size = 15
controller-1     | 	confluent.cells.min.size = 6
controller-1     | 	confluent.checksum.enabled.files = [none]
controller-1     | 	confluent.client.topic.max.metrics.count = 1000
controller-1     | 	confluent.client.topic.metrics.expiry.sec = 3600
controller-1     | 	confluent.client.topic.metrics.ignore_client_id_pattern = (?:link-.*-)?broker-\d+-fetcher-\d+(?:-pool-.*)?
controller-1     | 	confluent.client.topic.metrics.ignore_internal_topic_pattern = _.*
controller-1     | 	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
controller-1     | 	confluent.clm.enabled = false
controller-1     | 	confluent.clm.frequency.in.hours = 6
controller-1     | 	confluent.clm.list.object.thread_pool.size = 1
controller-1     | 	confluent.clm.max.backup.days = 3
controller-1     | 	confluent.clm.min.delay.in.minutes = 30
controller-1     | 	confluent.clm.thread.pool.size = 2
controller-1     | 	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
controller-1     | 	confluent.close.connections.on.credential.delete = false
controller-1     | 	confluent.cluster.link.admin.max.in.flight.requests = 1000
controller-1     | 	confluent.cluster.link.admin.request.batch.size = 1
controller-1     | 	confluent.cluster.link.allow.config.providers = true
controller-1     | 	confluent.cluster.link.allow.legacy.message.format = false
controller-1     | 	confluent.cluster.link.allow.truncation.below.hwm = false
controller-1     | 	confluent.cluster.link.availability.check.mode = ALL
controller-1     | 	confluent.cluster.link.background.thread.affinity = LINK
controller-1     | 	confluent.cluster.link.bootstrap.translation.feature.enable = true
controller-1     | 	confluent.cluster.link.clients.max.idle.ms = 3153600000000
controller-1     | 	confluent.cluster.link.enable = true
controller-1     | 	confluent.cluster.link.enable.local.admin = false
controller-1     | 	confluent.cluster.link.enable.metrics.reduction = false
controller-1     | 	confluent.cluster.link.enable.metrics.reduction.advanced = false
controller-1     | 	confluent.cluster.link.fetch.response.min.bytes = 1
controller-1     | 	confluent.cluster.link.fetch.response.total.bytes = 2147483647
controller-1     | 	confluent.cluster.link.fetcher.auto.tune.enable = false
controller-1     | 	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
controller-1     | 	confluent.cluster.link.insync.fetch.response.min.bytes = 1
controller-1     | 	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
controller-1     | 	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
controller-1     | 	confluent.cluster.link.intranet.connectivity.enable = false
controller-1     | 	confluent.cluster.link.intranet.connectivity.migration.enable = false
controller-1     | 	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.cluster.link.k1.to.k2.migration.enable = false
controller-1     | 	confluent.cluster.link.k2.mirror.topic.metadata.enable = false
controller-1     | 	confluent.cluster.link.local.admin.multitenant.enable = false
controller-1     | 	confluent.cluster.link.local.reverse.connection.listener.map = null
controller-1     | 	confluent.cluster.link.max.client.connections = 2147483647
controller-1     | 	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
controller-1     | 	confluent.cluster.link.metadata.topic.enable = false
controller-1     | 	confluent.cluster.link.metadata.topic.min.isr = 2
controller-1     | 	confluent.cluster.link.metadata.topic.partitions = 50
controller-1     | 	confluent.cluster.link.metadata.topic.replication.factor = 3
controller-1     | 	confluent.cluster.link.mirror.transition.batch.size = 10
controller-1     | 	confluent.cluster.link.num.background.threads = 1
controller-1     | 	confluent.cluster.link.num.fetchers = 1
controller-1     | 	confluent.cluster.link.periodic.task.batch.size = 2147483647
controller-1     | 	confluent.cluster.link.periodic.task.min.interval.ms = 1000
controller-1     | 	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
controller-1     | 	confluent.cluster.link.replica.fetch.connections.mode = combined
controller-1     | 	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
controller-1     | 	confluent.cluster.link.replication.quota.mode.per.tenant.overrides = 
controller-1     | 	confluent.cluster.link.replication.quota.window.num = 11
controller-1     | 	confluent.cluster.link.replication.quota.window.size.seconds = 2
controller-1     | 	confluent.cluster.link.request.quota.capacity = 400
controller-1     | 	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
controller-1     | 	confluent.cluster.link.switchover.disabled.principals = []
controller-1     | 	confluent.cluster.link.switchover.enable = false
controller-1     | 	confluent.cluster.link.switchover.listeners = []
controller-1     | 	confluent.cluster.link.switchover.server.states = []
controller-1     | 	confluent.cluster.link.tenant.replication.quota.enable = false
controller-1     | 	confluent.cluster.link.tenant.request.quota.enable = false
controller-1     | 	confluent.cluster.metadata.snapshot.tier.delete.enable = false
controller-1     | 	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
controller-1     | 	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
controller-1     | 	confluent.cluster.metadata.snapshot.tier.upload.enable = false
controller-1     | 	confluent.compacted.topic.prefer.tier.fetch.ms = -1
controller-1     | 	confluent.connection.invalid.request.delay.enable = false
controller-1     | 	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
controller-1     | 	confluent.consumer.fetch.partition.pruning.enable = true
controller-1     | 	confluent.consumer.lag.emitter.enabled = false
controller-1     | 	confluent.consumer.lag.emitter.interval.ms = 60000
controller-1     | 	confluent.dataflow.policy.watch.monitor.ms = 300000
controller-1     | 	confluent.default.data.policy.enforcement = true
controller-1     | 	confluent.defer.isr.shrink.enable = false
controller-1     | 	confluent.describe.topic.partitions.enabled = true
controller-1     | 	confluent.disk.io.manager.enable = false
controller-1     | 	confluent.disk.throughput.headroom = 10485760
controller-1     | 	confluent.disk.throughput.limit = 10485760000
controller-1     | 	confluent.disk.throughput.quota.tier.archive = 1048576000
controller-1     | 	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
controller-1     | 	confluent.durability.audit.batch.flush.frequency.ms = 900000
controller-1     | 	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
controller-1     | 	confluent.durability.audit.enable = false
controller-1     | 	confluent.durability.audit.idempotent.producer = false
controller-1     | 	confluent.durability.audit.initial.job.delay.ms = 900000
controller-1     | 	confluent.durability.audit.io.bytes.per.sec = 10485760
controller-1     | 	confluent.durability.audit.log.ignored.event.types = 
controller-1     | 	confluent.durability.audit.reporting.batch.ms = 1800000
controller-1     | 	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
controller-1     | 	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
controller-1     | 	confluent.durability.topic.partition.count = 50
controller-1     | 	confluent.durability.topic.replication.factor = 3
controller-1     | 	confluent.e2e_checksum.protection.enabled = false
controller-1     | 	confluent.e2e_checksum.protection.files = [none]
controller-1     | 	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
controller-1     | 	confluent.elastic.cku.enabled = false
controller-1     | 	confluent.elastic.cku.scaletozero.enabled = false
controller-1     | 	confluent.eligible.controllers = []
controller-1     | 	confluent.emit.network.type.default = 
controller-1     | 	confluent.emit.network.type.tag = false
controller-1     | 	confluent.enable.broker.reporting.min.usage.mode = true
controller-1     | 	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
controller-1     | 	confluent.fail.unsatisfied.placement.constraints = false
controller-1     | 	confluent.fetch.from.follower.require.leader.epoch.enable = false
controller-1     | 	confluent.fetch.partition.pruning.enable = true
controller-1     | 	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
controller-1     | 	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
controller-1     | 	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
controller-1     | 	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
controller-1     | 	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
controller-1     | 	confluent.flexible.fanout.enabled = false
controller-1     | 	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
controller-1     | 	confluent.flexible.fanout.mode = TENANT_QUOTA
controller-1     | 	confluent.floor.connection.rate.per.ip = -1.0
controller-1     | 	confluent.floor.connection.rate.per.tenant = -1.0
controller-1     | 	confluent.group.coordinator.dynamic.append.linger.enable = false
controller-1     | 	confluent.group.coordinator.max.partition.queue.size = -1
controller-1     | 	confluent.group.coordinator.offsets.batching.enable = false
controller-1     | 	confluent.group.coordinator.offsets.writer.threads = 2
controller-1     | 	confluent.group.coordinator.slow.event.log.count = 10
controller-1     | 	confluent.group.coordinator.slow.event.log.interval.ms = -1
controller-1     | 	confluent.group.coordinator.txn.offset.validation.enable = false
controller-1     | 	confluent.group.highest.offset.commit.rates.log.count = 10
controller-1     | 	confluent.group.highest.offset.commit.rates.log.enable = false
controller-1     | 	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
controller-1     | 	confluent.group.metadata.load.threads = 32
controller-1     | 	confluent.group.subscription.pattern.log.interval.ms = -1
controller-1     | 	confluent.heap.tenured.notify.bytes = 0
controller-1     | 	confluent.heap.tenured.notify.enabled = false
controller-1     | 	confluent.hot.partition.ratio = 0.8
controller-1     | 	confluent.http.server.start.timeout.ms = 60000
controller-1     | 	confluent.http.server.stop.timeout.ms = 30000
controller-1     | 	confluent.intelligent.replication.enable = false
controller-1     | 	confluent.intelligent.replication.push.max.memory.buffer.bytes = 209715200
controller-1     | 	confluent.intelligent.replication.push.max.threads = 4
controller-1     | 	confluent.intelligent.replication.push.threads.per.remote.broker = 1
controller-1     | 	confluent.internal.metrics.enable = false
controller-1     | 	confluent.internal.rest.server.bind.port = null
controller-1     | 	confluent.internal.rest.server.ssl.enable = false
controller-1     | 	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
controller-1     | 	confluent.lat.network.context.verification.enable = false
controller-1     | 	confluent.leader.epoch.checkpoint.checksum.enabled = false
controller-1     | 	confluent.listener.protocol = TCP
controller-1     | 	confluent.log.cleaner.timestamp.validation.enable = true
controller-1     | 	confluent.log.placement.constraints = 
controller-1     | 	confluent.max.broker.load = 1.0
controller-1     | 	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
controller-1     | 	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
controller-1     | 	confluent.max.connection.rate.per.ip = -1.0
controller-1     | 	confluent.max.connection.rate.per.tenant = -1.0
controller-1     | 	confluent.max.connection.throttle.ms = null
controller-1     | 	confluent.max.segment.ms = 9223372036854775807
controller-1     | 	confluent.metadata.active.encryptor = null
controller-1     | 	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
controller-1     | 	confluent.metadata.encryptor.classes = null
controller-1     | 	confluent.metadata.encryptor.required = false
controller-1     | 	confluent.metadata.encryptor.secret.file = null
controller-1     | 	confluent.metadata.encryptor.secrets = null
controller-1     | 	confluent.metadata.jvm.warmup.ms = 60000
controller-1     | 	confluent.metadata.leader.balance.slice.delay.ms = 100
controller-1     | 	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
controller-1     | 	confluent.metadata.max.leader.balance.changes.per.slice = 1000
controller-1     | 	confluent.metadata.rbac_auth.read.controller.enable = false
controller-1     | 	confluent.metadata.rbac_auth.update.controller.enable = false
controller-1     | 	confluent.metadata.reject.when.throttled.enable = false
controller-1     | 	confluent.metadata.server.cluster.registry.clusters = []
controller-1     | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
controller-1     | 	confluent.min.acks = 0
controller-1     | 	confluent.min.connection.throttle.ms = 0
controller-1     | 	confluent.min.segment.ms = 1
controller-1     | 	confluent.missing.id.cache.ttl.sec = 60
controller-1     | 	confluent.missing.id.query.range = 20000
controller-1     | 	confluent.missing.schema.cache.ttl.sec = 60
controller-1     | 	confluent.mtls.build.client.cert.chain.enable = false
controller-1     | 	confluent.mtls.enable = false
controller-1     | 	confluent.mtls.listener.name = EXTERNAL
controller-1     | 	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
controller-1     | 	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
controller-1     | 	confluent.mtls.truststore.manager.class.name = null
controller-1     | 	confluent.multitenant.authorizer.enable.acl.state = false
controller-1     | 	confluent.multitenant.interceptor.balancer.apis.enabled = false
controller-1     | 	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
controller-1     | 	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
controller-1     | 	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
controller-1     | 	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
controller-1     | 	confluent.multitenant.listener.names = null
controller-1     | 	confluent.multitenant.parse.lkc.id.enable = false
controller-1     | 	confluent.multitenant.parse.sni.host.name.enable = false
controller-1     | 	confluent.network.health.manager.enabled = false
controller-1     | 	confluent.network.health.manager.external.listener.name = EXTERNAL
controller-1     | 	confluent.network.health.manager.externalconnectivitystartup.enabled = false
controller-1     | 	confluent.network.health.manager.min.healthy.network.samples = 3
controller-1     | 	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
controller-1     | 	confluent.network.health.manager.mitigation.enabled = false
controller-1     | 	confluent.network.health.manager.network.sample.window.size = 120
controller-1     | 	confluent.network.health.manager.sample.duration.ms = 1000
controller-1     | 	confluent.oauth.flat.networking.verification.enable = false
controller-1     | 	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
controller-1     | 	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
controller-1     | 	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
controller-1     | 	confluent.offsets.topic.max.message.bytes = -1
controller-1     | 	confluent.offsets.topic.placement.constraints = 
controller-1     | 	confluent.omit.network.processor.metric.tag = false
controller-1     | 	confluent.operator.managed = false
controller-1     | 	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
controller-1     | 	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
controller-1     | 	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
controller-1     | 	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
controller-1     | 	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
controller-1     | 	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
controller-1     | 	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
controller-1     | 	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings = 
controller-1     | 	confluent.ppv2.endpoint.scheme.enable = false
controller-1     | 	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
controller-1     | 	confluent.ppv2.endpoint.scheme.template.variable.cloud = 
controller-1     | 	confluent.ppv2.endpoint.scheme.template.variable.domain = 
controller-1     | 	confluent.ppv2.endpoint.scheme.template.variable.region = 
controller-1     | 	confluent.ppv2.endpoint.scheme.template.variables = 
controller-1     | 	confluent.ppv2.endpoint.scheme.templates = 
controller-1     | 	confluent.prefer.tier.fetch.ms = -1
controller-1     | 	confluent.produce.throttle.pre.check.enable = false
controller-1     | 	confluent.produce.throttle.pre.check.for.new.connection.enable = false
controller-1     | 	confluent.producer.id.cache.broker.hard.limit = -1
controller-1     | 	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
controller-1     | 	confluent.producer.id.cache.extra.eviction.percentage = 0
controller-1     | 	confluent.producer.id.cache.limit = 2147483647
controller-1     | 	confluent.producer.id.cache.partition.hard.limit = -1
controller-1     | 	confluent.producer.id.cache.tenant.hard.limit = -1
controller-1     | 	confluent.producer.id.quota.manager.enable = false
controller-1     | 	confluent.producer.id.quota.window.num = 11
controller-1     | 	confluent.producer.id.quota.window.size.seconds = 1
controller-1     | 	confluent.producer.id.throttle.enable = false
controller-1     | 	confluent.producer.id.throttle.enable.threshold.percentage = 100
controller-1     | 	confluent.protocol.netty.http2.connection.window.size = 31457280
controller-1     | 	confluent.protocol.netty.http2.flow.control.enabled = true
controller-1     | 	confluent.protocol.netty.http2.initial.window.size = 153600
controller-1     | 	confluent.protocol.netty.http2.max.frame.size = 16384
controller-1     | 	confluent.protocol.netty.http2.stream.graceful.close.timeout.ms = 60000
controller-1     | 	confluent.protocol.netty.num.boss.threads = 1
controller-1     | 	confluent.protocol.netty.num.worker.threads = 4
controller-1     | 	confluent.proxy.mode.local.default = false
controller-1     | 	confluent.proxy.protocol.fallback.enabled = false
controller-1     | 	confluent.proxy.protocol.parser = class io.confluent.kafka.common.network.CloudProxyTlvParser
controller-1     | 	confluent.proxy.protocol.version = NONE
controller-1     | 	confluent.quota.computing.usage.adjustment = 0.5
controller-1     | 	confluent.quota.dynamic.adjustment.min.usage = 102400
controller-1     | 	confluent.quota.dynamic.enable = false
controller-1     | 	confluent.quota.dynamic.publishing.interval.ms = 60000
controller-1     | 	confluent.quota.dynamic.reporting.interval.ms = 30000
controller-1     | 	confluent.quota.tenant.broker.max.consumer.rate = 13107200
controller-1     | 	confluent.quota.tenant.broker.max.producer.rate = 13107200
controller-1     | 	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
controller-1     | 	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
controller-1     | 	confluent.quota.tenant.fetch.multiplier = 1.0
controller-1     | 	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
controller-1     | 	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
controller-1     | 	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
controller-1     | 	confluent.quota.tenant.internal.broker.max.controller.mutation.rate = 9223372036854775807
controller-1     | 	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
controller-1     | 	confluent.quota.tenant.internal.throttling.enable = false
controller-1     | 	confluent.quota.tenant.produce.multiplier = 1.0
controller-1     | 	confluent.quota.tenant.user.quotas.enable = false
controller-1     | 	confluent.rack.id.mapping = null
controller-1     | 	confluent.regional.metadata.client.class = null
controller-1     | 	confluent.regional.resource.manager.client.scheduler.threads = 2
controller-1     | 	confluent.regional.resource.manager.endpoint = null
controller-1     | 	confluent.regional.resource.manager.grpc.endpoint = null
controller-1     | 	confluent.reject.invalid.sni.hostnames = false
controller-1     | 	confluent.replica.fetch.backoff.max.ms = 1000
controller-1     | 	confluent.replica.fetch.connections.mode = combined
controller-1     | 	confluent.replication.mode = PULL
controller-1     | 	confluent.replication.push.feature.enable = false
controller-1     | 	confluent.reporters.telemetry.auto.enable = true
controller-1     | 	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
controller-1     | 	confluent.request.pipelining.enable = true
controller-1     | 	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
controller-1     | 	confluent.require.calling.resource.identity = false
controller-1     | 	confluent.require.compatible.keystore.updates = true
controller-1     | 	confluent.require.confluent.issuer = false
controller-1     | 	confluent.roll.check.interval.ms = 300000
controller-1     | 	confluent.schema.registry.max.cache.size = 10000
controller-1     | 	confluent.schema.registry.max.retries = 1
controller-1     | 	confluent.schema.registry.retries.wait.ms = 0
controller-1     | 	confluent.schema.registry.url = null
controller-1     | 	confluent.schema.validation.context.name.enable = false
controller-1     | 	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
controller-1     | 	confluent.schema.validator.multitenant.enable = false
controller-1     | 	confluent.schema.validator.samples.per.min = 0
controller-1     | 	confluent.security.bc.approved.mode.enable = false
controller-1     | 	confluent.security.event.logger.authentication.enable = false
controller-1     | 	confluent.security.event.logger.authentication.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.authorization.event.rate.limit = -1
controller-1     | 	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
controller-1     | 	confluent.security.event.logger.enable = true
controller-1     | 	confluent.security.event.logger.kafka.request.rate.limit = -1
controller-1     | 	confluent.security.event.logger.physical.cluster.id = 
controller-1     | 	confluent.security.event.router.config = 
controller-1     | 	confluent.security.revoked.certificate.ids = 
controller-1     | 	confluent.segment.eager.roll.enable = false
controller-1     | 	confluent.segment.speculative.prefetch.enable = false
controller-1     | 	confluent.share.coordinator.slow.event.log.count = 10
controller-1     | 	confluent.share.coordinator.slow.event.log.interval.ms = -1
controller-1     | 	confluent.share.metadata.load.threads = 32
controller-1     | 	confluent.spiffe.id.principal.extraction.rules = 
controller-1     | 	confluent.ssl.key.password = null
controller-1     | 	confluent.ssl.keystore.location = null
controller-1     | 	confluent.ssl.keystore.password = null
controller-1     | 	confluent.ssl.keystore.type = null
controller-1     | 	confluent.ssl.protocol = null
controller-1     | 	confluent.ssl.truststore.location = null
controller-1     | 	confluent.ssl.truststore.password = null
controller-1     | 	confluent.ssl.truststore.type = null
controller-1     | 	confluent.step.connection.rate.per.ip = -1.0
controller-1     | 	confluent.step.connection.rate.per.tenant = -1.0
controller-1     | 	confluent.storage.probe.disk.metrics.collection.enabled = false
controller-1     | 	confluent.storage.probe.period.ms = -1
controller-1     | 	confluent.storage.probe.slow.write.threshold.ms = 5000
controller-1     | 	confluent.stray.log.delete.delay.ms = 604800000
controller-1     | 	confluent.stray.log.max.deletions.per.run = 72
controller-1     | 	confluent.subdomain.prefix = null
controller-1     | 	confluent.subdomain.separator.map = null
controller-1     | 	confluent.subdomain.separator.variable = %sep
controller-1     | 	confluent.system.time.roll.enable = false
controller-1     | 	confluent.telemetry.enabled = false
controller-1     | 	confluent.telemetry.external.client.metrics.delta.temporality = true
controller-1     | 	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
controller-1     | 	confluent.telemetry.external.client.metrics.push.enabled = false
controller-1     | 	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
controller-1     | 	confluent.telemetry.external.client.metrics.subscription.match.list = null
controller-1     | 	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
controller-1     | 	confluent.telemetry.external.client.metrics.supported.compression.types = [zstd, lz4, gzip, snappy]
controller-1     | 	confluent.tenant.latency.metric.enabled = false
controller-1     | 	confluent.tenantaware.encryption.key.manager.enable = false
controller-1     | 	confluent.tenantaware.encryption.key.manager.proactive.key.generation.enable = false
controller-1     | 	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
controller-1     | 	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
controller-1     | 	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
controller-1     | 	confluent.tier.archiver.num.threads = 2
controller-1     | 	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
controller-1     | 	confluent.tier.azure.block.blob.container = null
controller-1     | 	confluent.tier.azure.block.blob.cred.file.path = null
controller-1     | 	confluent.tier.azure.block.blob.endpoint = null
controller-1     | 	confluent.tier.azure.block.blob.prefix = 
controller-1     | 	confluent.tier.backend = 
controller-1     | 	confluent.tier.bucket.probe.period.ms = -1
controller-1     | 	confluent.tier.cleaner.compact.min.efficiency = 0.5
controller-1     | 	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
controller-1     | 	confluent.tier.cleaner.dedupe.buffer.size = 134217728
controller-1     | 	confluent.tier.cleaner.dual.compaction = false
controller-1     | 	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
controller-1     | 	confluent.tier.cleaner.dual.compaction.validation.percent = 0
controller-1     | 	confluent.tier.cleaner.enable = false
controller-1     | 	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
controller-1     | 	confluent.tier.cleaner.feature.enable = false
controller-1     | 	confluent.tier.cleaner.io.buffer.load.factor = 0.9
controller-1     | 	confluent.tier.cleaner.io.buffer.size = 10485760
controller-1     | 	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
controller-1     | 	confluent.tier.cleaner.min.cleanable.ratio = 0.75
controller-1     | 	confluent.tier.cleaner.num.threads = 2
controller-1     | 	confluent.tier.enable = false
controller-1     | 	confluent.tier.feature = false
controller-1     | 	confluent.tier.fenced.segment.delete.delay.ms = 600000
controller-1     | 	confluent.tier.fetcher.async.enable = false
controller-1     | 	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
controller-1     | 	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
controller-1     | 	confluent.tier.fetcher.memorypool.bytes = 0
controller-1     | 	confluent.tier.fetcher.num.threads = 4
controller-1     | 	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
controller-1     | 	confluent.tier.fetcher.offset.cache.period.ms = 60000
controller-1     | 	confluent.tier.fetcher.offset.cache.size = 200000
controller-1     | 	confluent.tier.gcs.bucket = null
controller-1     | 	confluent.tier.gcs.cred.file.path = null
controller-1     | 	confluent.tier.gcs.prefix = 
controller-1     | 	confluent.tier.gcs.region = null
controller-1     | 	confluent.tier.gcs.sse.customer.encryption.key = null
controller-1     | 	confluent.tier.gcs.write.chunk.size = 0
controller-1     | 	confluent.tier.local.hotset.bytes = -1
controller-1     | 	confluent.tier.local.hotset.ms = 86400000
controller-1     | 	confluent.tier.max.partition.fetch.bytes.override = 0
controller-1     | 	confluent.tier.metadata.bootstrap.servers = null
controller-1     | 	confluent.tier.metadata.catchup.max.poll.ms = 0
controller-1     | 	confluent.tier.metadata.max.poll.ms = 100
controller-1     | 	confluent.tier.metadata.namespace = null
controller-1     | 	confluent.tier.metadata.num.partitions = 50
controller-1     | 	confluent.tier.metadata.replication.factor = 3
controller-1     | 	confluent.tier.metadata.request.timeout.ms = 30000
controller-1     | 	confluent.tier.metadata.snapshots.enable = false
controller-1     | 	confluent.tier.metadata.snapshots.interval.ms = 86400000
controller-1     | 	confluent.tier.metadata.snapshots.retention.days = 7
controller-1     | 	confluent.tier.metadata.snapshots.threads = 2
controller-1     | 	confluent.tier.object.fetcher.num.threads = 1
controller-1     | 	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
controller-1     | 	confluent.tier.partition.state.cleanup.enable = false
controller-1     | 	confluent.tier.partition.state.cleanup.interval.ms = 86400000
controller-1     | 	confluent.tier.partition.state.commit.interval.ms = 15000
controller-1     | 	confluent.tier.prefetch.cache.enable = false
controller-1     | 	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
controller-1     | 	confluent.tier.prefetch.cache.range.bytes = 5242880
controller-1     | 	confluent.tier.prefetch.cache.total.size.bytes = 209715200
controller-1     | 	confluent.tier.s3.assumerole.arn = null
controller-1     | 	confluent.tier.s3.auto.abort.threshold.bytes = 500000
controller-1     | 	confluent.tier.s3.aws.endpoint.override = null
controller-1     | 	confluent.tier.s3.aws.signer.override = null
controller-1     | 	confluent.tier.s3.bucket = null
controller-1     | 	confluent.tier.s3.cred.file.path = null
controller-1     | 	confluent.tier.s3.force.path.style.access = false
controller-1     | 	confluent.tier.s3.ipv6.enabled = true
controller-1     | 	confluent.tier.s3.prefix = 
controller-1     | 	confluent.tier.s3.region = null
controller-1     | 	confluent.tier.s3.security.providers = null
controller-1     | 	confluent.tier.s3.sse.algorithm = AES256
controller-1     | 	confluent.tier.s3.sse.customer.encryption.key = null
controller-1     | 	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
controller-1     | 	confluent.tier.s3.ssl.key.password = null
controller-1     | 	confluent.tier.s3.ssl.keystore.location = null
controller-1     | 	confluent.tier.s3.ssl.keystore.password = null
controller-1     | 	confluent.tier.s3.ssl.keystore.type = null
controller-1     | 	confluent.tier.s3.ssl.protocol = TLSv1.3
controller-1     | 	confluent.tier.s3.ssl.provider = null
controller-1     | 	confluent.tier.s3.ssl.truststore.location = null
controller-1     | 	confluent.tier.s3.ssl.truststore.password = null
controller-1     | 	confluent.tier.s3.ssl.truststore.type = null
controller-1     | 	confluent.tier.s3.storage.class.override = 
controller-1     | 	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
controller-1     | 	confluent.tier.s3.v2.enabled = false
controller-1     | 	confluent.tier.segment.hotset.roll.min.bytes = 104857600
controller-1     | 	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
controller-1     | 	confluent.tier.topic.data.loss.validation.fencing.enable = false
controller-1     | 	confluent.tier.topic.delete.backoff.ms = 21600000
controller-1     | 	confluent.tier.topic.delete.check.interval.ms = 300000
controller-1     | 	confluent.tier.topic.delete.max.inprogress.partitions = 100
controller-1     | 	confluent.tier.topic.head.data.loss.validation.enable = true
controller-1     | 	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
controller-1     | 	confluent.tier.topic.materialization.from.snapshot.enable = false
controller-1     | 	confluent.tier.topic.producer.enable.idempotence = true
controller-1     | 	confluent.tier.topic.snapshots.enable = false
controller-1     | 	confluent.tier.topic.snapshots.interval.ms = 300000
controller-1     | 	confluent.tier.topic.snapshots.max.records = 100000
controller-1     | 	confluent.tier.topic.snapshots.retention.hours = 168
controller-1     | 	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
controller-1     | 	confluent.topic.partition.default.placement = 2
controller-1     | 	confluent.topic.policy.use.computed.assignments = false
controller-1     | 	confluent.topic.replica.assignor.builder.class = 
controller-1     | 	confluent.track.api.key.per.ip = false
controller-1     | 	confluent.track.per.ip.max.size = 100000
controller-1     | 	confluent.track.tenant.id.per.ip = false
controller-1     | 	confluent.traffic.cdc.network.id.routes.enable = false
controller-1     | 	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
controller-1     | 	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
controller-1     | 	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
controller-1     | 	confluent.traffic.network.id = 
controller-1     | 	confluent.traffic.network.type = 
controller-1     | 	confluent.transaction.2pc.timeout.ms = -1
controller-1     | 	confluent.transaction.logging.verbosity = 0
controller-1     | 	confluent.transaction.state.log.placement.constraints = 
controller-1     | 	confluent.unique.deprecated.request.metrics.per.tenant = 1000
controller-1     | 	confluent.valid.broker.rack.set = null
controller-1     | 	confluent.valid.sni.hostnames = 
controller-1     | 	confluent.valid.sni.hostnames.exclude.suffix = 
controller-1     | 	confluent.verify.group.subscription.prefix = false
controller-1     | 	confluent.virtual.topic.creation.enabled = false
controller-1     | 	confluent.zone.tagged.request.metrics.enable = false
controller-1     | 	connection.failed.authentication.delay.ms = 100
controller-1     | 	connection.min.expire.interval.ms = 250
controller-1     | 	connections.max.age.ms = 3153600000000
controller-1     | 	connections.max.idle.ms = 600000
controller-1     | 	connections.max.reauth.ms = 0
controller-1     | 	controlled.shutdown.enable = true
controller-1     | 	controller.listener.names = CONTROLLER
controller-1     | 	controller.performance.always.log.threshold.ms = 2000
controller-1     | 	controller.performance.sample.period.ms = 60000
controller-1     | 	controller.quorum.append.linger.ms = 25
controller-1     | 	controller.quorum.bootstrap.servers = []
controller-1     | 	controller.quorum.election.backoff.max.ms = 1000
controller-1     | 	controller.quorum.election.timeout.ms = 1000
controller-1     | 	controller.quorum.fetch.timeout.ms = 2000
controller-1     | 	controller.quorum.request.timeout.ms = 2000
controller-1     | 	controller.quorum.retry.backoff.ms = 20
controller-1     | 	controller.quorum.voters = [1@controller-1:19091]
controller-1     | 	controller.quota.window.num = 11
controller-1     | 	controller.quota.window.size.seconds = 1
controller-1     | 	controller.socket.timeout.ms = 30000
controller-1     | 	create.cluster.link.policy.class.name = null
controller-1     | 	create.topic.policy.class.name = null
controller-1     | 	default.replication.factor = 1
controller-1     | 	delegation.token.expiry.check.interval.ms = 3600000
controller-1     | 	delegation.token.expiry.time.ms = 86400000
controller-1     | 	delegation.token.max.lifetime.ms = 604800000
controller-1     | 	delegation.token.secret.key = null
controller-1     | 	delete.records.purgatory.purge.interval.requests = 1
controller-1     | 	delete.topic.enable = true
controller-1     | 	early.start.listeners = null
controller-1     | 	enable.fips = false
controller-1     | 	fetch.max.bytes = 57671680
controller-1     | 	fetch.purgatory.purge.interval.requests = 1000
controller-1     | 	floor.max.connection.creation.rate = null
controller-1     | 	follower.replication.throttled.rate = 9223372036854775807
controller-1     | 	follower.replication.throttled.replicas = none
controller-1     | 	group.consumer.assignors = [uniform, range]
controller-1     | 	group.consumer.heartbeat.interval.ms = 5000
controller-1     | 	group.consumer.max.heartbeat.interval.ms = 15000
controller-1     | 	group.consumer.max.session.timeout.ms = 60000
controller-1     | 	group.consumer.max.size = 2147483647
controller-1     | 	group.consumer.migration.policy = bidirectional
controller-1     | 	group.consumer.min.heartbeat.interval.ms = 5000
controller-1     | 	group.consumer.min.session.timeout.ms = 45000
controller-1     | 	group.consumer.regex.refresh.interval.ms = 600000
controller-1     | 	group.consumer.session.timeout.ms = 45000
controller-1     | 	group.coordinator.append.linger.ms = 5
controller-1     | 	group.coordinator.rebalance.protocols = [classic, consumer, share, streams]
controller-1     | 	group.coordinator.threads = 4
controller-1     | 	group.initial.rebalance.delay.ms = 3000
controller-1     | 	group.max.session.timeout.ms = 1800000
controller-1     | 	group.max.size = 2147483647
controller-1     | 	group.min.session.timeout.ms = 6000
controller-1     | 	group.share.assignors = [simple]
controller-1     | 	group.share.delivery.count.limit = 5
controller-1     | 	group.share.enable = false
controller-1     | 	group.share.heartbeat.interval.ms = 5000
controller-1     | 	group.share.initialize.retry.interval.ms = 30000
controller-1     | 	group.share.max.heartbeat.interval.ms = 15000
controller-1     | 	group.share.max.record.lock.duration.ms = 60000
controller-1     | 	group.share.max.session.timeout.ms = 60000
controller-1     | 	group.share.max.share.sessions = 2000
controller-1     | 	group.share.max.size = 200
controller-1     | 	group.share.min.heartbeat.interval.ms = 5000
controller-1     | 	group.share.min.record.lock.duration.ms = 15000
controller-1     | 	group.share.min.session.timeout.ms = 45000
controller-1     | 	group.share.partition.max.record.locks = 2000
controller-1     | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
controller-1     | 	group.share.record.lock.duration.ms = 30000
controller-1     | 	group.share.rollout.ready = true
controller-1     | 	group.share.session.timeout.ms = 45000
controller-1     | 	group.streams.heartbeat.interval.ms = 5000
controller-1     | 	group.streams.max.heartbeat.interval.ms = 15000
controller-1     | 	group.streams.max.session.timeout.ms = 60000
controller-1     | 	group.streams.max.size = 2147483647
controller-1     | 	group.streams.max.standby.replicas = 2
controller-1     | 	group.streams.min.heartbeat.interval.ms = 5000
controller-1     | 	group.streams.min.session.timeout.ms = 45000
controller-1     | 	group.streams.num.standby.replicas = 0
controller-1     | 	group.streams.session.timeout.ms = 45000
controller-1     | 	initial.broker.registration.timeout.ms = 60000
controller-1     | 	inter.broker.listener.name = null
controller-1     | 	internal.metadata.delete.delay.millis = 60000
controller-1     | 	internal.metadata.log.segment.bytes = null
controller-1     | 	internal.metadata.max.batch.size.in.bytes = 8388608
controller-1     | 	internal.metadata.max.fetch.size.in.bytes = 8388608
controller-1     | 	k2.stack.builder.class.name = null
controller-1     | 	k2.startup.timeout.ms = 60000
controller-1     | 	k2.topic.metadata.refresh.ms = 10000
controller-1     | 	kafka.metrics.polling.interval.secs = 10
controller-1     | 	kafka.metrics.reporters = []
controller-1     | 	leader.imbalance.check.interval.seconds = 300
controller-1     | 	leader.replication.throttled.rate = 9223372036854775807
controller-1     | 	leader.replication.throttled.replicas = none
controller-1     | 	listener.security.protocol.map = CONTROLLER:PLAINTEXT
controller-1     | 	listeners = CONTROLLER://controller-1:19091
controller-1     | 	log.cleaner.backoff.ms = 15000
controller-1     | 	log.cleaner.dedupe.buffer.size = 134217728
controller-1     | 	log.cleaner.delete.retention.ms = 86400000
controller-1     | 	log.cleaner.enable = true
controller-1     | 	log.cleaner.hash.algorithm = MD5
controller-1     | 	log.cleaner.io.buffer.load.factor = 0.9
controller-1     | 	log.cleaner.io.buffer.size = 524288
controller-1     | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
controller-1     | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
controller-1     | 	log.cleaner.min.cleanable.ratio = 0.5
controller-1     | 	log.cleaner.min.compaction.lag.ms = 0
controller-1     | 	log.cleaner.threads = 1
controller-1     | 	log.cleanup.policy = [delete]
controller-1     | 	log.cleanup.policy.empty.validation = none
controller-1     | 	log.deletion.max.segments.per.run = 2147483647
controller-1     | 	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
controller-1     | 	log.dir = /tmp/kafka-logs
controller-1     | 	log.dir.failure.timeout.ms = 30000
controller-1     | 	log.dirs = /var/lib/kafka/data
controller-1     | 	log.flush.interval.messages = 9223372036854775807
controller-1     | 	log.flush.interval.ms = null
controller-1     | 	log.flush.offset.checkpoint.interval.ms = 60000
controller-1     | 	log.flush.scheduler.interval.ms = 9223372036854775807
controller-1     | 	log.flush.start.offset.checkpoint.interval.ms = 60000
controller-1     | 	log.index.interval.bytes = 4096
controller-1     | 	log.index.size.max.bytes = 10485760
controller-1     | 	log.initial.task.delay.ms = 30000
controller-1     | 	log.local.retention.bytes = -2
controller-1     | 	log.local.retention.ms = -2
controller-1     | 	log.message.timestamp.after.max.ms = 3600000
controller-1     | 	log.message.timestamp.before.max.ms = 9223372036854775807
controller-1     | 	log.message.timestamp.type = CreateTime
controller-1     | 	log.preallocate = false
controller-1     | 	log.retention.bytes = -1
controller-1     | 	log.retention.check.interval.ms = 300000
controller-1     | 	log.retention.hours = 168
controller-1     | 	log.retention.minutes = null
controller-1     | 	log.retention.ms = null
controller-1     | 	log.roll.hours = 168
controller-1     | 	log.roll.jitter.hours = 0
controller-1     | 	log.roll.jitter.ms = null
controller-1     | 	log.roll.ms = null
controller-1     | 	log.segment.bytes = 1073741824
controller-1     | 	log.segment.delete.delay.ms = 60000
controller-1     | 	max.connection.creation.rate = 1.7976931348623157E308
controller-1     | 	max.connection.creation.rate.per.ip.enable.threshold = 0.0
controller-1     | 	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
controller-1     | 	max.connections = 2147483647
controller-1     | 	max.connections.per.ip = 2147483647
controller-1     | 	max.connections.per.ip.overrides = 
controller-1     | 	max.connections.per.tenant = 0
controller-1     | 	max.connections.protected.listeners = []
controller-1     | 	max.connections.reap.amount = 0
controller-1     | 	max.incremental.fetch.session.cache.slots = 1000
controller-1     | 	max.request.partition.size.limit = 2000
controller-1     | 	message.max.bytes = 1048588
controller-1     | 	metadata.log.dir = null
controller-1     | 	metadata.log.max.record.bytes.between.snapshots = 20971520
controller-1     | 	metadata.log.max.snapshot.interval.ms = 3600000
controller-1     | 	metadata.log.segment.bytes = 1073741824
controller-1     | 	metadata.log.segment.ms = 604800000
controller-1     | 	metadata.max.idle.interval.ms = 500
controller-1     | 	metadata.max.retention.bytes = 104857600
controller-1     | 	metadata.max.retention.ms = 604800000
controller-1     | 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
controller-1     | 	metrics.num.samples = 2
controller-1     | 	metrics.recording.level = INFO
controller-1     | 	metrics.sample.window.ms = 30000
controller-1     | 	min.insync.replicas = 1
controller-1     | 	multitenant.authorizer.support.resource.ids = false
controller-1     | 	multitenant.metadata.class = null
controller-1     | 	multitenant.metadata.dir = null
controller-1     | 	multitenant.metadata.reload.delay.ms = 120000
controller-1     | 	multitenant.metadata.ssl.certs.path = null
controller-1     | 	multitenant.tenant.delete.batch.size = 10
controller-1     | 	multitenant.tenant.delete.check.ms = 120000
controller-1     | 	multitenant.tenant.delete.delay = 604800000
controller-1     | 	node.id = 1
controller-1     | 	num.io.threads = 8
controller-1     | 	num.network.threads = 3
controller-1     | 	num.partitions = 1
controller-1     | 	num.recovery.threads.per.data.dir = 2
controller-1     | 	num.replica.alter.log.dirs.threads = null
controller-1     | 	num.replica.fetchers = 1
controller-1     | 	offset.metadata.max.bytes = 4096
controller-1     | 	offsets.commit.timeout.ms = 5000
controller-1     | 	offsets.load.buffer.size = 5242880
controller-1     | 	offsets.retention.check.interval.ms = 600000
controller-1     | 	offsets.retention.minutes = 10080
controller-1     | 	offsets.topic.compression.codec = 0
controller-1     | 	offsets.topic.num.partitions = 50
controller-1     | 	offsets.topic.replication.factor = 3
controller-1     | 	offsets.topic.segment.bytes = 104857600
controller-1     | 	otel.exporter.otlp.custom.endpoint = default
controller-1     | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
controller-1     | 	process.roles = [controller]
controller-1     | 	producer.id.expiration.check.interval.ms = 600000
controller-1     | 	producer.id.expiration.ms = 86400000
controller-1     | 	producer.purgatory.purge.interval.requests = 1000
controller-1     | 	queued.max.request.bytes = -1
controller-1     | 	queued.max.requests = 500
controller-1     | 	quota.window.num = 11
controller-1     | 	quota.window.size.seconds = 1
controller-1     | 	quotas.consumption.expiration.time.ms = 600000
controller-1     | 	quotas.expiration.interval.ms = 3600000
controller-1     | 	quotas.expiration.time.ms = 604800000
controller-1     | 	quotas.lazy.evaluation.threshold = 0.5
controller-1     | 	quotas.topic.append.timeout.ms = 5000
controller-1     | 	quotas.topic.compression.codec = 3
controller-1     | 	quotas.topic.load.buffer.size = 5242880
controller-1     | 	quotas.topic.num.partitions = 50
controller-1     | 	quotas.topic.placement.constraints = 
controller-1     | 	quotas.topic.replication.factor = 3
controller-1     | 	quotas.topic.segment.bytes = 104857600
controller-1     | 	remote.fetch.max.wait.ms = 500
controller-1     | 	remote.list.offsets.request.timeout.ms = 30000
controller-1     | 	remote.log.index.file.cache.total.size.bytes = 1073741824
controller-1     | 	remote.log.manager.copier.thread.pool.size = 10
controller-1     | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
controller-1     | 	remote.log.manager.copy.quota.window.num = 11
controller-1     | 	remote.log.manager.copy.quota.window.size.seconds = 1
controller-1     | 	remote.log.manager.expiration.thread.pool.size = 10
controller-1     | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
controller-1     | 	remote.log.manager.fetch.quota.window.num = 11
controller-1     | 	remote.log.manager.fetch.quota.window.size.seconds = 1
controller-1     | 	remote.log.manager.task.interval.ms = 30000
controller-1     | 	remote.log.manager.task.retry.backoff.max.ms = 30000
controller-1     | 	remote.log.manager.task.retry.backoff.ms = 500
controller-1     | 	remote.log.manager.task.retry.jitter = 0.2
controller-1     | 	remote.log.manager.thread.pool.size = 2
controller-1     | 	remote.log.metadata.custom.metadata.max.bytes = 128
controller-1     | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
controller-1     | 	remote.log.metadata.manager.class.path = null
controller-1     | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
controller-1     | 	remote.log.metadata.manager.listener.name = null
controller-1     | 	remote.log.reader.max.pending.tasks = 100
controller-1     | 	remote.log.reader.threads = 10
controller-1     | 	remote.log.storage.manager.class.name = null
controller-1     | 	remote.log.storage.manager.class.path = null
controller-1     | 	remote.log.storage.manager.impl.prefix = rsm.config.
controller-1     | 	remote.log.storage.system.enable = false
controller-1     | 	replica.fetch.backoff.ms = 1000
controller-1     | 	replica.fetch.max.bytes = 1048576
controller-1     | 	replica.fetch.min.bytes = 1
controller-1     | 	replica.fetch.response.max.bytes = 10485760
controller-1     | 	replica.fetch.wait.max.ms = 500
controller-1     | 	replica.high.watermark.checkpoint.interval.ms = 5000
controller-1     | 	replica.lag.time.max.ms = 30000
controller-1     | 	replica.selector.class = null
controller-1     | 	replica.socket.receive.buffer.bytes = 65536
controller-1     | 	replica.socket.timeout.ms = 30000
controller-1     | 	replication.quota.window.num = 11
controller-1     | 	replication.quota.window.size.seconds = 1
controller-1     | 	request.timeout.ms = 30000
controller-1     | 	sasl.client.callback.handler.class = null
controller-1     | 	sasl.enabled.mechanisms = [GSSAPI]
controller-1     | 	sasl.jaas.config = null
controller-1     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
controller-1     | 	sasl.kerberos.min.time.before.relogin = 60000
controller-1     | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
controller-1     | 	sasl.kerberos.service.name = null
controller-1     | 	sasl.kerberos.ticket.renew.jitter = 0.05
controller-1     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
controller-1     | 	sasl.login.callback.handler.class = null
controller-1     | 	sasl.login.class = null
controller-1     | 	sasl.login.connect.timeout.ms = null
controller-1     | 	sasl.login.read.timeout.ms = null
controller-1     | 	sasl.login.refresh.buffer.seconds = 300
controller-1     | 	sasl.login.refresh.min.period.seconds = 60
controller-1     | 	sasl.login.refresh.window.factor = 0.8
controller-1     | 	sasl.login.refresh.window.jitter = 0.05
controller-1     | 	sasl.login.retry.backoff.max.ms = 10000
controller-1     | 	sasl.login.retry.backoff.ms = 100
controller-1     | 	sasl.mechanism.controller.protocol = GSSAPI
controller-1     | 	sasl.mechanism.inter.broker.protocol = GSSAPI
controller-1     | 	sasl.oauthbearer.assertion.algorithm = RS256
controller-1     | 	sasl.oauthbearer.assertion.claim.aud = null
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
controller-1     | 	sasl.oauthbearer.assertion.claim.iss = null
controller-1     | 	sasl.oauthbearer.assertion.claim.jti.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
controller-1     | 	sasl.oauthbearer.assertion.claim.sub = null
controller-1     | 	sasl.oauthbearer.assertion.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
controller-1     | 	sasl.oauthbearer.assertion.template.file = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.id = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.secret = null
controller-1     | 	sasl.oauthbearer.clock.skew.seconds = 30
controller-1     | 	sasl.oauthbearer.expected.audience = null
controller-1     | 	sasl.oauthbearer.expected.issuer = null
controller-1     | 	sasl.oauthbearer.iat.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jti.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
controller-1     | 	sasl.oauthbearer.jwks.endpoint.url = null
controller-1     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
controller-1     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
controller-1     | 	sasl.oauthbearer.scope = null
controller-1     | 	sasl.oauthbearer.scope.claim.name = scope
controller-1     | 	sasl.oauthbearer.sub.claim.name = sub
controller-1     | 	sasl.oauthbearer.token.endpoint.url = null
controller-1     | 	sasl.server.authn.async.enable = false
controller-1     | 	sasl.server.authn.async.max.threads = 1
controller-1     | 	sasl.server.authn.async.timeout.ms = 30000
controller-1     | 	sasl.server.callback.handler.class = null
controller-1     | 	sasl.server.max.receive.size = 524288
controller-1     | 	security.inter.broker.protocol = PLAINTEXT
controller-1     | 	security.providers = null
controller-1     | 	server.max.startup.time.ms = 9223372036854775807
controller-1     | 	share.coordinator.append.linger.ms = 5
controller-1     | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
controller-1     | 	share.coordinator.load.buffer.size = 5242880
controller-1     | 	share.coordinator.snapshot.update.records.per.snapshot = 500
controller-1     | 	share.coordinator.state.topic.compression.codec = 0
controller-1     | 	share.coordinator.state.topic.min.isr = 2
controller-1     | 	share.coordinator.state.topic.num.partitions = 50
controller-1     | 	share.coordinator.state.topic.prune.interval.ms = 300000
controller-1     | 	share.coordinator.state.topic.replication.factor = 3
controller-1     | 	share.coordinator.state.topic.segment.bytes = 104857600
controller-1     | 	share.coordinator.threads = 1
controller-1     | 	share.coordinator.write.timeout.ms = 5000
controller-1     | 	share.fetch.purgatory.purge.interval.requests = 1000
controller-1     | 	socket.connection.setup.timeout.max.ms = 30000
controller-1     | 	socket.connection.setup.timeout.ms = 10000
controller-1     | 	socket.listen.backlog.size = 50
controller-1     | 	socket.receive.buffer.bytes = 102400
controller-1     | 	socket.request.max.bytes = 104857600
controller-1     | 	socket.send.buffer.bytes = 102400
controller-1     | 	ssl.allow.dn.changes = false
controller-1     | 	ssl.allow.san.changes = false
controller-1     | 	ssl.cipher.suites = []
controller-1     | 	ssl.client.auth = none
controller-1     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
controller-1     | 	ssl.endpoint.identification.algorithm = https
controller-1     | 	ssl.engine.factory.class = null
controller-1     | 	ssl.key.password = null
controller-1     | 	ssl.keymanager.algorithm = SunX509
controller-1     | 	ssl.keystore.certificate.chain = null
controller-1     | 	ssl.keystore.key = null
controller-1     | 	ssl.keystore.location = null
controller-1     | 	ssl.keystore.password = null
controller-1     | 	ssl.keystore.type = JKS
controller-1     | 	ssl.principal.mapping.rules = DEFAULT
controller-1     | 	ssl.protocol = TLSv1.3
controller-1     | 	ssl.provider = null
controller-1     | 	ssl.secure.random.implementation = null
controller-1     | 	ssl.trustmanager.algorithm = PKIX
controller-1     | 	ssl.truststore.certificates = null
controller-1     | 	ssl.truststore.location = null
controller-1     | 	ssl.truststore.password = null
controller-1     | 	ssl.truststore.type = JKS
controller-1     | 	telemetry.max.bytes = 1048576
controller-1     | 	throughput.quota.window.num = 11
controller-1     | 	token.impersonation.validation = true
controller-1     | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
controller-1     | 	transaction.max.timeout.ms = 900000
controller-1     | 	transaction.metadata.load.threads = 32
controller-1     | 	transaction.partition.verification.enable = true
controller-1     | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
controller-1     | 	transaction.state.log.load.buffer.size = 5242880
controller-1     | 	transaction.state.log.min.isr = 2
controller-1     | 	transaction.state.log.num.partitions = 50
controller-1     | 	transaction.state.log.replication.factor = 1
controller-1     | 	transaction.state.log.segment.bytes = 104857600
controller-1     | 	transaction.two.phase.commit.enable = false
controller-1     | 	transactional.id.expiration.ms = 604800000
controller-1     | 	unclean.leader.election.enable = false
controller-1     | 	unclean.leader.election.interval.ms = 300000
controller-1     | 	unstable.api.versions.enable = false
controller-1     | 	unstable.feature.versions.enable = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,875] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,878] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,880] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,884] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,884] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ConfluentControllerMetricsPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:47:59,888] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,889] INFO ConfluentMetricsReporterConfig values: 
controller-1     | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
controller-1     | 	confluent.metrics.reporter.include = .*MaxLag.*|kafka.log:type=Log,name=Size.*|.*name=(ActiveControllerCount|BytesInPerSec|BytesOutPerSec|CaughtUpReplicasCount|FailedFetchRequestsPerSec|FailedProduceRequestsPerSec|InSyncReplicasCount|LeaderCount|LeaderElectionRateAndTimeMs|LocalTimeMs|LogEndOffset|LogStartOffset|NetworkProcessorAvgIdlePercent|NumLogSegments|NumPartitionsInError|OfflinePartitionsCount|ObserverReplicasCount|PartitionCount|RemoteTimeMs|ReplicasCount|RequestHandlerAvgIdlePercent|RequestQueueSize|RequestQueueTimeMs|RequestsPerSec|ResponseQueueSize|ResponseQueueTimeMs|ResponseSendTimeMs|Size|TierSize|TotalFetchRequestsPerSec|TotalLag|TotalProduceRequestsPerSec|TotalSize|TotalTimeMs|UncleanLeaderElectionsPerSec|UnderReplicated|UnderReplicatedPartitions|UnderMinIsrPartitionCount|ZooKeeperDisconnectsPerSec|ZooKeeperExpiresPerSec|TieredPartitionsUndergoingUncleanLeaderRecoveryCount|NonTieredPartitionsUndergoingUncleanLeaderRecoveryCount|TierTopicPartitionsUndergoingUncleanLeaderRecoveryCount|ContiguousUnhealthySamples|ContiguousSamplesEngineThreadGroupsStuck|ContiguousSamplesStorageThreadGroupsStuck|ContiguousSamplesNoStorageThreadMakingProgress).*|.*(BytesFetchedRate).*
controller-1     | 	confluent.metrics.reporter.publish.ms = 15000
controller-1     | 	confluent.metrics.reporter.topic = _confluent-metrics
controller-1     | 	confluent.metrics.reporter.topic.create = true
controller-1     | 	confluent.metrics.reporter.topic.max.message.bytes = 10485760
controller-1     | 	confluent.metrics.reporter.topic.partitions = 12
controller-1     | 	confluent.metrics.reporter.topic.replicas = 1
controller-1     | 	confluent.metrics.reporter.topic.retention.bytes = -1
controller-1     | 	confluent.metrics.reporter.topic.retention.ms = 259200000
controller-1     | 	confluent.metrics.reporter.topic.roll.ms = 14400000
controller-1     | 	confluent.metrics.reporter.volume.metrics.refresh.ms = 15000
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,891] INFO [ConfluentControllerMetricsChanges id=1] set cluster-level min.insync.replicas to 1. (org.apache.kafka.controller.metrics.ConfluentControllerMetricsChanges)
controller-1     | [2025-11-13 18:47:59,892] INFO [ConfluentControllerMetricsChanges id=1] Finished reloading all Confluent controller metrics in 3 ms. (org.apache.kafka.controller.metrics.ConfluentControllerMetricsChanges)
controller-1     | [2025-11-13 18:47:59,892] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing CellControllerMetadataMetricsPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,893] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SbcDataBalanceManager with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,901] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:47:59,913] INFO Balancer received a new Replica Exclusions Image (image: , delta: BrokerReplicaExclusionsDelta{newExclusions=[], removedExclusions=[]}) (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:47:59,953] INFO ProducerConfig values: 
controller-1     | 	acks = -1
controller-1     | 	batch.size = 16384
controller-1     | 	bootstrap.servers = [kafka-1:19092]
controller-1     | 	buffer.memory = 33554432
controller-1     | 	client.dns.lookup = use_all_dns_ips
controller-1     | 	client.id = confluent-metrics-reporter
controller-1     | 	compression.gzip.level = -1
controller-1     | 	compression.lz4.level = 9
controller-1     | 	compression.type = zstd
controller-1     | 	compression.zstd.level = 3
controller-1     | 	confluent.client.switchover.disable = false
controller-1     | 	confluent.lkc.id = null
controller-1     | 	confluent.proxy.protocol.client.address = null
controller-1     | 	confluent.proxy.protocol.client.mode = PROXY
controller-1     | 	confluent.proxy.protocol.client.port = null
controller-1     | 	confluent.proxy.protocol.client.version = NONE
controller-1     | 	confluent.selectable.plugin.class = null
controller-1     | 	connections.max.idle.ms = 540000
controller-1     | 	delivery.timeout.ms = 120000
controller-1     | 	enable.idempotence = false
controller-1     | 	enable.metrics.push = true
controller-1     | 	interceptor.classes = []
controller-1     | 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
controller-1     | 	linger.ms = 500
controller-1     | 	max.block.ms = 60000
controller-1     | 	max.in.flight.requests.per.connection = 1
controller-1     | 	max.request.size = 10485760
controller-1     | 	metadata.max.age.ms = 300000
controller-1     | 	metadata.max.idle.ms = 300000
controller-1     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
controller-1     | 	metadata.recovery.strategy = rebootstrap
controller-1     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
controller-1     | 	metrics.num.samples = 2
controller-1     | 	metrics.recording.level = INFO
controller-1     | 	metrics.sample.window.ms = 30000
controller-1     | 	partitioner.adaptive.partitioning.enable = true
controller-1     | 	partitioner.availability.timeout.ms = 0
controller-1     | 	partitioner.class = null
controller-1     | 	partitioner.ignore.keys = false
controller-1     | 	receive.buffer.bytes = 32768
controller-1     | 	reconnect.backoff.max.ms = 1000
controller-1     | 	reconnect.backoff.ms = 50
controller-1     | 	request.timeout.ms = 30000
controller-1     | 	retries = 2147483647
controller-1     | 	retry.backoff.max.ms = 1000
controller-1     | 	retry.backoff.ms = 500
controller-1     | 	sasl.client.callback.handler.class = null
controller-1     | 	sasl.jaas.config = null
controller-1     | 	sasl.jaas.config.jndi.allowlist = null
controller-1     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
controller-1     | 	sasl.kerberos.min.time.before.relogin = 60000
controller-1     | 	sasl.kerberos.service.name = null
controller-1     | 	sasl.kerberos.ticket.renew.jitter = 0.05
controller-1     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
controller-1     | 	sasl.login.callback.handler.class = null
controller-1     | 	sasl.login.class = null
controller-1     | 	sasl.login.connect.timeout.ms = null
controller-1     | 	sasl.login.read.timeout.ms = null
controller-1     | 	sasl.login.refresh.buffer.seconds = 300
controller-1     | 	sasl.login.refresh.min.period.seconds = 60
controller-1     | 	sasl.login.refresh.window.factor = 0.8
controller-1     | 	sasl.login.refresh.window.jitter = 0.05
controller-1     | 	sasl.login.retry.backoff.max.ms = 10000
controller-1     | 	sasl.login.retry.backoff.ms = 100
controller-1     | 	sasl.mechanism = GSSAPI
controller-1     | 	sasl.oauthbearer.assertion.algorithm = RS256
controller-1     | 	sasl.oauthbearer.assertion.claim.aud = null
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
controller-1     | 	sasl.oauthbearer.assertion.claim.iss = null
controller-1     | 	sasl.oauthbearer.assertion.claim.jti.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
controller-1     | 	sasl.oauthbearer.assertion.claim.sub = null
controller-1     | 	sasl.oauthbearer.assertion.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
controller-1     | 	sasl.oauthbearer.assertion.template.file = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.id = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.secret = null
controller-1     | 	sasl.oauthbearer.clock.skew.seconds = 30
controller-1     | 	sasl.oauthbearer.expected.audience = null
controller-1     | 	sasl.oauthbearer.expected.issuer = null
controller-1     | 	sasl.oauthbearer.header.urlencode = false
controller-1     | 	sasl.oauthbearer.iat.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jti.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
controller-1     | 	sasl.oauthbearer.jwks.endpoint.url = null
controller-1     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
controller-1     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
controller-1     | 	sasl.oauthbearer.scope = null
controller-1     | 	sasl.oauthbearer.scope.claim.name = scope
controller-1     | 	sasl.oauthbearer.sub.claim.name = sub
controller-1     | 	sasl.oauthbearer.token.endpoint.url = null
controller-1     | 	security.protocol = PLAINTEXT
controller-1     | 	security.providers = null
controller-1     | 	send.buffer.bytes = 131072
controller-1     | 	socket.connection.setup.timeout.max.ms = 30000
controller-1     | 	socket.connection.setup.timeout.ms = 10000
controller-1     | 	ssl.cipher.suites = null
controller-1     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
controller-1     | 	ssl.endpoint.identification.algorithm = https
controller-1     | 	ssl.engine.factory.class = null
controller-1     | 	ssl.key.password = null
controller-1     | 	ssl.keymanager.algorithm = SunX509
controller-1     | 	ssl.keystore.certificate.chain = null
controller-1     | 	ssl.keystore.key = null
controller-1     | 	ssl.keystore.location = null
controller-1     | 	ssl.keystore.password = null
controller-1     | 	ssl.keystore.type = JKS
controller-1     | 	ssl.protocol = TLSv1.3
controller-1     | 	ssl.provider = null
controller-1     | 	ssl.secure.random.implementation = null
controller-1     | 	ssl.trustmanager.algorithm = PKIX
controller-1     | 	ssl.truststore.certificates = null
controller-1     | 	ssl.truststore.location = null
controller-1     | 	ssl.truststore.password = null
controller-1     | 	ssl.truststore.type = JKS
controller-1     | 	transaction.timeout.ms = 60000
controller-1     | 	transaction.two.phase.commit.enable = false
controller-1     | 	transactional.id = null
controller-1     | 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:47:59,958] INFO Handling event SbcAlteredExclusionsEvent-4 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:47:59,960] INFO SBC Event SbcMetadataUpdateEvent-1 generated 1 more events to enqueue in the following order - [SbcConfigUpdateEvent-3]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:47:59,961] INFO Handling event SbcLeaderUpdateEvent-2 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:47:59,962] INFO This balancer node is now the metadata quorum leader. Activating kafkadatabalance manager without alive broker snapshot. (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:47:59,962] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:47:59,963] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC config processing delayed. (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:47:59,965] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:47:59,966] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC startup delayed. (io.confluent.databalancer.event.SbcEvent)
kafka-1          | [2025-11-13 18:47:59,989] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:48:00,091] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:48:00,145] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
kafka-1          | [2025-11-13 18:48:00,193] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:48:00,195] INFO [ControllerServer id=1] Node 1 identified 0 potential metadata log encryptor rotation candidates: [] (org.apache.kafka.controller.ClusterControlManager)
controller-1     | [2025-11-13 18:48:00,198] INFO [ControllerServer id=1] Potential metadata log encryptor rotation candidates that are existing in all controllers: [] (org.apache.kafka.controller.ClusterControlManager)
controller-1     | [2025-11-13 18:48:00,199] INFO [ControllerServer id=1] Potential metadata log encryptor rotation candidates that are existing in all brokers: [] (org.apache.kafka.controller.ClusterControlManager)
springcoreapi-1  | 18:48:00.180 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils -- Could not detect default configuration classes for test class [com.joey.stanley.group.project.feedback_api.FeedbackApiApplicationTests]: FeedbackApiApplicationTests does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
controller-1     | [2025-11-13 18:48:00,223] INFO [ControllerServer id=1] Replayed RegisterControllerRecord containing ControllerRegistration(id=1, incarnationId=9-8ijVEERFCkIjmAEBX7CA, zkMigrationReady=false, listeners=[Endpoint(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='controller-1', port=19091)], supportedFeatures={confluent.metadata.version: 7-131, eligible.leader.replicas.version: 0-1, group.version: 0-1, kraft.version: 0-1, metadata.version: 7-27, share.version: 0-1, streams.version: 0-1, transaction.version: 0-2}, metadataEncryptors=[]). (org.apache.kafka.controller.ClusterControlManager)
controller-1     | [2025-11-13 18:48:00,241] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:48:00,241] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:48:00,251] INFO These configurations '[topic.replicas]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:00,254] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:48:00,254] INFO [ControllerRegistrationManager id=1 incarnation=9-8ijVEERFCkIjmAEBX7CA] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
controller-1     | [2025-11-13 18:48:00,252] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:48:00,255] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:48:00,255] INFO Kafka startTimeMs: 1763059680251 (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:48:00,265] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,270] WARN [Producer clientId=confluent-metrics-reporter] Connection to node -1 (kafka-1/172.23.0.5:19092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,270] WARN [Producer clientId=confluent-metrics-reporter] Bootstrap broker kafka-1:19092 (id: -1 rack: null isFenced: false) disconnected (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,273] INFO EventEmitterConfig values: 
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:00,295] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:48:00,308] INFO [RaftManager id=2] Attempting durable transition to FollowerState(fetchTimeoutMs=2000, epoch=1, leader=1, leaderEndpoints=Endpoints(endpoints={ListenerName(CONTROLLER)=controller-1/<unresolved>:19091}), votedKey=Optional.empty, voters=[1], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1427, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafka-1          | [2025-11-13 18:48:00,314] INFO [RaftManager id=2] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=1, leader=1, leaderEndpoints=Endpoints(endpoints={ListenerName(CONTROLLER)=controller-1/<unresolved>:19091}), votedKey=Optional.empty, voters=[1], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1427, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
controller-1     | [2025-11-13 18:48:00,329] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,330] WARN [Producer clientId=confluent-metrics-reporter] Connection to node -1 (kafka-1/172.23.0.5:19092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,330] INFO Linux CPU collector enabled: true (io.confluent.telemetry.ConfluentTelemetryConfig)
controller-1     | [2025-11-13 18:48:00,331] WARN [Producer clientId=confluent-metrics-reporter] Bootstrap broker kafka-1:19092 (id: -1 rack: null isFenced: false) disconnected (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,331] INFO Using cpu metric: io\.confluent\.kafka\.server/server/linux_system_cpu_utilization_1m (io.confluent.telemetry.ConfluentTelemetryConfig)
kafka-1          | [2025-11-13 18:48:00,358] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:48:00,358] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
controller-1     | [2025-11-13 18:48:00,376] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
controller-1     | [2025-11-13 18:48:00,379] WARN no telemetry exporters are enabled (io.confluent.telemetry.ConfluentTelemetryConfig)
kafka-1          | [2025-11-13 18:48:00,393] INFO [broker-2-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:48:00,393] INFO [broker-2-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:48:00,397] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:48:00,411] INFO [broker-2-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:48:00,411] INFO [broker-2-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:48:00,413] INFO [broker-2-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafka-1          | [2025-11-13 18:48:00,413] INFO [broker-2-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node controller-1:19091 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
controller-1     | [2025-11-13 18:48:00,435] INFO [ControllerServer id=1] No previous registration found for broker 2. New incarnation ID is 2EtBPz5qRnCYVvxEMpfzDw.  Generated 0 record(s) to clean up previous incarnations. New broker epoch is 10. (org.apache.kafka.controller.ClusterControlManager)
kafka-1          | [2025-11-13 18:48:00,434] INFO [RaftManager id=2] High watermark set to Optional[LogOffsetMetadata(offset=10, metadata=Optional.empty)] for the first time for epoch 1 (org.apache.kafka.raft.FollowerState)
kafka-1          | [2025-11-13 18:48:00,438] INFO [RaftManager id=2] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@1388627206 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
controller-1     | [2025-11-13 18:48:00,438] INFO [ControllerServer id=1] Node 2 identified 0 potential metadata log encryptor rotation candidates: [] (org.apache.kafka.controller.ClusterControlManager)
controller-1     | [2025-11-13 18:48:00,439] INFO [ControllerServer id=1] Potential metadata log encryptor rotation candidates that are existing in all controllers: [] (org.apache.kafka.controller.ClusterControlManager)
controller-1     | [2025-11-13 18:48:00,439] INFO [ControllerServer id=1] Potential metadata log encryptor rotation candidates that are existing in all brokers: [] (org.apache.kafka.controller.ClusterControlManager)
controller-1     | [2025-11-13 18:48:00,442] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,443] WARN [Producer clientId=confluent-metrics-reporter] Connection to node -1 (kafka-1/172.23.0.5:19092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,443] WARN [Producer clientId=confluent-metrics-reporter] Bootstrap broker kafka-1:19092 (id: -1 rack: null isFenced: false) disconnected (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:00,449] INFO [MetadataLoader id=2] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 0, but the high water mark is 10 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:48:00,450] WARN Ignoring redefinition of existing telemetry label kafka.version (io.confluent.telemetry.ResourceBuilderFacade)
controller-1     | [2025-11-13 18:48:00,463] INFO [ControllerServer id=1] Replayed initial RegisterBrokerRecord for broker 2: RegisterBrokerRecord(brokerId=2, isMigratingZkBroker=false, incarnationId=2EtBPz5qRnCYVvxEMpfzDw, brokerEpoch=10, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka-1', port=19092, securityProtocol=0), BrokerEndpoint(name='EXTERNAL', host='localhost', port=9091, securityProtocol=0)], features=[BrokerFeature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='confluent.metadata.version', minSupportedVersion=7, maxSupportedVersion=131), BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=27), BrokerFeature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='streams.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), BrokerFeature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1)], rack='rack-0', fenced=true, inControlledShutdown=false, degradedComponents=[], metadataEncryptors=[], logDirs=[6bCTz2tZ517tPjzYLk0jFQ]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1          | [2025-11-13 18:48:00,473] INFO [MetadataLoader id=2] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 10 (org.apache.kafka.image.loader.MetadataLoader)
controller-1     | [2025-11-13 18:48:00,478] INFO ConfluentTelemetryConfig values: 
controller-1     | 	confluent.telemetry.api.key = null
controller-1     | 	confluent.telemetry.api.secret = null
controller-1     | 	confluent.telemetry.base.url = https://collector.telemetry.confluent.cloud
controller-1     | 	confluent.telemetry.cluster.id = null
controller-1     | 	confluent.telemetry.debug.enabled = false
controller-1     | 	confluent.telemetry.enabled = false
controller-1     | 	confluent.telemetry.events.collector.include = .*transaction.remove.expired.transaction.cleanup.interval.ms.*|.*transaction.state.log.load.buffer.size.*|.*transaction.state.log.min.isr.*|.*transaction.state.log.num.partitions.*|.*transaction.state.log.replication.factor.*|.*transaction.state.log.segment.bytes.*|.*transactional.id.expiration.ms.*|.*controlled.shutdown.enable.*|.*fetch.max.bytes.*|.*fetch.purgatory.purge.interval.requests.*|.*group.initial.rebalance.delay.ms.*|.*group.max.session.timeout.ms.*|.*group.max.size.*|.*group.min.session.timeout.ms.*|.*log.cleaner.backoff.ms.*|.*log.cleaner.dedupe.buffer.size.*|.*log.cleaner.delete.retention.ms.*|.*log.cleaner.enable.*|.*log.cleaner.io.buffer.load.factor.*|.*log.cleaner.io.buffer.size.*|.*log.cleaner.io.max.bytes.per.second.*|.*log.cleaner.max.compaction.lag.ms.*|.*log.cleaner.min.cleanable.ratio.*|.*log.cleaner.min.compaction.lag.ms.*|.*log.cleaner.threads.*|.*log.cleanup.policy.*|.*log.index.interval.bytes.*|.*log.index.size.max.bytes.*|.*log.message.downconversion.enable.*|.*log.message.format.version.*|.*log.message.timestamp.difference.max.ms.*|.*log.message.timestamp.type.*|.*max.connection.creation.rate.*|.*max.connections.*|.*max.connections.per.ip.*|.*max.incremental.fetch.session.cache.slots.*|.*replica.fetch.backoff.ms.*|.*replica.fetch.max.bytes.*|.*replica.fetch.min.bytes.*|.*replica.fetch.response.max.bytes.*|.*replica.fetch.wait.max.ms.*|.*replica.high.watermark.checkpoint.interval.ms.*|.*replica.lag.time.max.ms.*|.*replica.selector.class.*|.*replica.socket.receive.buffer.bytes.*|.*replica.socket.timeout.ms.*|.*alter.config.policy.class.name.*|.*alter.log.dirs.replication.quota.window.num.*|.*alter.log.dirs.replication.quota.window.size.seconds.*|.*metrics.num.samples.*|.*metrics.recording.level.*|.*metrics.sample.window.ms.*|.*quota.window.num.*|.*quota.window.size.seconds.*|.*replication.quota.window.num.*|.*replication.quota.window.size.seconds.*|.*confluent.balancer.enable.*|.*confluent.balancer.throttle.bytes.per.second.*|.*confluent.balancer.heal.uneven.load.trigger.*|.*confluent.balancer.heal.broker.failure.threshold.ms.*|.*confluent.balancer.disk.max.load.*|.*confluent.balancer.exclude.topic.prefixes.*|.*confluent.balancer.exclude.topic.names.*|.*confluent.tier.local.hotset.bytes.*|.*confluent.tier.local.hotset.ms.*|.*confluent.tier.archiver.num.threads.*|.*confluent.tier.backend.*|.*confluent.tier.enable.*|.*confluent.tier.feature.*|.*confluent.tier.fetcher.num.threads.*|.*confluent.tier.max.partition.fetch.bytes.override.*|.*confluent.tier.metadata.replication.factor.*|.*confluent.operator.managed.*|.*confluent.ansible.managed.*|.*confluent.license.*
controller-1     | 	confluent.telemetry.events.enable = true
controller-1     | 	confluent.telemetry.external.client.metrics.exclude.labels = 
controller-1     | 	confluent.telemetry.metrics.collector.include = .*io.confluent.telemetry/.*.*|.*io\.confluent\.system/(?:.*/)?(process_cpu_load|max_file_descriptor_count|open_file_descriptor_count|system_cpu_load|system_load_average|free_physical_memory_size|total_physical_memory_size|disk_total_bytes|disk_usable_bytes|jvm/mem|jvm/gc).*|.*io.confluent.kafka.server/.*(confluent_audit/audit_log_fallback_rate_per_minute|confluent_audit/audit_log_rate_per_minute|confluent_authorizer/authorization_request_rate_per_minute|confluent_authorizer/authorization_allowed_rate_per_minute|confluent_authorizer/authorization_denied_rate_per_minute|confluent_auth_store/rbac_role_bindings_count|confluent_auth_store/rbac_access_rules_count|confluent_auth_store/acl_access_rules_count).*|.*io.confluent.kafka.server/.*(acl_authorizer/zookeeper_disconnects/total/delta|acl_authorizer/zookeeper_expires/total/delta|broker_failure/zookeeper_disconnects/total/delta|broker_failure/zookeeper_expires/total/delta|broker_topic/bytes_in/total/delta|broker_topic/bytes_out/total/delta|broker_topic/failed_produce_requests/total/delta|broker_topic/failed_fetch_requests/total/delta|broker_topic/produce_message_conversions/total/delta|broker_topic/fetch_message_conversions/total/delta|client_broker_topic/client_bytes_in/delta|client_broker_topic/client_bytes_out/delta|client_broker_topic/client_records_in/delta|client_broker_topic/client_records_out/delta|cluster_link/active_link_count|cluster_link/consumer_offset_committed_rate|cluster_link/consumer_offset_committed_total|cluster_link/fetch_throttle_time_avg|cluster_link/fetch_throttle_time_max|cluster_link/link_count|cluster_link/linked_leader_epoch_change_rate|cluster_link/linked_leader_epoch_change_total|cluster_link/linked_topic_partition_addition_rate|cluster_link/linked_topic_partition_addition_total|cluster_link/mirror_partition_count|cluster_link/mirror_topic_byte_total|cluster_link/mirror_topic_count|cluster_link/mirror_topic_lag|cluster_link/topic_config_update_rate|cluster_link/topic_config_update_total|cluster_link_fetcher/connection_count|cluster_link_fetcher/failed_reauthentication_rate|cluster_link_fetcher/failed_reauthentication_total|cluster_link_fetcher/incoming_byte_rate|cluster_link_fetcher/incoming_byte_total|cluster_link_fetcher/outgoing_byte_rate|cluster_link_fetcher/outgoing_byte_total|cluster_link_fetcher/reauthentication_latency_avg|cluster_link_fetcher_manager/max_lag|controller/active_controller_count|controller/leader_election_rate_and_time_ms|controller/offline_partitions_count|controller/partition_availability|controller/preferred_replica_imbalance_count|controller/tenant_partition_availability|controller/global_under_min_isr_partition_count|controller/unclean_leader_elections/total|controller_channel/connection_close_rate|controller_channel/connection_close_total|controller_channel/connection_count|controller_channel/connection_creation_rate|controller_channel/connection_creation_total|controller_channel/request_size_avg|controller_channel/request_size_max|controller_channel_manager/queue_size|controller_channel_manager/total_queue_size|controller_event_manager/event_queue_size|delayed_operation_purgatory/purgatory_size|executor/zookeeper_disconnects/total/delta|executor/zookeeper_expires/total/delta|fetch/queue_size|fetcher/bytes_per_sec|fetcher_lag/consumer_lag|group_coordinator/partition_load_time_max|log/log_end_offset|log/log_start_offset|log/total_size|log_cleaner_manager/achieved_cleaning_ratio/time/delta|log_cleaner_manager/achieved_cleaning_ratio/total/delta|log_cleaner_manager/compacted_partition_bytes|log_cleaner_manager/max_dirty_percent|log_cleaner_manager/time_since_last_run_ms|log_cleaner_manager/uncleanable_bytes|log_cleaner_manager/uncleanable_partitions_count|replica_alter_log_dirs_manager/max_lag|replica_fetcher/request_size_avg|replica_fetcher/request_size_max|replica_fetcher_manager/max_lag|replica_manager/blocked_on_mirror_source_partition_count|replica_manager/isr_shrinks|replica_manager/leader_count|replica_manager/partition_count|replica_manager/under_min_isr_mirror_partition_count|replica_manager/under_min_isr_partition_count|replica_manager/under_replicated_mirror_partitions|replica_manager/under_replicated_partitions|request/errors/total/delta|request/local_time_ms/time/delta|request/local_time_ms/total/delta|request/queue_size|request/remote_time_ms/time/delta|request/remote_time_ms/total/delta|request/request_queue_time_ms/time/delta|request/request_queue_time_ms/total/delta|request/requests|request/response_queue_time_ms/time/delta|request/response_queue_time_ms/total/delta|request/response_send_time_ms/time/delta|request/response_send_time_ms/total/delta|request/total_time_ms/time/delta|request/total_time_ms/total/delta|request_channel/request_queue_size|request_channel/response_queue_size|request_handler_pool/request_handler_avg_idle_percent|session_expire_listener/zookeeper_disconnects/total/delta|session_expire_listener/zookeeper_expires/total/delta|socket_server/connections|socket_server/successful_authentication_total/delta|socket_server/failed_authentication_total/delta|socket_server/network_processor_avg_idle_percent|socket_server/request_size_avg|socket_server/request_size_max|tenant/consumer_lag_offsets|log/size|partition/replicas_count|partition/under_replicated|tier_tasks/num_partitions_in_error).*|.*org\.apache\.kafka\.(producer\.connection\.creation\.rate|producer\.node\.request\.latency\.avg|producer\.node\.request\.latency\.max|producer\.produce\.throttle\.time\.avg|producer\.produce\.throttle\.time\.max|producer\.record\.queue\.time\.avg|producer\.record\.queue\.time\.max|producer\.connection\.creation\.total|consumer\.connection\.creation\.rate|consumer\.connection\.creation\.total|consumer\.node\.request\.latency\.avg|consumer\.node\.request\.latency\.max|consumer\.poll\.idle\.ratio\.avg|consumer\.coordinator\.commit\.latency\.avg|consumer\.coordinator\.commit\.latency\.max|consumer\.coordinator\.assigned\.partitions|consumer\.coordinator\.rebalance\.latency\.avg|consumer\.coordinator\.rebalance\.latency\.max|consumer\.coordinator\.rebalance\.latency\.total|consumer\.fetch\.manager\.fetch\.latency\.avg|consumer\.fetch\.manager\.fetch\.latency\.max).*|.*\Qio.confluent.hybrid/node_count\E.*
controller-1     | 	confluent.telemetry.metrics.collector.interval.ms = 60000
controller-1     | 	confluent.telemetry.metrics.collector.slo.enabled = false
controller-1     | 	confluent.telemetry.proxy.password = null
controller-1     | 	confluent.telemetry.proxy.url = null
controller-1     | 	confluent.telemetry.proxy.username = null
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:00,485] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:00,486] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC config processing delayed. (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:00,488] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:00,489] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC startup delayed. (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:00,489] INFO VolumeMetricsCollectorConfig values: 
controller-1     | 	confluent.telemetry.metrics.collector.volume.update.ms = 15000
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:00,491] INFO HttpClientConfig values: 
controller-1     | 	api.key = null
controller-1     | 	api.secret = null
controller-1     | 	buffer.batch.duration.max.ms = null
controller-1     | 	buffer.batch.items.max = null
controller-1     | 	buffer.inflight.submissions.max = null
controller-1     | 	buffer.pending.batches.max = null
controller-1     | 	client.attempts.max = null
controller-1     | 	client.base.url = https://collector.telemetry.confluent.cloud
controller-1     | 	client.compression = null
controller-1     | 	client.connect.timeout.ms = null
controller-1     | 	client.metrics.path.override = /v1/metrics
controller-1     | 	client.request.timeout.ms = null
controller-1     | 	client.retry.delay.seconds = null
controller-1     | 	proxy.password = null
controller-1     | 	proxy.url = null
controller-1     | 	proxy.username = null
controller-1     | 	type = httpTelemetryClient
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:00,492] INFO HttpExporterConfig values: 
controller-1     | 	api.key = null
controller-1     | 	api.secret = null
controller-1     | 	buffer.batch.duration.max.ms = null
controller-1     | 	buffer.batch.items.max = null
controller-1     | 	buffer.inflight.submissions.max = null
controller-1     | 	buffer.pending.batches.max = null
controller-1     | 	client = _confluentClient
controller-1     | 	client.attempts.max = null
controller-1     | 	client.base.url = null
controller-1     | 	client.compression = null
controller-1     | 	client.connect.timeout.ms = null
controller-1     | 	client.metrics.path.override = /v1/metrics
controller-1     | 	client.request.timeout.ms = null
controller-1     | 	client.retry.delay.seconds = null
controller-1     | 	enabled = false
controller-1     | 	events.enabled = true
controller-1     | 	metrics.enabled = true
controller-1     | 	metrics.include = null
controller-1     | 	proxy.password = null
controller-1     | 	proxy.url = null
controller-1     | 	proxy.username = null
controller-1     | 	remote.configurable = true
controller-1     | 	type = http
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:00,492] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
controller-1     | [2025-11-13 18:48:00,494] WARN no telemetry exporters are enabled (io.confluent.telemetry.ConfluentTelemetryConfig)
controller-1     | [2025-11-13 18:48:00,494] INFO Initializing the event logger (io.confluent.telemetry.reporter.TelemetryReporter)
kafka-1          | [2025-11-13 18:48:00,499] INFO [BrokerLifecycleManager id=2] Successfully registered broker 2 with broker epoch 10 (kafka.server.BrokerLifecycleManager)
controller-1     | [2025-11-13 18:48:00,500] INFO EventLoggerConfig values: 
controller-1     | 	event.logger.cloudevent.codec = structured
controller-1     | 	event.logger.exporter.class = class io.confluent.telemetry.events.exporter.http.EventHttpExporter
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:00,499] INFO [BrokerLifecycleManager id=2] Successfully registered broker 2 with broker epoch 10 (kafka.server.BrokerLifecycleManager)
controller-1     | [2025-11-13 18:48:00,521] INFO HttpExporterConfig values: 
controller-1     | 	api.key = null
controller-1     | 	api.secret = null
controller-1     | 	buffer.batch.duration.max.ms = null
controller-1     | 	buffer.batch.items.max = null
controller-1     | 	buffer.inflight.submissions.max = null
controller-1     | 	buffer.pending.batches.max = null
controller-1     | 	client.attempts.max = null
controller-1     | 	client.base.url = https://collector.telemetry.confluent.cloud
controller-1     | 	client.compression = null
controller-1     | 	client.connect.timeout.ms = null
controller-1     | 	client.request.timeout.ms = null
controller-1     | 	client.retry.delay.seconds = null
controller-1     | 	enabled = true
controller-1     | 	events.enabled = true
controller-1     | 	filtering.enabled = false
controller-1     | 	filtering.routes.allowed = []
controller-1     | 	metrics.enabled = true
controller-1     | 	proxy.password = null
controller-1     | 	proxy.url = null
controller-1     | 	proxy.username = null
controller-1     | 	type = http
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:00,521] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 9 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:48:00,566] INFO [BrokerLifecycleManager id=2] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
kafka-1          | [2025-11-13 18:48:00,566] INFO [BrokerLifecycleManager id=2] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
kafka-1          | [2025-11-13 18:48:00,568] INFO [BrokerServer id=2] Finished waiting for broker metadata to catch up (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,568] INFO [BrokerServer id=2] Finished waiting for broker metadata to catch up (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,595] INFO [BrokerLifecycleManager id=2] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
kafka-1          | [2025-11-13 18:48:00,595] INFO [BrokerLifecycleManager id=2] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
kafka-1          | [2025-11-13 18:48:00,635] INFO Starting DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
kafka-1          | [2025-11-13 18:48:00,635] INFO Starting DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
controller-1     | [2025-11-13 18:48:00,637] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:00,638] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC config processing delayed. (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:00,638] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:00,638] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC startup delayed. (io.confluent.databalancer.event.SbcEvent)
kafka-1          | [2025-11-13 18:48:00,639] INFO Attempting to initiate DynamicMetricsReporters. Attempt: 1 (kafka.server.DynamicMetricsReportersScheduler)
kafka-1          | [2025-11-13 18:48:00,639] INFO Attempting to initiate DynamicMetricsReporters. Attempt: 1 (kafka.server.DynamicMetricsReportersScheduler)
controller-1     | [2025-11-13 18:48:00,656] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,656] WARN [Producer clientId=confluent-metrics-reporter] Connection to node -1 (kafka-1/172.23.0.5:19092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:00,658] WARN [Producer clientId=confluent-metrics-reporter] Bootstrap broker kafka-1:19092 (id: -1 rack: null isFenced: false) disconnected (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:00,671] INFO [BrokerServer id=2] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,671] INFO [BrokerServer id=2] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,674] INFO [BrokerServer id=2] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,674] INFO [BrokerServer id=2] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,674] INFO [BrokerServer id=2] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,674] INFO [BrokerServer id=2] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,675] INFO [BrokerServer id=2] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,675] INFO [BrokerServer id=2] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,675] INFO [BrokerServer id=2] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,675] INFO [BrokerServer id=2] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:00,677] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing MetadataVersionPublisher(id=2) with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:48:00,678] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:48:00,724] INFO [BrokerMetadataPublisher id=2] Publishing initial metadata at offset OffsetAndEpoch[offset=11, epoch=1] with metadata.version Optional[4.1-IV1A]. (kafka.server.metadata.BrokerMetadataPublisher)
kafka-1          | [2025-11-13 18:48:00,724] INFO [BrokerMetadataPublisher id=2] Publishing initial metadata at offset OffsetAndEpoch[offset=11, epoch=1] with metadata.version Optional[4.1-IV1A]. (kafka.server.metadata.BrokerMetadataPublisher)
kafka-1          | [2025-11-13 18:48:00,726] INFO Loading logs from log dirs ArrayBuffer(/var/lib/kafka/data) (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,726] INFO Loading logs from log dirs ArrayBuffer(/var/lib/kafka/data) (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,735] INFO No logs found to be loaded in /var/lib/kafka/data (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,735] INFO No logs found to be loaded in /var/lib/kafka/data (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,769] INFO Loaded 0 logs in 30ms (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,769] INFO Loaded 0 logs in 30ms (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,770] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,770] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,773] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,773] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,775] INFO Starting log roller with a period of 300000 ms. (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,775] INFO Starting log roller with a period of 300000 ms. (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:00,799] INFO ConfluentMetricsReporterConfig values: 
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.metrics.reporter.include = .*MaxLag.*|kafka.log:type=Log,name=Size.*|.*name=(ActiveControllerCount|BytesInPerSec|BytesOutPerSec|CaughtUpReplicasCount|FailedFetchRequestsPerSec|FailedProduceRequestsPerSec|InSyncReplicasCount|LeaderCount|LeaderElectionRateAndTimeMs|LocalTimeMs|LogEndOffset|LogStartOffset|NetworkProcessorAvgIdlePercent|NumLogSegments|NumPartitionsInError|OfflinePartitionsCount|ObserverReplicasCount|PartitionCount|RemoteTimeMs|ReplicasCount|RequestHandlerAvgIdlePercent|RequestQueueSize|RequestQueueTimeMs|RequestsPerSec|ResponseQueueSize|ResponseQueueTimeMs|ResponseSendTimeMs|Size|TierSize|TotalFetchRequestsPerSec|TotalLag|TotalProduceRequestsPerSec|TotalSize|TotalTimeMs|UncleanLeaderElectionsPerSec|UnderReplicated|UnderReplicatedPartitions|UnderMinIsrPartitionCount|ZooKeeperDisconnectsPerSec|ZooKeeperExpiresPerSec|TieredPartitionsUndergoingUncleanLeaderRecoveryCount|NonTieredPartitionsUndergoingUncleanLeaderRecoveryCount|TierTopicPartitionsUndergoingUncleanLeaderRecoveryCount|ContiguousUnhealthySamples|ContiguousSamplesEngineThreadGroupsStuck|ContiguousSamplesStorageThreadGroupsStuck|ContiguousSamplesNoStorageThreadMakingProgress).*|.*(BytesFetchedRate).*
kafka-1          | 	confluent.metrics.reporter.publish.ms = 15000
kafka-1          | 	confluent.metrics.reporter.topic = _confluent-metrics
kafka-1          | 	confluent.metrics.reporter.topic.create = true
kafka-1          | 	confluent.metrics.reporter.topic.max.message.bytes = 10485760
kafka-1          | 	confluent.metrics.reporter.topic.partitions = 12
kafka-1          | 	confluent.metrics.reporter.topic.replicas = 3
kafka-1          | 	confluent.metrics.reporter.topic.retention.bytes = -1
kafka-1          | 	confluent.metrics.reporter.topic.retention.ms = 259200000
kafka-1          | 	confluent.metrics.reporter.topic.roll.ms = 14400000
kafka-1          | 	confluent.metrics.reporter.volume.metrics.refresh.ms = 15000
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:00,802] INFO Starting the log cleaner (org.apache.kafka.storage.internals.log.LogCleaner)
controller-1     | [2025-11-13 18:48:00,819] INFO [Producer clientId=confluent-metrics-reporter] Rebootstrapping with [kafka-1/172.23.0.5:19092] (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:00,825] INFO ProducerConfig values: 
kafka-1          | 	acks = -1
kafka-1          | 	batch.size = 16384
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	buffer.memory = 33554432
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = confluent-metrics-reporter
kafka-1          | 	compression.gzip.level = -1
kafka-1          | 	compression.lz4.level = 9
kafka-1          | 	compression.type = zstd
kafka-1          | 	compression.zstd.level = 3
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 540000
kafka-1          | 	delivery.timeout.ms = 120000
kafka-1          | 	enable.idempotence = false
kafka-1          | 	enable.metrics.push = true
kafka-1          | 	interceptor.classes = []
kafka-1          | 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
kafka-1          | 	linger.ms = 500
kafka-1          | 	max.block.ms = 60000
kafka-1          | 	max.in.flight.requests.per.connection = 1
kafka-1          | 	max.request.size = 10485760
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.max.idle.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = rebootstrap
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	partitioner.adaptive.partitioning.enable = true
kafka-1          | 	partitioner.availability.timeout.ms = 0
kafka-1          | 	partitioner.class = null
kafka-1          | 	partitioner.ignore.keys = false
kafka-1          | 	receive.buffer.bytes = 32768
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	retries = 2147483647
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 500
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	transaction.timeout.ms = 60000
kafka-1          | 	transaction.two.phase.commit.enable = false
kafka-1          | 	transactional.id = null
kafka-1          | 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
springcoreapi-1  | 18:48:00.812 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper -- Found @SpringBootConfiguration com.joey.stanley.group.project.feedback_api.FeedbackApiApplication for test class com.joey.stanley.group.project.feedback_api.FeedbackApiApplicationTests
controller-1     | [2025-11-13 18:48:00,879] INFO [Producer clientId=confluent-metrics-reporter] Rebootstrapping with [kafka-1/172.23.0.5:19092] (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:00,921] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
controller-1     | [2025-11-13 18:48:00,931] INFO [Producer clientId=confluent-metrics-reporter] Rebootstrapping with [kafka-1/172.23.0.5:19092] (org.apache.kafka.clients.Metadata)
controller-1     | [2025-11-13 18:48:00,984] INFO [Producer clientId=confluent-metrics-reporter] Rebootstrapping with [kafka-1/172.23.0.5:19092] (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:01,010] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:01,011] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:01,011] INFO Kafka startTimeMs: 1763059681008 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:01,024] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,028] WARN [Producer clientId=confluent-metrics-reporter] Connection to node -1 (kafka-1/172.23.0.5:19092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,035] WARN [Producer clientId=confluent-metrics-reporter] Bootstrap broker kafka-1:19092 (id: -1 rack: null isFenced: false) disconnected (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:01,038] INFO [Producer clientId=confluent-metrics-reporter] Rebootstrapping with [kafka-1/172.23.0.5:19092] (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:01,039] INFO Starting Confluent metrics reporter for cluster id Nk018hRAQFytWskYqtQduw with an interval of 15000 ms (io.confluent.metrics.reporter.ConfluentMetricsReporter)
kafka-1          | [2025-11-13 18:48:01,045] INFO DynamicMetricsReporters initiated successfully. (kafka.server.DynamicMetricsReportersScheduler)
kafka-1          | [2025-11-13 18:48:01,045] INFO DynamicMetricsReporters initiated successfully. (kafka.server.DynamicMetricsReportersScheduler)
kafka-1          | [2025-11-13 18:48:01,045] INFO Stopping DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
kafka-1          | [2025-11-13 18:48:01,045] INFO Stopping DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
kafka-1          | [2025-11-13 18:48:01,081] INFO [kafka-log-cleaner-thread-0]: Starting (org.apache.kafka.storage.internals.log.LogCleaner$CleanerThread)
kafka-1          | [2025-11-13 18:48:01,091] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:01,090] INFO [Producer clientId=confluent-metrics-reporter] Rebootstrapping with [kafka-1/172.23.0.5:19092] (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:01,091] WARN [Producer clientId=confluent-metrics-reporter] Connection to node -1 (kafka-1/172.23.0.5:19092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,096] WARN [Producer clientId=confluent-metrics-reporter] Bootstrap broker kafka-1:19092 (id: -1 rack: null isFenced: false) disconnected (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,102] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka-1          | [2025-11-13 18:48:01,102] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka-1          | [2025-11-13 18:48:01,106] INFO [AddPartitionsToTxnSenderThread-2]: Starting (org.apache.kafka.server.transaction.AddPartitionsToTxnManager)
kafka-1          | [2025-11-13 18:48:01,109] INFO [GroupCoordinator id=2] Starting up. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
kafka-1          | [2025-11-13 18:48:01,113] INFO [GroupCoordinator id=2] Startup complete. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
kafka-1          | [2025-11-13 18:48:01,116] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka-1          | [2025-11-13 18:48:01,116] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka-1          | [2025-11-13 18:48:01,121] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka-1          | [2025-11-13 18:48:01,121] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka-1          | [2025-11-13 18:48:01,122] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka-1          | [2025-11-13 18:48:01,122] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
controller-1     | [2025-11-13 18:48:01,137] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:01,138] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC config processing delayed. (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:01,138] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:01,139] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC startup delayed. (io.confluent.databalancer.event.SbcEvent)
kafka-1          | [2025-11-13 18:48:01,144] INFO [ShareCoordinator id=2] Starting up. (org.apache.kafka.coordinator.share.ShareCoordinatorService)
controller-1     | [2025-11-13 18:48:01,145] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
controller-1     | [2025-11-13 18:48:01,146] WARN [Producer clientId=confluent-metrics-reporter] Connection to node -1 (kafka-1/172.23.0.5:19092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,146] INFO [ShareCoordinator id=2] Startup complete. (org.apache.kafka.coordinator.share.ShareCoordinatorService)
controller-1     | [2025-11-13 18:48:01,147] WARN [Producer clientId=confluent-metrics-reporter] Bootstrap broker kafka-1:19092 (id: -1 rack: null isFenced: false) disconnected (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,208] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,209] WARN [Producer clientId=confluent-metrics-reporter] Connection to node -1 (kafka-1/172.23.0.5:19092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,209] WARN [Producer clientId=confluent-metrics-reporter] Bootstrap broker kafka-1:19092 (id: -1 rack: null isFenced: false) disconnected (org.apache.kafka.clients.NetworkClient)
kafka-1          | [2025-11-13 18:48:01,218] INFO [DynamicConfigPublisher broker id=2] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafka-1          | [2025-11-13 18:48:01,218] INFO [DynamicConfigPublisher broker id=2] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafka-1          | [2025-11-13 18:48:01,253] INFO KafkaConfig values: 
kafka-1          | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafka-1          | 	add.partitions.to.txn.retry.backoff.ms = 20
kafka-1          | 	advertised.listeners = PLAINTEXT://kafka-1:19092, EXTERNAL://localhost:9091
kafka-1          | 	alter.config.policy.class.name = null
kafka-1          | 	alter.log.dirs.replication.quota.window.num = 11
kafka-1          | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka-1          | 	authorizer.class.name = 
kafka-1          | 	auto.create.topics.enable = true
kafka-1          | 	auto.leader.rebalance.enable = true
kafka-1          | 	background.threads = 10
kafka-1          | 	broker.heartbeat.interval.ms = 2000
kafka-1          | 	broker.id = 2
kafka-1          | 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
kafka-1          | 	broker.rack = rack-0
kafka-1          | 	broker.session.timeout.ms = 9000
kafka-1          | 	broker.session.uuid = Cq1QTtEwT2CoFqEpv4E8ZA
kafka-1          | 	client.quota.callback.class = null
kafka-1          | 	client.quota.max.throttle.time.in.response.ms = 60000
kafka-1          | 	client.quota.max.throttle.time.ms = 5000
kafka-1          | 	compression.gzip.level = -1
kafka-1          | 	compression.lz4.level = 9
kafka-1          | 	compression.type = producer
kafka-1          | 	compression.zstd.level = 3
kafka-1          | 	confluent.accp.enabled = false
kafka-1          | 	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
kafka-1          | 	confluent.alter.broker.health.max.demoted.brokers = 2147483647
kafka-1          | 	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
kafka-1          | 	confluent.ansible.managed = false
kafka-1          | 	confluent.api.visibility = DEFAULT
kafka-1          | 	confluent.append.record.interceptor.classes = []
kafka-1          | 	confluent.apply.create.topic.policy.to.create.partitions = false
kafka-1          | 	confluent.authorizer.authority.name = 
kafka-1          | 	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
kafka-1          | 	confluent.backpressure.disk.enable = false
kafka-1          | 	confluent.backpressure.disk.free.threshold.bytes = 21474836480
kafka-1          | 	confluent.backpressure.disk.produce.bytes.per.second = 131072
kafka-1          | 	confluent.backpressure.disk.threshold.recovery.factor = 1.5
kafka-1          | 	confluent.backpressure.request.min.broker.limit = 200
kafka-1          | 	confluent.backpressure.request.queue.size.percentile = p95
kafka-1          | 	confluent.backpressure.types = null
kafka-1          | 	confluent.balancer.api.state.topic = _confluent_balancer_api_state
kafka-1          | 	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
kafka-1          | 	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
kafka-1          | 	confluent.balancer.capacity.threshold.upper.limit = 0.95
kafka-1          | 	confluent.balancer.cell.load.upper.bound = 0.7
kafka-1          | 	confluent.balancer.cell.overload.detection.interval.ms = 3600000
kafka-1          | 	confluent.balancer.cell.overload.duration.ms = 86400000
kafka-1          | 	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
kafka-1          | 	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.cpu.balance.threshold = 1.1
kafka-1          | 	confluent.balancer.cpu.goal.act.as.capacity.goal = false
kafka-1          | 	confluent.balancer.cpu.low.utilization.threshold = 0.2
kafka-1          | 	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
kafka-1          | 	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
kafka-1          | 	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
kafka-1          | 	confluent.balancer.disk.max.load = 0.85
kafka-1          | 	confluent.balancer.disk.min.free.space.gb = 0
kafka-1          | 	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
kafka-1          | 	confluent.balancer.disk.utilization.detector.duration.ms = 600000
kafka-1          | 	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
kafka-1          | 	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
kafka-1          | 	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
kafka-1          | 	confluent.balancer.enable = true
kafka-1          | 	confluent.balancer.enable.network.capacity.metric.ingestion = false
kafka-1          | 	confluent.balancer.exclude.topic.names = []
kafka-1          | 	confluent.balancer.exclude.topic.prefixes = []
kafka-1          | 	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
kafka-1          | 	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
kafka-1          | 	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
kafka-1          | 	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
kafka-1          | 	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
kafka-1          | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
kafka-1          | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
kafka-1          | 	confluent.balancer.incremental.balancing.enabled = false
kafka-1          | 	confluent.balancer.incremental.balancing.goals = []
kafka-1          | 	confluent.balancer.incremental.balancing.lower.bound = 0.02
kafka-1          | 	confluent.balancer.incremental.balancing.min.valid.windows = 5
kafka-1          | 	confluent.balancer.incremental.balancing.step.ratio = 0.2
kafka-1          | 	confluent.balancer.inter.cell.balancing.enabled = false
kafka-1          | 	confluent.balancer.inter.cell.movements.excluded.tenant.ids = []
kafka-1          | 	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
kafka-1          | 	confluent.balancer.max.replicas = 2147483647
kafka-1          | 	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
kafka-1          | 	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
kafka-1          | 	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
kafka-1          | 	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
kafka-1          | 	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.rebalancing.goals = []
kafka-1          | 	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.resource.utilization.detector.interval.ms = 60000
kafka-1          | 	confluent.balancer.sbc.metrics.parser.enabled = false
kafka-1          | 	confluent.balancer.self.healing.maximum.rounds = 1
kafka-1          | 	confluent.balancer.task.history.retention.days = 30
kafka-1          | 	confluent.balancer.tenant.maximum.movements = 0
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.consume_out = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.cpu = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.nw_in = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.nw_out = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.produce_in = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.replica_count = 3
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.consume_out = 614400.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.cpu = 300.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_in = 204800.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_out = 614400.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.produce_in = 204800.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.replica_count = 45000.0
kafka-1          | 	confluent.balancer.tenant.striping.enable.dry.run.mode = true
kafka-1          | 	confluent.balancer.tenant.striping.enabled = false
kafka-1          | 	confluent.balancer.tenant.striping.expiry.counter.threshold = 10
kafka-1          | 	confluent.balancer.tenant.striping.rate.limit = 3
kafka-1          | 	confluent.balancer.tenant.striping.resource.usage.expiry.ms = 3600000
kafka-1          | 	confluent.balancer.tenant.suspension.ms = 86400000
kafka-1          | 	confluent.balancer.throttle.bytes.per.second = 10485760
kafka-1          | 	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
kafka-1          | 	confluent.balancer.topic.partition.maximum.movements = 3
kafka-1          | 	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
kafka-1          | 	confluent.balancer.topic.partition.movements.history.limit = 900
kafka-1          | 	confluent.balancer.topic.partition.suspension.ms = 3600000
kafka-1          | 	confluent.balancer.topic.replication.factor = 3
kafka-1          | 	confluent.balancer.triggering.goals = []
kafka-1          | 	confluent.balancer.v2.addition.enabled = false
kafka-1          | 	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
kafka-1          | 	confluent.balancer.v2.executor.enabled = false
kafka-1          | 	confluent.basic.auth.credentials.source = null
kafka-1          | 	confluent.basic.auth.user.info = null
kafka-1          | 	confluent.bearer.assertion.claim.aud = null
kafka-1          | 	confluent.bearer.assertion.claim.exp.minutes = null
kafka-1          | 	confluent.bearer.assertion.claim.iss = null
kafka-1          | 	confluent.bearer.assertion.claim.jti.include = null
kafka-1          | 	confluent.bearer.assertion.claim.nbf.include = null
kafka-1          | 	confluent.bearer.assertion.claim.sub = null
kafka-1          | 	confluent.bearer.assertion.file = null
kafka-1          | 	confluent.bearer.assertion.private.key.file = null
kafka-1          | 	confluent.bearer.assertion.private.key.passphrase = null
kafka-1          | 	confluent.bearer.assertion.template.file = null
kafka-1          | 	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
kafka-1          | 	confluent.bearer.auth.client.id = null
kafka-1          | 	confluent.bearer.auth.client.secret = null
kafka-1          | 	confluent.bearer.auth.credentials.source = null
kafka-1          | 	confluent.bearer.auth.identity.pool.id = null
kafka-1          | 	confluent.bearer.auth.issuer.endpoint.url = null
kafka-1          | 	confluent.bearer.auth.logical.cluster = null
kafka-1          | 	confluent.bearer.auth.scope = null
kafka-1          | 	confluent.bearer.auth.scope.claim.name = scope
kafka-1          | 	confluent.bearer.auth.sub.claim.name = sub
kafka-1          | 	confluent.bearer.auth.token = null
kafka-1          | 	confluent.broker.health.manager.enabled = true
kafka-1          | 	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
kafka-1          | 	confluent.broker.health.manager.hard.kill.duration.ms = 60000
kafka-1          | 	confluent.broker.health.manager.mitigation.enabled = false
kafka-1          | 	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
kafka-1          | 	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
kafka-1          | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
kafka-1          | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
kafka-1          | 	confluent.broker.health.manager.sample.duration.ms = 1000
kafka-1          | 	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.broker.load.advertised.limit.load = 0.8
kafka-1          | 	confluent.broker.load.average.service.request.time.ms = 0.1
kafka-1          | 	confluent.broker.load.delay.metric.start.ms = 180000
kafka-1          | 	confluent.broker.load.enabled = false
kafka-1          | 	confluent.broker.load.num.samples = 60
kafka-1          | 	confluent.broker.load.tenant.metric.enable = false
kafka-1          | 	confluent.broker.load.update.metric.tags.interval.ms = 60000
kafka-1          | 	confluent.broker.load.window.size.ms = 60000
kafka-1          | 	confluent.broker.load.workload.coefficient = 20.0
kafka-1          | 	confluent.broker.registration.delay.ms = 0
kafka-1          | 	confluent.broker.type = confluent_platform
kafka-1          | 	confluent.broker.type.topic.enabled = true
kafka-1          | 	confluent.calling.resource.identity.type.map = 
kafka-1          | 	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
kafka-1          | 	confluent.catalog.collector.enable = false
kafka-1          | 	confluent.catalog.collector.full.configs.enable = false
kafka-1          | 	confluent.catalog.collector.max.bytes.per.snapshot = 850000
kafka-1          | 	confluent.catalog.collector.max.topics.process = 500
kafka-1          | 	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
kafka-1          | 	confluent.catalog.collector.multitenant.topics.enable = true
kafka-1          | 	confluent.catalog.collector.snapshot.init.delay.sec = 60
kafka-1          | 	confluent.catalog.collector.snapshot.interval.sec = 300
kafka-1          | 	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
kafka-1          | 	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
kafka-1          | 	confluent.cdc.api.keys.topic = 
kafka-1          | 	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
kafka-1          | 	confluent.cdc.client.quotas.enable = false
kafka-1          | 	confluent.cdc.client.quotas.topic.name = 
kafka-1          | 	confluent.cdc.lkc.metadata.topic = 
kafka-1          | 	confluent.cdc.user.metadata.enable = false
kafka-1          | 	confluent.cdc.user.metadata.topic = _confluent-user_metadata
kafka-1          | 	confluent.cell.metrics.refresh.period.ms = 60000
kafka-1          | 	confluent.cells.default.size = 15
kafka-1          | 	confluent.cells.enable = false
kafka-1          | 	confluent.cells.implicit.creation.enable = false
kafka-1          | 	confluent.cells.k2.base.broker.index = -1
kafka-1          | 	confluent.cells.load.refresher.enable = true
kafka-1          | 	confluent.cells.max.size = 15
kafka-1          | 	confluent.cells.min.size = 6
kafka-1          | 	confluent.checksum.enabled.files = [none]
kafka-1          | 	confluent.client.topic.max.metrics.count = 1000
kafka-1          | 	confluent.client.topic.metrics.expiry.sec = 3600
kafka-1          | 	confluent.client.topic.metrics.ignore_client_id_pattern = (?:link-.*-)?broker-\d+-fetcher-\d+(?:-pool-.*)?
kafka-1          | 	confluent.client.topic.metrics.ignore_internal_topic_pattern = _.*
kafka-1          | 	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
kafka-1          | 	confluent.clm.enabled = false
kafka-1          | 	confluent.clm.frequency.in.hours = 6
kafka-1          | 	confluent.clm.list.object.thread_pool.size = 1
kafka-1          | 	confluent.clm.max.backup.days = 3
kafka-1          | 	confluent.clm.min.delay.in.minutes = 30
kafka-1          | 	confluent.clm.thread.pool.size = 2
kafka-1          | 	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
kafka-1          | 	confluent.close.connections.on.credential.delete = false
kafka-1          | 	confluent.cluster.link.admin.max.in.flight.requests = 1000
kafka-1          | 	confluent.cluster.link.admin.request.batch.size = 1
kafka-1          | 	confluent.cluster.link.allow.config.providers = true
kafka-1          | 	confluent.cluster.link.allow.legacy.message.format = false
kafka-1          | 	confluent.cluster.link.allow.truncation.below.hwm = false
kafka-1          | 	confluent.cluster.link.availability.check.mode = ALL
kafka-1          | 	confluent.cluster.link.background.thread.affinity = LINK
kafka-1          | 	confluent.cluster.link.bootstrap.translation.feature.enable = true
kafka-1          | 	confluent.cluster.link.clients.max.idle.ms = 3153600000000
kafka-1          | 	confluent.cluster.link.enable = false
kafka-1          | 	confluent.cluster.link.enable.local.admin = false
kafka-1          | 	confluent.cluster.link.enable.metrics.reduction = false
kafka-1          | 	confluent.cluster.link.enable.metrics.reduction.advanced = false
kafka-1          | 	confluent.cluster.link.fetch.response.min.bytes = 1
kafka-1          | 	confluent.cluster.link.fetch.response.total.bytes = 2147483647
kafka-1          | 	confluent.cluster.link.fetcher.auto.tune.enable = false
kafka-1          | 	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
kafka-1          | 	confluent.cluster.link.insync.fetch.response.min.bytes = 1
kafka-1          | 	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
kafka-1          | 	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
kafka-1          | 	confluent.cluster.link.intranet.connectivity.enable = false
kafka-1          | 	confluent.cluster.link.intranet.connectivity.migration.enable = false
kafka-1          | 	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.cluster.link.k1.to.k2.migration.enable = false
kafka-1          | 	confluent.cluster.link.k2.mirror.topic.metadata.enable = false
kafka-1          | 	confluent.cluster.link.local.admin.multitenant.enable = false
kafka-1          | 	confluent.cluster.link.local.reverse.connection.listener.map = null
kafka-1          | 	confluent.cluster.link.max.client.connections = 2147483647
kafka-1          | 	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
kafka-1          | 	confluent.cluster.link.metadata.topic.enable = false
kafka-1          | 	confluent.cluster.link.metadata.topic.min.isr = 2
kafka-1          | 	confluent.cluster.link.metadata.topic.partitions = 50
kafka-1          | 	confluent.cluster.link.metadata.topic.replication.factor = 3
kafka-1          | 	confluent.cluster.link.mirror.transition.batch.size = 10
kafka-1          | 	confluent.cluster.link.num.background.threads = 1
kafka-1          | 	confluent.cluster.link.num.fetchers = 1
kafka-1          | 	confluent.cluster.link.periodic.task.batch.size = 2147483647
kafka-1          | 	confluent.cluster.link.periodic.task.min.interval.ms = 1000
kafka-1          | 	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
kafka-1          | 	confluent.cluster.link.replica.fetch.connections.mode = combined
kafka-1          | 	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
kafka-1          | 	confluent.cluster.link.replication.quota.mode.per.tenant.overrides = 
kafka-1          | 	confluent.cluster.link.replication.quota.window.num = 11
kafka-1          | 	confluent.cluster.link.replication.quota.window.size.seconds = 2
kafka-1          | 	confluent.cluster.link.request.quota.capacity = 400
kafka-1          | 	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
kafka-1          | 	confluent.cluster.link.switchover.disabled.principals = []
kafka-1          | 	confluent.cluster.link.switchover.enable = false
kafka-1          | 	confluent.cluster.link.switchover.listeners = []
kafka-1          | 	confluent.cluster.link.switchover.server.states = []
kafka-1          | 	confluent.cluster.link.tenant.replication.quota.enable = false
kafka-1          | 	confluent.cluster.link.tenant.request.quota.enable = false
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.enable = false
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.upload.enable = false
kafka-1          | 	confluent.compacted.topic.prefer.tier.fetch.ms = -1
kafka-1          | 	confluent.connection.invalid.request.delay.enable = false
kafka-1          | 	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
kafka-1          | 	confluent.consumer.fetch.partition.pruning.enable = true
kafka-1          | 	confluent.consumer.lag.emitter.enabled = false
kafka-1          | 	confluent.consumer.lag.emitter.interval.ms = 60000
kafka-1          | 	confluent.dataflow.policy.watch.monitor.ms = 300000
kafka-1          | 	confluent.default.data.policy.enforcement = true
kafka-1          | 	confluent.defer.isr.shrink.enable = false
kafka-1          | 	confluent.describe.topic.partitions.enabled = true
kafka-1          | 	confluent.disk.io.manager.enable = false
kafka-1          | 	confluent.disk.throughput.headroom = 10485760
kafka-1          | 	confluent.disk.throughput.limit = 10485760000
kafka-1          | 	confluent.disk.throughput.quota.tier.archive = 1048576000
kafka-1          | 	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
kafka-1          | 	confluent.durability.audit.batch.flush.frequency.ms = 900000
kafka-1          | 	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
kafka-1          | 	confluent.durability.audit.enable = false
kafka-1          | 	confluent.durability.audit.idempotent.producer = false
kafka-1          | 	confluent.durability.audit.initial.job.delay.ms = 900000
kafka-1          | 	confluent.durability.audit.io.bytes.per.sec = 10485760
kafka-1          | 	confluent.durability.audit.log.ignored.event.types = 
kafka-1          | 	confluent.durability.audit.reporting.batch.ms = 1800000
kafka-1          | 	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
kafka-1          | 	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
kafka-1          | 	confluent.durability.topic.partition.count = 50
kafka-1          | 	confluent.durability.topic.replication.factor = 3
kafka-1          | 	confluent.e2e_checksum.protection.enabled = false
kafka-1          | 	confluent.e2e_checksum.protection.files = [none]
kafka-1          | 	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
kafka-1          | 	confluent.elastic.cku.enabled = false
kafka-1          | 	confluent.elastic.cku.scaletozero.enabled = false
kafka-1          | 	confluent.eligible.controllers = []
kafka-1          | 	confluent.emit.network.type.default = 
kafka-1          | 	confluent.emit.network.type.tag = false
kafka-1          | 	confluent.enable.broker.reporting.min.usage.mode = true
kafka-1          | 	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
kafka-1          | 	confluent.fail.unsatisfied.placement.constraints = false
kafka-1          | 	confluent.fetch.from.follower.require.leader.epoch.enable = false
kafka-1          | 	confluent.fetch.partition.pruning.enable = true
kafka-1          | 	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
kafka-1          | 	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
kafka-1          | 	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
kafka-1          | 	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
kafka-1          | 	confluent.flexible.fanout.enabled = false
kafka-1          | 	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
kafka-1          | 	confluent.flexible.fanout.mode = TENANT_QUOTA
kafka-1          | 	confluent.floor.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.floor.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.group.coordinator.dynamic.append.linger.enable = false
kafka-1          | 	confluent.group.coordinator.max.partition.queue.size = -1
kafka-1          | 	confluent.group.coordinator.offsets.batching.enable = false
kafka-1          | 	confluent.group.coordinator.offsets.writer.threads = 2
kafka-1          | 	confluent.group.coordinator.slow.event.log.count = 10
kafka-1          | 	confluent.group.coordinator.slow.event.log.interval.ms = -1
kafka-1          | 	confluent.group.coordinator.txn.offset.validation.enable = false
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.count = 10
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.enable = false
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
kafka-1          | 	confluent.group.metadata.load.threads = 32
kafka-1          | 	confluent.group.subscription.pattern.log.interval.ms = -1
kafka-1          | 	confluent.heap.tenured.notify.bytes = 0
kafka-1          | 	confluent.heap.tenured.notify.enabled = false
kafka-1          | 	confluent.hot.partition.ratio = 0.8
kafka-1          | 	confluent.http.server.start.timeout.ms = 60000
kafka-1          | 	confluent.http.server.stop.timeout.ms = 30000
kafka-1          | 	confluent.intelligent.replication.enable = false
kafka-1          | 	confluent.intelligent.replication.push.max.memory.buffer.bytes = 209715200
kafka-1          | 	confluent.intelligent.replication.push.max.threads = 4
kafka-1          | 	confluent.intelligent.replication.push.threads.per.remote.broker = 1
kafka-1          | 	confluent.internal.metrics.enable = false
kafka-1          | 	confluent.internal.rest.server.bind.port = null
kafka-1          | 	confluent.internal.rest.server.ssl.enable = false
kafka-1          | 	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
kafka-1          | 	confluent.lat.network.context.verification.enable = false
kafka-1          | 	confluent.leader.epoch.checkpoint.checksum.enabled = false
kafka-1          | 	confluent.listener.protocol = TCP
kafka-1          | 	confluent.log.cleaner.timestamp.validation.enable = true
kafka-1          | 	confluent.log.placement.constraints = 
kafka-1          | 	confluent.max.broker.load = 1.0
kafka-1          | 	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
kafka-1          | 	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
kafka-1          | 	confluent.max.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.max.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.max.connection.throttle.ms = null
kafka-1          | 	confluent.max.segment.ms = 9223372036854775807
kafka-1          | 	confluent.metadata.active.encryptor = null
kafka-1          | 	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
kafka-1          | 	confluent.metadata.encryptor.classes = null
kafka-1          | 	confluent.metadata.encryptor.required = false
kafka-1          | 	confluent.metadata.encryptor.secret.file = null
kafka-1          | 	confluent.metadata.encryptor.secrets = null
kafka-1          | 	confluent.metadata.jvm.warmup.ms = 60000
kafka-1          | 	confluent.metadata.leader.balance.slice.delay.ms = 100
kafka-1          | 	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
kafka-1          | 	confluent.metadata.max.leader.balance.changes.per.slice = 1000
kafka-1          | 	confluent.metadata.rbac_auth.read.controller.enable = false
kafka-1          | 	confluent.metadata.rbac_auth.update.controller.enable = false
kafka-1          | 	confluent.metadata.reject.when.throttled.enable = false
kafka-1          | 	confluent.metadata.server.cluster.registry.clusters = []
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.min.acks = 0
kafka-1          | 	confluent.min.connection.throttle.ms = 0
kafka-1          | 	confluent.min.segment.ms = 1
kafka-1          | 	confluent.missing.id.cache.ttl.sec = 60
kafka-1          | 	confluent.missing.id.query.range = 20000
kafka-1          | 	confluent.missing.schema.cache.ttl.sec = 60
kafka-1          | 	confluent.mtls.build.client.cert.chain.enable = false
kafka-1          | 	confluent.mtls.enable = false
kafka-1          | 	confluent.mtls.listener.name = EXTERNAL
kafka-1          | 	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
kafka-1          | 	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
kafka-1          | 	confluent.mtls.truststore.manager.class.name = null
kafka-1          | 	confluent.multitenant.authorizer.enable.acl.state = false
kafka-1          | 	confluent.multitenant.interceptor.balancer.apis.enabled = false
kafka-1          | 	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
kafka-1          | 	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
kafka-1          | 	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
kafka-1          | 	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
kafka-1          | 	confluent.multitenant.listener.names = null
kafka-1          | 	confluent.multitenant.parse.lkc.id.enable = false
kafka-1          | 	confluent.multitenant.parse.sni.host.name.enable = false
kafka-1          | 	confluent.network.health.manager.enabled = false
kafka-1          | 	confluent.network.health.manager.external.listener.name = EXTERNAL
kafka-1          | 	confluent.network.health.manager.externalconnectivitystartup.enabled = false
kafka-1          | 	confluent.network.health.manager.min.healthy.network.samples = 3
kafka-1          | 	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
kafka-1          | 	confluent.network.health.manager.mitigation.enabled = false
kafka-1          | 	confluent.network.health.manager.network.sample.window.size = 120
kafka-1          | 	confluent.network.health.manager.sample.duration.ms = 1000
kafka-1          | 	confluent.oauth.flat.networking.verification.enable = false
kafka-1          | 	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
kafka-1          | 	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1          | 	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
kafka-1          | 	confluent.offsets.topic.max.message.bytes = -1
kafka-1          | 	confluent.offsets.topic.placement.constraints = 
kafka-1          | 	confluent.omit.network.processor.metric.tag = false
kafka-1          | 	confluent.operator.managed = false
kafka-1          | 	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
kafka-1          | 	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
kafka-1          | 	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
kafka-1          | 	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
kafka-1          | 	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
kafka-1          | 	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
kafka-1          | 	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
kafka-1          | 	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.enable = false
kafka-1          | 	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.cloud = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.domain = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.region = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variables = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.templates = 
kafka-1          | 	confluent.prefer.tier.fetch.ms = -1
kafka-1          | 	confluent.produce.throttle.pre.check.enable = false
kafka-1          | 	confluent.produce.throttle.pre.check.for.new.connection.enable = false
kafka-1          | 	confluent.producer.id.cache.broker.hard.limit = -1
kafka-1          | 	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
kafka-1          | 	confluent.producer.id.cache.extra.eviction.percentage = 0
kafka-1          | 	confluent.producer.id.cache.limit = 2147483647
kafka-1          | 	confluent.producer.id.cache.partition.hard.limit = -1
kafka-1          | 	confluent.producer.id.cache.tenant.hard.limit = -1
kafka-1          | 	confluent.producer.id.quota.manager.enable = false
kafka-1          | 	confluent.producer.id.quota.window.num = 11
kafka-1          | 	confluent.producer.id.quota.window.size.seconds = 1
kafka-1          | 	confluent.producer.id.throttle.enable = false
kafka-1          | 	confluent.producer.id.throttle.enable.threshold.percentage = 100
kafka-1          | 	confluent.protocol.netty.http2.connection.window.size = 31457280
kafka-1          | 	confluent.protocol.netty.http2.flow.control.enabled = true
kafka-1          | 	confluent.protocol.netty.http2.initial.window.size = 153600
kafka-1          | 	confluent.protocol.netty.http2.max.frame.size = 16384
kafka-1          | 	confluent.protocol.netty.http2.stream.graceful.close.timeout.ms = 60000
kafka-1          | 	confluent.protocol.netty.num.boss.threads = 1
kafka-1          | 	confluent.protocol.netty.num.worker.threads = 4
kafka-1          | 	confluent.proxy.mode.local.default = false
kafka-1          | 	confluent.proxy.protocol.fallback.enabled = false
kafka-1          | 	confluent.proxy.protocol.parser = class io.confluent.kafka.common.network.CloudProxyTlvParser
kafka-1          | 	confluent.proxy.protocol.version = NONE
kafka-1          | 	confluent.quota.computing.usage.adjustment = 0.5
kafka-1          | 	confluent.quota.dynamic.adjustment.min.usage = 102400
kafka-1          | 	confluent.quota.dynamic.enable = false
kafka-1          | 	confluent.quota.dynamic.publishing.interval.ms = 60000
kafka-1          | 	confluent.quota.dynamic.reporting.interval.ms = 30000
kafka-1          | 	confluent.quota.tenant.broker.max.consumer.rate = 13107200
kafka-1          | 	confluent.quota.tenant.broker.max.producer.rate = 13107200
kafka-1          | 	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
kafka-1          | 	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
kafka-1          | 	confluent.quota.tenant.fetch.multiplier = 1.0
kafka-1          | 	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
kafka-1          | 	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
kafka-1          | 	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.broker.max.controller.mutation.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.throttling.enable = false
kafka-1          | 	confluent.quota.tenant.produce.multiplier = 1.0
kafka-1          | 	confluent.quota.tenant.user.quotas.enable = false
kafka-1          | 	confluent.rack.id.mapping = null
kafka-1          | 	confluent.regional.metadata.client.class = null
kafka-1          | 	confluent.regional.resource.manager.client.scheduler.threads = 2
kafka-1          | 	confluent.regional.resource.manager.endpoint = null
kafka-1          | 	confluent.regional.resource.manager.grpc.endpoint = null
kafka-1          | 	confluent.reject.invalid.sni.hostnames = false
kafka-1          | 	confluent.replica.fetch.backoff.max.ms = 1000
kafka-1          | 	confluent.replica.fetch.connections.mode = combined
kafka-1          | 	confluent.replication.mode = PULL
kafka-1          | 	confluent.replication.push.feature.enable = false
kafka-1          | 	confluent.reporters.telemetry.auto.enable = false
kafka-1          | 	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
kafka-1          | 	confluent.request.pipelining.enable = true
kafka-1          | 	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
kafka-1          | 	confluent.require.calling.resource.identity = false
kafka-1          | 	confluent.require.compatible.keystore.updates = true
kafka-1          | 	confluent.require.confluent.issuer = false
kafka-1          | 	confluent.roll.check.interval.ms = 300000
kafka-1          | 	confluent.schema.registry.max.cache.size = 10000
kafka-1          | 	confluent.schema.registry.max.retries = 1
kafka-1          | 	confluent.schema.registry.retries.wait.ms = 0
kafka-1          | 	confluent.schema.registry.url = null
kafka-1          | 	confluent.schema.validation.context.name.enable = false
kafka-1          | 	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
kafka-1          | 	confluent.schema.validator.multitenant.enable = false
kafka-1          | 	confluent.schema.validator.samples.per.min = 0
kafka-1          | 	confluent.security.bc.approved.mode.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.authorization.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
kafka-1          | 	confluent.security.event.logger.enable = true
kafka-1          | 	confluent.security.event.logger.kafka.request.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.physical.cluster.id = 
kafka-1          | 	confluent.security.event.router.config = 
kafka-1          | 	confluent.security.revoked.certificate.ids = 
kafka-1          | 	confluent.segment.eager.roll.enable = false
kafka-1          | 	confluent.segment.speculative.prefetch.enable = false
kafka-1          | 	confluent.share.coordinator.slow.event.log.count = 10
kafka-1          | 	confluent.share.coordinator.slow.event.log.interval.ms = -1
kafka-1          | 	confluent.share.metadata.load.threads = 32
kafka-1          | 	confluent.spiffe.id.principal.extraction.rules = 
kafka-1          | 	confluent.ssl.key.password = null
kafka-1          | 	confluent.ssl.keystore.location = null
kafka-1          | 	confluent.ssl.keystore.password = null
kafka-1          | 	confluent.ssl.keystore.type = null
kafka-1          | 	confluent.ssl.protocol = null
kafka-1          | 	confluent.ssl.truststore.location = null
kafka-1          | 	confluent.ssl.truststore.password = null
kafka-1          | 	confluent.ssl.truststore.type = null
kafka-1          | 	confluent.step.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.step.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.storage.probe.disk.metrics.collection.enabled = false
kafka-1          | 	confluent.storage.probe.period.ms = -1
kafka-1          | 	confluent.storage.probe.slow.write.threshold.ms = 5000
kafka-1          | 	confluent.stray.log.delete.delay.ms = 604800000
kafka-1          | 	confluent.stray.log.max.deletions.per.run = 72
kafka-1          | 	confluent.subdomain.prefix = null
kafka-1          | 	confluent.subdomain.separator.map = null
kafka-1          | 	confluent.subdomain.separator.variable = %sep
kafka-1          | 	confluent.system.time.roll.enable = false
kafka-1          | 	confluent.telemetry.enabled = false
kafka-1          | 	confluent.telemetry.external.client.metrics.delta.temporality = true
kafka-1          | 	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
kafka-1          | 	confluent.telemetry.external.client.metrics.push.enabled = false
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.match.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.supported.compression.types = [zstd, lz4, gzip, snappy]
kafka-1          | 	confluent.tenant.latency.metric.enabled = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.enable = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.proactive.key.generation.enable = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
kafka-1          | 	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
kafka-1          | 	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
kafka-1          | 	confluent.tier.archiver.num.threads = 2
kafka-1          | 	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
kafka-1          | 	confluent.tier.azure.block.blob.container = null
kafka-1          | 	confluent.tier.azure.block.blob.cred.file.path = null
kafka-1          | 	confluent.tier.azure.block.blob.endpoint = null
kafka-1          | 	confluent.tier.azure.block.blob.prefix = 
kafka-1          | 	confluent.tier.backend = 
kafka-1          | 	confluent.tier.bucket.probe.period.ms = -1
kafka-1          | 	confluent.tier.cleaner.compact.min.efficiency = 0.5
kafka-1          | 	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
kafka-1          | 	confluent.tier.cleaner.dedupe.buffer.size = 134217728
kafka-1          | 	confluent.tier.cleaner.dual.compaction = false
kafka-1          | 	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
kafka-1          | 	confluent.tier.cleaner.dual.compaction.validation.percent = 0
kafka-1          | 	confluent.tier.cleaner.enable = false
kafka-1          | 	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
kafka-1          | 	confluent.tier.cleaner.feature.enable = false
kafka-1          | 	confluent.tier.cleaner.io.buffer.load.factor = 0.9
kafka-1          | 	confluent.tier.cleaner.io.buffer.size = 10485760
kafka-1          | 	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1          | 	confluent.tier.cleaner.min.cleanable.ratio = 0.75
kafka-1          | 	confluent.tier.cleaner.num.threads = 2
kafka-1          | 	confluent.tier.enable = false
kafka-1          | 	confluent.tier.feature = false
kafka-1          | 	confluent.tier.fenced.segment.delete.delay.ms = 600000
kafka-1          | 	confluent.tier.fetcher.async.enable = false
kafka-1          | 	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
kafka-1          | 	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
kafka-1          | 	confluent.tier.fetcher.memorypool.bytes = 0
kafka-1          | 	confluent.tier.fetcher.num.threads = 4
kafka-1          | 	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
kafka-1          | 	confluent.tier.fetcher.offset.cache.period.ms = 60000
kafka-1          | 	confluent.tier.fetcher.offset.cache.size = 200000
kafka-1          | 	confluent.tier.gcs.bucket = null
kafka-1          | 	confluent.tier.gcs.cred.file.path = null
kafka-1          | 	confluent.tier.gcs.prefix = 
kafka-1          | 	confluent.tier.gcs.region = null
kafka-1          | 	confluent.tier.gcs.sse.customer.encryption.key = null
kafka-1          | 	confluent.tier.gcs.write.chunk.size = 0
kafka-1          | 	confluent.tier.local.hotset.bytes = -1
kafka-1          | 	confluent.tier.local.hotset.ms = 86400000
kafka-1          | 	confluent.tier.max.partition.fetch.bytes.override = 0
kafka-1          | 	confluent.tier.metadata.bootstrap.servers = null
kafka-1          | 	confluent.tier.metadata.catchup.max.poll.ms = 0
kafka-1          | 	confluent.tier.metadata.max.poll.ms = 100
kafka-1          | 	confluent.tier.metadata.namespace = null
kafka-1          | 	confluent.tier.metadata.num.partitions = 50
kafka-1          | 	confluent.tier.metadata.replication.factor = 3
kafka-1          | 	confluent.tier.metadata.request.timeout.ms = 30000
kafka-1          | 	confluent.tier.metadata.snapshots.enable = false
kafka-1          | 	confluent.tier.metadata.snapshots.interval.ms = 86400000
kafka-1          | 	confluent.tier.metadata.snapshots.retention.days = 7
kafka-1          | 	confluent.tier.metadata.snapshots.threads = 2
kafka-1          | 	confluent.tier.object.fetcher.num.threads = 1
kafka-1          | 	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
kafka-1          | 	confluent.tier.partition.state.cleanup.enable = false
kafka-1          | 	confluent.tier.partition.state.cleanup.interval.ms = 86400000
kafka-1          | 	confluent.tier.partition.state.commit.interval.ms = 15000
kafka-1          | 	confluent.tier.prefetch.cache.enable = false
kafka-1          | 	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
kafka-1          | 	confluent.tier.prefetch.cache.range.bytes = 5242880
kafka-1          | 	confluent.tier.prefetch.cache.total.size.bytes = 209715200
kafka-1          | 	confluent.tier.s3.assumerole.arn = null
kafka-1          | 	confluent.tier.s3.auto.abort.threshold.bytes = 500000
kafka-1          | 	confluent.tier.s3.aws.endpoint.override = null
kafka-1          | 	confluent.tier.s3.aws.signer.override = null
kafka-1          | 	confluent.tier.s3.bucket = null
kafka-1          | 	confluent.tier.s3.cred.file.path = null
kafka-1          | 	confluent.tier.s3.force.path.style.access = false
kafka-1          | 	confluent.tier.s3.ipv6.enabled = true
kafka-1          | 	confluent.tier.s3.prefix = 
kafka-1          | 	confluent.tier.s3.region = null
kafka-1          | 	confluent.tier.s3.security.providers = null
kafka-1          | 	confluent.tier.s3.sse.algorithm = AES256
kafka-1          | 	confluent.tier.s3.sse.customer.encryption.key = null
kafka-1          | 	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	confluent.tier.s3.ssl.key.password = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.location = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.password = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.type = null
kafka-1          | 	confluent.tier.s3.ssl.protocol = TLSv1.3
kafka-1          | 	confluent.tier.s3.ssl.provider = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.location = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.password = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.type = null
kafka-1          | 	confluent.tier.s3.storage.class.override = 
kafka-1          | 	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
kafka-1          | 	confluent.tier.s3.v2.enabled = false
kafka-1          | 	confluent.tier.segment.hotset.roll.min.bytes = 104857600
kafka-1          | 	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
kafka-1          | 	confluent.tier.topic.data.loss.validation.fencing.enable = false
kafka-1          | 	confluent.tier.topic.delete.backoff.ms = 21600000
kafka-1          | 	confluent.tier.topic.delete.check.interval.ms = 300000
kafka-1          | 	confluent.tier.topic.delete.max.inprogress.partitions = 100
kafka-1          | 	confluent.tier.topic.head.data.loss.validation.enable = true
kafka-1          | 	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
kafka-1          | 	confluent.tier.topic.materialization.from.snapshot.enable = false
kafka-1          | 	confluent.tier.topic.producer.enable.idempotence = true
kafka-1          | 	confluent.tier.topic.snapshots.enable = false
kafka-1          | 	confluent.tier.topic.snapshots.interval.ms = 300000
kafka-1          | 	confluent.tier.topic.snapshots.max.records = 100000
kafka-1          | 	confluent.tier.topic.snapshots.retention.hours = 168
kafka-1          | 	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
kafka-1          | 	confluent.topic.partition.default.placement = 2
kafka-1          | 	confluent.topic.policy.use.computed.assignments = false
kafka-1          | 	confluent.topic.replica.assignor.builder.class = 
kafka-1          | 	confluent.track.api.key.per.ip = false
kafka-1          | 	confluent.track.per.ip.max.size = 100000
kafka-1          | 	confluent.track.tenant.id.per.ip = false
kafka-1          | 	confluent.traffic.cdc.network.id.routes.enable = false
kafka-1          | 	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
kafka-1          | 	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
kafka-1          | 	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
kafka-1          | 	confluent.traffic.network.id = 
kafka-1          | 	confluent.traffic.network.type = 
kafka-1          | 	confluent.transaction.2pc.timeout.ms = -1
kafka-1          | 	confluent.transaction.logging.verbosity = 0
kafka-1          | 	confluent.transaction.state.log.placement.constraints = 
kafka-1          | 	confluent.unique.deprecated.request.metrics.per.tenant = 1000
kafka-1          | 	confluent.valid.broker.rack.set = null
kafka-1          | 	confluent.valid.sni.hostnames = 
kafka-1          | 	confluent.valid.sni.hostnames.exclude.suffix = 
kafka-1          | 	confluent.verify.group.subscription.prefix = false
kafka-1          | 	confluent.virtual.topic.creation.enabled = false
kafka-1          | 	confluent.zone.tagged.request.metrics.enable = false
kafka-1          | 	connection.failed.authentication.delay.ms = 100
kafka-1          | 	connection.min.expire.interval.ms = 250
kafka-1          | 	connections.max.age.ms = 3153600000000
kafka-1          | 	connections.max.idle.ms = 600000
kafka-1          | 	connections.max.reauth.ms = 0
kafka-1          | 	controlled.shutdown.enable = true
kafka-1          | 	controller.listener.names = CONTROLLER
kafka-1          | 	controller.performance.always.log.threshold.ms = 2000
kafka-1          | 	controller.performance.sample.period.ms = 60000
kafka-1          | 	controller.quorum.append.linger.ms = 25
kafka-1          | 	controller.quorum.bootstrap.servers = []
kafka-1          | 	controller.quorum.election.backoff.max.ms = 1000
kafka-1          | 	controller.quorum.election.timeout.ms = 1000
kafka-1          | 	controller.quorum.fetch.timeout.ms = 2000
kafka-1          | 	controller.quorum.request.timeout.ms = 2000
kafka-1          | 	controller.quorum.retry.backoff.ms = 20
kafka-1          | 	controller.quorum.voters = [1@controller-1:19091]
kafka-1          | 	controller.quota.window.num = 11
kafka-1          | 	controller.quota.window.size.seconds = 1
kafka-1          | 	controller.socket.timeout.ms = 30000
kafka-1          | 	create.cluster.link.policy.class.name = null
kafka-1          | 	create.topic.policy.class.name = null
kafka-1          | 	default.replication.factor = 1
kafka-1          | 	delegation.token.expiry.check.interval.ms = 3600000
kafka-1          | 	delegation.token.expiry.time.ms = 86400000
kafka-1          | 	delegation.token.max.lifetime.ms = 604800000
kafka-1          | 	delegation.token.secret.key = null
kafka-1          | 	delete.records.purgatory.purge.interval.requests = 1
kafka-1          | 	delete.topic.enable = true
kafka-1          | 	early.start.listeners = null
kafka-1          | 	enable.fips = false
kafka-1          | 	fetch.max.bytes = 57671680
kafka-1          | 	fetch.purgatory.purge.interval.requests = 1000
kafka-1          | 	floor.max.connection.creation.rate = null
kafka-1          | 	follower.replication.throttled.rate = 9223372036854775807
kafka-1          | 	follower.replication.throttled.replicas = none
kafka-1          | 	group.consumer.assignors = [uniform, range]
kafka-1          | 	group.consumer.heartbeat.interval.ms = 5000
kafka-1          | 	group.consumer.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.consumer.max.session.timeout.ms = 60000
kafka-1          | 	group.consumer.max.size = 2147483647
kafka-1          | 	group.consumer.migration.policy = bidirectional
kafka-1          | 	group.consumer.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.consumer.min.session.timeout.ms = 45000
kafka-1          | 	group.consumer.regex.refresh.interval.ms = 600000
kafka-1          | 	group.consumer.session.timeout.ms = 45000
kafka-1          | 	group.coordinator.append.linger.ms = 5
kafka-1          | 	group.coordinator.rebalance.protocols = [classic, consumer, share, streams]
kafka-1          | 	group.coordinator.threads = 4
kafka-1          | 	group.initial.rebalance.delay.ms = 0
kafka-1          | 	group.max.session.timeout.ms = 1800000
kafka-1          | 	group.max.size = 2147483647
kafka-1          | 	group.min.session.timeout.ms = 6000
kafka-1          | 	group.share.assignors = [simple]
kafka-1          | 	group.share.delivery.count.limit = 5
kafka-1          | 	group.share.enable = false
kafka-1          | 	group.share.heartbeat.interval.ms = 5000
kafka-1          | 	group.share.initialize.retry.interval.ms = 30000
kafka-1          | 	group.share.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.share.max.record.lock.duration.ms = 60000
kafka-1          | 	group.share.max.session.timeout.ms = 60000
kafka-1          | 	group.share.max.share.sessions = 2000
kafka-1          | 	group.share.max.size = 200
kafka-1          | 	group.share.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.share.min.record.lock.duration.ms = 15000
kafka-1          | 	group.share.min.session.timeout.ms = 45000
kafka-1          | 	group.share.partition.max.record.locks = 2000
kafka-1          | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafka-1          | 	group.share.record.lock.duration.ms = 30000
kafka-1          | 	group.share.rollout.ready = true
kafka-1          | 	group.share.session.timeout.ms = 45000
kafka-1          | 	group.streams.heartbeat.interval.ms = 5000
kafka-1          | 	group.streams.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.streams.max.session.timeout.ms = 60000
kafka-1          | 	group.streams.max.size = 2147483647
kafka-1          | 	group.streams.max.standby.replicas = 2
kafka-1          | 	group.streams.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.streams.min.session.timeout.ms = 45000
kafka-1          | 	group.streams.num.standby.replicas = 0
kafka-1          | 	group.streams.session.timeout.ms = 45000
kafka-1          | 	initial.broker.registration.timeout.ms = 60000
kafka-1          | 	inter.broker.listener.name = PLAINTEXT
kafka-1          | 	internal.metadata.delete.delay.millis = 60000
kafka-1          | 	internal.metadata.log.segment.bytes = null
kafka-1          | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafka-1          | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafka-1          | 	k2.stack.builder.class.name = null
kafka-1          | 	k2.startup.timeout.ms = 60000
kafka-1          | 	k2.topic.metadata.refresh.ms = 10000
kafka-1          | 	kafka.metrics.polling.interval.secs = 10
kafka-1          | 	kafka.metrics.reporters = []
kafka-1          | 	leader.imbalance.check.interval.seconds = 300
kafka-1          | 	leader.replication.throttled.rate = 9223372036854775807
kafka-1          | 	leader.replication.throttled.replicas = none
kafka-1          | 	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
kafka-1          | 	listeners = PLAINTEXT://kafka-1:19092, EXTERNAL://0.0.0.0:9091
kafka-1          | 	log.cleaner.backoff.ms = 15000
kafka-1          | 	log.cleaner.dedupe.buffer.size = 134217728
kafka-1          | 	log.cleaner.delete.retention.ms = 86400000
kafka-1          | 	log.cleaner.enable = true
kafka-1          | 	log.cleaner.hash.algorithm = MD5
kafka-1          | 	log.cleaner.io.buffer.load.factor = 0.9
kafka-1          | 	log.cleaner.io.buffer.size = 524288
kafka-1          | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1          | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1          | 	log.cleaner.min.cleanable.ratio = 0.5
kafka-1          | 	log.cleaner.min.compaction.lag.ms = 0
kafka-1          | 	log.cleaner.threads = 1
kafka-1          | 	log.cleanup.policy = [delete]
kafka-1          | 	log.cleanup.policy.empty.validation = none
kafka-1          | 	log.deletion.max.segments.per.run = 2147483647
kafka-1          | 	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
kafka-1          | 	log.dir = /tmp/kafka-logs
kafka-1          | 	log.dir.failure.timeout.ms = 30000
kafka-1          | 	log.dirs = /var/lib/kafka/data
kafka-1          | 	log.flush.interval.messages = 9223372036854775807
kafka-1          | 	log.flush.interval.ms = null
kafka-1          | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka-1          | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka-1          | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka-1          | 	log.index.interval.bytes = 4096
kafka-1          | 	log.index.size.max.bytes = 10485760
kafka-1          | 	log.initial.task.delay.ms = 30000
kafka-1          | 	log.local.retention.bytes = -2
kafka-1          | 	log.local.retention.ms = -2
kafka-1          | 	log.message.timestamp.after.max.ms = 3600000
kafka-1          | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafka-1          | 	log.message.timestamp.type = CreateTime
kafka-1          | 	log.preallocate = false
kafka-1          | 	log.retention.bytes = -1
kafka-1          | 	log.retention.check.interval.ms = 300000
kafka-1          | 	log.retention.hours = 168
kafka-1          | 	log.retention.minutes = null
kafka-1          | 	log.retention.ms = null
kafka-1          | 	log.roll.hours = 168
kafka-1          | 	log.roll.jitter.hours = 0
kafka-1          | 	log.roll.jitter.ms = null
kafka-1          | 	log.roll.ms = null
kafka-1          | 	log.segment.bytes = 1073741824
kafka-1          | 	log.segment.delete.delay.ms = 60000
kafka-1          | 	max.connection.creation.rate = 1.7976931348623157E308
kafka-1          | 	max.connection.creation.rate.per.ip.enable.threshold = 0.0
kafka-1          | 	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
kafka-1          | 	max.connections = 2147483647
kafka-1          | 	max.connections.per.ip = 2147483647
kafka-1          | 	max.connections.per.ip.overrides = 
kafka-1          | 	max.connections.per.tenant = 0
kafka-1          | 	max.connections.protected.listeners = []
kafka-1          | 	max.connections.reap.amount = 0
kafka-1          | 	max.incremental.fetch.session.cache.slots = 1000
kafka-1          | 	max.request.partition.size.limit = 2000
kafka-1          | 	message.max.bytes = 1048588
kafka-1          | 	metadata.log.dir = null
kafka-1          | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafka-1          | 	metadata.log.max.snapshot.interval.ms = 3600000
kafka-1          | 	metadata.log.segment.bytes = 1073741824
kafka-1          | 	metadata.log.segment.ms = 604800000
kafka-1          | 	metadata.max.idle.interval.ms = 500
kafka-1          | 	metadata.max.retention.bytes = 104857600
kafka-1          | 	metadata.max.retention.ms = 604800000
kafka-1          | 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	min.insync.replicas = 1
kafka-1          | 	multitenant.authorizer.support.resource.ids = false
kafka-1          | 	multitenant.metadata.class = null
kafka-1          | 	multitenant.metadata.dir = null
kafka-1          | 	multitenant.metadata.reload.delay.ms = 120000
kafka-1          | 	multitenant.metadata.ssl.certs.path = null
kafka-1          | 	multitenant.tenant.delete.batch.size = 10
kafka-1          | 	multitenant.tenant.delete.check.ms = 120000
kafka-1          | 	multitenant.tenant.delete.delay = 604800000
kafka-1          | 	node.id = 2
kafka-1          | 	num.io.threads = 8
kafka-1          | 	num.network.threads = 3
kafka-1          | 	num.partitions = 1
kafka-1          | 	num.recovery.threads.per.data.dir = 2
kafka-1          | 	num.replica.alter.log.dirs.threads = null
kafka-1          | 	num.replica.fetchers = 1
kafka-1          | 	offset.metadata.max.bytes = 4096
kafka-1          | 	offsets.commit.timeout.ms = 5000
kafka-1          | 	offsets.load.buffer.size = 5242880
kafka-1          | 	offsets.retention.check.interval.ms = 600000
kafka-1          | 	offsets.retention.minutes = 10080
kafka-1          | 	offsets.topic.compression.codec = 0
kafka-1          | 	offsets.topic.num.partitions = 50
kafka-1          | 	offsets.topic.replication.factor = 3
kafka-1          | 	offsets.topic.segment.bytes = 104857600
kafka-1          | 	otel.exporter.otlp.custom.endpoint = default
kafka-1          | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka-1          | 	process.roles = [broker]
kafka-1          | 	producer.id.expiration.check.interval.ms = 600000
kafka-1          | 	producer.id.expiration.ms = 86400000
kafka-1          | 	producer.purgatory.purge.interval.requests = 1000
kafka-1          | 	queued.max.request.bytes = -1
kafka-1          | 	queued.max.requests = 500
kafka-1          | 	quota.window.num = 11
kafka-1          | 	quota.window.size.seconds = 1
kafka-1          | 	quotas.consumption.expiration.time.ms = 600000
kafka-1          | 	quotas.expiration.interval.ms = 3600000
kafka-1          | 	quotas.expiration.time.ms = 604800000
kafka-1          | 	quotas.lazy.evaluation.threshold = 0.5
kafka-1          | 	quotas.topic.append.timeout.ms = 5000
kafka-1          | 	quotas.topic.compression.codec = 3
kafka-1          | 	quotas.topic.load.buffer.size = 5242880
kafka-1          | 	quotas.topic.num.partitions = 50
kafka-1          | 	quotas.topic.placement.constraints = 
kafka-1          | 	quotas.topic.replication.factor = 3
kafka-1          | 	quotas.topic.segment.bytes = 104857600
kafka-1          | 	remote.fetch.max.wait.ms = 500
kafka-1          | 	remote.list.offsets.request.timeout.ms = 30000
kafka-1          | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafka-1          | 	remote.log.manager.copier.thread.pool.size = 10
kafka-1          | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafka-1          | 	remote.log.manager.copy.quota.window.num = 11
kafka-1          | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafka-1          | 	remote.log.manager.expiration.thread.pool.size = 10
kafka-1          | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafka-1          | 	remote.log.manager.fetch.quota.window.num = 11
kafka-1          | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafka-1          | 	remote.log.manager.task.interval.ms = 30000
kafka-1          | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafka-1          | 	remote.log.manager.task.retry.backoff.ms = 500
kafka-1          | 	remote.log.manager.task.retry.jitter = 0.2
kafka-1          | 	remote.log.manager.thread.pool.size = 2
kafka-1          | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafka-1          | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafka-1          | 	remote.log.metadata.manager.class.path = null
kafka-1          | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafka-1          | 	remote.log.metadata.manager.listener.name = null
kafka-1          | 	remote.log.reader.max.pending.tasks = 100
kafka-1          | 	remote.log.reader.threads = 10
kafka-1          | 	remote.log.storage.manager.class.name = null
kafka-1          | 	remote.log.storage.manager.class.path = null
kafka-1          | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafka-1          | 	remote.log.storage.system.enable = false
kafka-1          | 	replica.fetch.backoff.ms = 1000
kafka-1          | 	replica.fetch.max.bytes = 1048576
kafka-1          | 	replica.fetch.min.bytes = 1
kafka-1          | 	replica.fetch.response.max.bytes = 10485760
kafka-1          | 	replica.fetch.wait.max.ms = 500
kafka-1          | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka-1          | 	replica.lag.time.max.ms = 30000
kafka-1          | 	replica.selector.class = null
kafka-1          | 	replica.socket.receive.buffer.bytes = 65536
kafka-1          | 	replica.socket.timeout.ms = 30000
kafka-1          | 	replication.quota.window.num = 11
kafka-1          | 	replication.quota.window.size.seconds = 1
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.enabled.mechanisms = [GSSAPI]
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism.controller.protocol = GSSAPI
kafka-1          | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	sasl.server.authn.async.enable = false
kafka-1          | 	sasl.server.authn.async.max.threads = 1
kafka-1          | 	sasl.server.authn.async.timeout.ms = 30000
kafka-1          | 	sasl.server.callback.handler.class = null
kafka-1          | 	sasl.server.max.receive.size = 524288
kafka-1          | 	security.inter.broker.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	server.max.startup.time.ms = 9223372036854775807
kafka-1          | 	share.coordinator.append.linger.ms = 5
kafka-1          | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafka-1          | 	share.coordinator.load.buffer.size = 5242880
kafka-1          | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafka-1          | 	share.coordinator.state.topic.compression.codec = 0
kafka-1          | 	share.coordinator.state.topic.min.isr = 2
kafka-1          | 	share.coordinator.state.topic.num.partitions = 50
kafka-1          | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafka-1          | 	share.coordinator.state.topic.replication.factor = 3
kafka-1          | 	share.coordinator.state.topic.segment.bytes = 104857600
kafka-1          | 	share.coordinator.threads = 1
kafka-1          | 	share.coordinator.write.timeout.ms = 5000
kafka-1          | 	share.fetch.purgatory.purge.interval.requests = 1000
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	socket.listen.backlog.size = 50
kafka-1          | 	socket.receive.buffer.bytes = 102400
kafka-1          | 	socket.request.max.bytes = 104857600
kafka-1          | 	socket.send.buffer.bytes = 102400
kafka-1          | 	ssl.allow.dn.changes = false
kafka-1          | 	ssl.allow.san.changes = false
kafka-1          | 	ssl.cipher.suites = []
kafka-1          | 	ssl.client.auth = none
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.principal.mapping.rules = DEFAULT
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	telemetry.max.bytes = 1048576
kafka-1          | 	throughput.quota.window.num = 11
kafka-1          | 	token.impersonation.validation = true
kafka-1          | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka-1          | 	transaction.max.timeout.ms = 900000
kafka-1          | 	transaction.metadata.load.threads = 32
kafka-1          | 	transaction.partition.verification.enable = true
kafka-1          | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka-1          | 	transaction.state.log.load.buffer.size = 5242880
kafka-1          | 	transaction.state.log.min.isr = 2
kafka-1          | 	transaction.state.log.num.partitions = 50
kafka-1          | 	transaction.state.log.replication.factor = 3
kafka-1          | 	transaction.state.log.segment.bytes = 104857600
kafka-1          | 	transaction.two.phase.commit.enable = false
kafka-1          | 	transactional.id.expiration.ms = 604800000
kafka-1          | 	unclean.leader.election.enable = false
kafka-1          | 	unclean.leader.election.interval.ms = 300000
kafka-1          | 	unstable.api.versions.enable = false
kafka-1          | 	unstable.feature.versions.enable = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:01,318] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=2) with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:48:01,320] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing DisabledLinkCoordinatorListener with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1          | [2025-11-13 18:48:01,318] INFO [BrokerServer id=2] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,318] INFO [BrokerServer id=2] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafka-ui-1       | [30m2025-11-13 18:48:01,322[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
kafka-ui-1       | 
kafka-ui-1       | Using generated security password: 454e997a-c620-46d8-b66f-39980bd79252
kafka-ui-1       | 
kafka-1          | [2025-11-13 18:48:01,326] INFO KafkaConfig values: 
kafka-1          | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafka-1          | 	add.partitions.to.txn.retry.backoff.ms = 20
kafka-1          | 	advertised.listeners = PLAINTEXT://kafka-1:19092, EXTERNAL://localhost:9091
kafka-1          | 	alter.config.policy.class.name = null
kafka-1          | 	alter.log.dirs.replication.quota.window.num = 11
kafka-1          | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka-1          | 	authorizer.class.name = 
kafka-1          | 	auto.create.topics.enable = true
kafka-1          | 	auto.leader.rebalance.enable = true
kafka-1          | 	background.threads = 10
kafka-1          | 	broker.heartbeat.interval.ms = 2000
kafka-1          | 	broker.id = 2
kafka-1          | 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
kafka-1          | 	broker.rack = rack-0
kafka-1          | 	broker.session.timeout.ms = 9000
kafka-1          | 	broker.session.uuid = Cq1QTtEwT2CoFqEpv4E8ZA
kafka-1          | 	client.quota.callback.class = null
kafka-1          | 	client.quota.max.throttle.time.in.response.ms = 60000
kafka-1          | 	client.quota.max.throttle.time.ms = 5000
kafka-1          | 	compression.gzip.level = -1
kafka-1          | 	compression.lz4.level = 9
kafka-1          | 	compression.type = producer
kafka-1          | 	compression.zstd.level = 3
kafka-1          | 	confluent.accp.enabled = false
kafka-1          | 	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
kafka-1          | 	confluent.alter.broker.health.max.demoted.brokers = 2147483647
kafka-1          | 	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
kafka-1          | 	confluent.ansible.managed = false
kafka-1          | 	confluent.api.visibility = DEFAULT
kafka-1          | 	confluent.append.record.interceptor.classes = []
kafka-1          | 	confluent.apply.create.topic.policy.to.create.partitions = false
kafka-1          | 	confluent.authorizer.authority.name = 
kafka-1          | 	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
kafka-1          | 	confluent.backpressure.disk.enable = false
kafka-1          | 	confluent.backpressure.disk.free.threshold.bytes = 21474836480
kafka-1          | 	confluent.backpressure.disk.produce.bytes.per.second = 131072
kafka-1          | 	confluent.backpressure.disk.threshold.recovery.factor = 1.5
kafka-1          | 	confluent.backpressure.request.min.broker.limit = 200
kafka-1          | 	confluent.backpressure.request.queue.size.percentile = p95
kafka-1          | 	confluent.backpressure.types = null
kafka-1          | 	confluent.balancer.api.state.topic = _confluent_balancer_api_state
kafka-1          | 	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
kafka-1          | 	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
kafka-1          | 	confluent.balancer.capacity.threshold.upper.limit = 0.95
kafka-1          | 	confluent.balancer.cell.load.upper.bound = 0.7
kafka-1          | 	confluent.balancer.cell.overload.detection.interval.ms = 3600000
kafka-1          | 	confluent.balancer.cell.overload.duration.ms = 86400000
kafka-1          | 	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
kafka-1          | 	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.cpu.balance.threshold = 1.1
kafka-1          | 	confluent.balancer.cpu.goal.act.as.capacity.goal = false
kafka-1          | 	confluent.balancer.cpu.low.utilization.threshold = 0.2
kafka-1          | 	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
kafka-1          | 	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
kafka-1          | 	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
kafka-1          | 	confluent.balancer.disk.max.load = 0.85
kafka-1          | 	confluent.balancer.disk.min.free.space.gb = 0
kafka-1          | 	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
kafka-1          | 	confluent.balancer.disk.utilization.detector.duration.ms = 600000
kafka-1          | 	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
kafka-1          | 	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
kafka-1          | 	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
kafka-1          | 	confluent.balancer.enable = true
kafka-1          | 	confluent.balancer.enable.network.capacity.metric.ingestion = false
kafka-1          | 	confluent.balancer.exclude.topic.names = []
kafka-1          | 	confluent.balancer.exclude.topic.prefixes = []
kafka-1          | 	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
kafka-1          | 	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
kafka-1          | 	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
kafka-1          | 	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
kafka-1          | 	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
kafka-1          | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
kafka-1          | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
kafka-1          | 	confluent.balancer.incremental.balancing.enabled = false
kafka-1          | 	confluent.balancer.incremental.balancing.goals = []
kafka-1          | 	confluent.balancer.incremental.balancing.lower.bound = 0.02
kafka-1          | 	confluent.balancer.incremental.balancing.min.valid.windows = 5
kafka-1          | 	confluent.balancer.incremental.balancing.step.ratio = 0.2
kafka-1          | 	confluent.balancer.inter.cell.balancing.enabled = false
kafka-1          | 	confluent.balancer.inter.cell.movements.excluded.tenant.ids = []
kafka-1          | 	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
kafka-1          | 	confluent.balancer.max.replicas = 2147483647
kafka-1          | 	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
kafka-1          | 	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
kafka-1          | 	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
kafka-1          | 	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
kafka-1          | 	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.rebalancing.goals = []
kafka-1          | 	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.resource.utilization.detector.interval.ms = 60000
kafka-1          | 	confluent.balancer.sbc.metrics.parser.enabled = false
kafka-1          | 	confluent.balancer.self.healing.maximum.rounds = 1
kafka-1          | 	confluent.balancer.task.history.retention.days = 30
kafka-1          | 	confluent.balancer.tenant.maximum.movements = 0
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.consume_out = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.cpu = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.nw_in = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.nw_out = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.produce_in = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.replica_count = 3
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.consume_out = 614400.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.cpu = 300.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_in = 204800.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_out = 614400.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.produce_in = 204800.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.replica_count = 45000.0
kafka-1          | 	confluent.balancer.tenant.striping.enable.dry.run.mode = true
kafka-1          | 	confluent.balancer.tenant.striping.enabled = false
kafka-1          | 	confluent.balancer.tenant.striping.expiry.counter.threshold = 10
kafka-1          | 	confluent.balancer.tenant.striping.rate.limit = 3
kafka-1          | 	confluent.balancer.tenant.striping.resource.usage.expiry.ms = 3600000
kafka-1          | 	confluent.balancer.tenant.suspension.ms = 86400000
kafka-1          | 	confluent.balancer.throttle.bytes.per.second = 10485760
kafka-1          | 	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
kafka-1          | 	confluent.balancer.topic.partition.maximum.movements = 3
kafka-1          | 	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
kafka-1          | 	confluent.balancer.topic.partition.movements.history.limit = 900
kafka-1          | 	confluent.balancer.topic.partition.suspension.ms = 3600000
kafka-1          | 	confluent.balancer.topic.replication.factor = 3
kafka-1          | 	confluent.balancer.triggering.goals = []
kafka-1          | 	confluent.balancer.v2.addition.enabled = false
kafka-1          | 	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
kafka-1          | 	confluent.balancer.v2.executor.enabled = false
kafka-1          | 	confluent.basic.auth.credentials.source = null
kafka-1          | 	confluent.basic.auth.user.info = null
kafka-1          | 	confluent.bearer.assertion.claim.aud = null
kafka-1          | 	confluent.bearer.assertion.claim.exp.minutes = null
kafka-1          | 	confluent.bearer.assertion.claim.iss = null
kafka-1          | 	confluent.bearer.assertion.claim.jti.include = null
kafka-1          | 	confluent.bearer.assertion.claim.nbf.include = null
kafka-1          | 	confluent.bearer.assertion.claim.sub = null
kafka-1          | 	confluent.bearer.assertion.file = null
kafka-1          | 	confluent.bearer.assertion.private.key.file = null
kafka-1          | 	confluent.bearer.assertion.private.key.passphrase = null
kafka-1          | 	confluent.bearer.assertion.template.file = null
kafka-1          | 	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
kafka-1          | 	confluent.bearer.auth.client.id = null
kafka-1          | 	confluent.bearer.auth.client.secret = null
kafka-1          | 	confluent.bearer.auth.credentials.source = null
kafka-1          | 	confluent.bearer.auth.identity.pool.id = null
kafka-1          | 	confluent.bearer.auth.issuer.endpoint.url = null
kafka-1          | 	confluent.bearer.auth.logical.cluster = null
kafka-1          | 	confluent.bearer.auth.scope = null
kafka-1          | 	confluent.bearer.auth.scope.claim.name = scope
kafka-1          | 	confluent.bearer.auth.sub.claim.name = sub
kafka-1          | 	confluent.bearer.auth.token = null
kafka-1          | 	confluent.broker.health.manager.enabled = true
kafka-1          | 	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
kafka-1          | 	confluent.broker.health.manager.hard.kill.duration.ms = 60000
kafka-1          | 	confluent.broker.health.manager.mitigation.enabled = false
kafka-1          | 	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
kafka-1          | 	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
kafka-1          | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
kafka-1          | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
kafka-1          | 	confluent.broker.health.manager.sample.duration.ms = 1000
kafka-1          | 	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.broker.load.advertised.limit.load = 0.8
kafka-1          | 	confluent.broker.load.average.service.request.time.ms = 0.1
kafka-1          | 	confluent.broker.load.delay.metric.start.ms = 180000
kafka-1          | 	confluent.broker.load.enabled = false
kafka-1          | 	confluent.broker.load.num.samples = 60
kafka-1          | 	confluent.broker.load.tenant.metric.enable = false
kafka-1          | 	confluent.broker.load.update.metric.tags.interval.ms = 60000
kafka-1          | 	confluent.broker.load.window.size.ms = 60000
kafka-1          | 	confluent.broker.load.workload.coefficient = 20.0
kafka-1          | 	confluent.broker.registration.delay.ms = 0
kafka-1          | 	confluent.broker.type = confluent_platform
kafka-1          | 	confluent.broker.type.topic.enabled = true
kafka-1          | 	confluent.calling.resource.identity.type.map = 
kafka-1          | 	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
kafka-1          | 	confluent.catalog.collector.enable = false
kafka-1          | 	confluent.catalog.collector.full.configs.enable = false
kafka-1          | 	confluent.catalog.collector.max.bytes.per.snapshot = 850000
kafka-1          | 	confluent.catalog.collector.max.topics.process = 500
kafka-1          | 	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
kafka-1          | 	confluent.catalog.collector.multitenant.topics.enable = true
kafka-1          | 	confluent.catalog.collector.snapshot.init.delay.sec = 60
kafka-1          | 	confluent.catalog.collector.snapshot.interval.sec = 300
kafka-1          | 	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
kafka-1          | 	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
kafka-1          | 	confluent.cdc.api.keys.topic = 
kafka-1          | 	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
kafka-1          | 	confluent.cdc.client.quotas.enable = false
kafka-1          | 	confluent.cdc.client.quotas.topic.name = 
kafka-1          | 	confluent.cdc.lkc.metadata.topic = 
kafka-1          | 	confluent.cdc.user.metadata.enable = false
kafka-1          | 	confluent.cdc.user.metadata.topic = _confluent-user_metadata
kafka-1          | 	confluent.cell.metrics.refresh.period.ms = 60000
kafka-1          | 	confluent.cells.default.size = 15
kafka-1          | 	confluent.cells.enable = false
kafka-1          | 	confluent.cells.implicit.creation.enable = false
kafka-1          | 	confluent.cells.k2.base.broker.index = -1
kafka-1          | 	confluent.cells.load.refresher.enable = true
kafka-1          | 	confluent.cells.max.size = 15
kafka-1          | 	confluent.cells.min.size = 6
kafka-1          | 	confluent.checksum.enabled.files = [none]
kafka-1          | 	confluent.client.topic.max.metrics.count = 1000
kafka-1          | 	confluent.client.topic.metrics.expiry.sec = 3600
kafka-1          | 	confluent.client.topic.metrics.ignore_client_id_pattern = (?:link-.*-)?broker-\d+-fetcher-\d+(?:-pool-.*)?
kafka-1          | 	confluent.client.topic.metrics.ignore_internal_topic_pattern = _.*
kafka-1          | 	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
kafka-1          | 	confluent.clm.enabled = false
kafka-1          | 	confluent.clm.frequency.in.hours = 6
kafka-1          | 	confluent.clm.list.object.thread_pool.size = 1
kafka-1          | 	confluent.clm.max.backup.days = 3
kafka-1          | 	confluent.clm.min.delay.in.minutes = 30
kafka-1          | 	confluent.clm.thread.pool.size = 2
kafka-1          | 	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
kafka-1          | 	confluent.close.connections.on.credential.delete = false
kafka-1          | 	confluent.cluster.link.admin.max.in.flight.requests = 1000
kafka-1          | 	confluent.cluster.link.admin.request.batch.size = 1
kafka-1          | 	confluent.cluster.link.allow.config.providers = true
kafka-1          | 	confluent.cluster.link.allow.legacy.message.format = false
kafka-1          | 	confluent.cluster.link.allow.truncation.below.hwm = false
kafka-1          | 	confluent.cluster.link.availability.check.mode = ALL
kafka-1          | 	confluent.cluster.link.background.thread.affinity = LINK
kafka-1          | 	confluent.cluster.link.bootstrap.translation.feature.enable = true
kafka-1          | 	confluent.cluster.link.clients.max.idle.ms = 3153600000000
kafka-1          | 	confluent.cluster.link.enable = false
kafka-1          | 	confluent.cluster.link.enable.local.admin = false
kafka-1          | 	confluent.cluster.link.enable.metrics.reduction = false
kafka-1          | 	confluent.cluster.link.enable.metrics.reduction.advanced = false
kafka-1          | 	confluent.cluster.link.fetch.response.min.bytes = 1
kafka-1          | 	confluent.cluster.link.fetch.response.total.bytes = 2147483647
kafka-1          | 	confluent.cluster.link.fetcher.auto.tune.enable = false
kafka-1          | 	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
kafka-1          | 	confluent.cluster.link.insync.fetch.response.min.bytes = 1
kafka-1          | 	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
kafka-1          | 	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
kafka-1          | 	confluent.cluster.link.intranet.connectivity.enable = false
kafka-1          | 	confluent.cluster.link.intranet.connectivity.migration.enable = false
kafka-1          | 	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.cluster.link.k1.to.k2.migration.enable = false
kafka-1          | 	confluent.cluster.link.k2.mirror.topic.metadata.enable = false
kafka-1          | 	confluent.cluster.link.local.admin.multitenant.enable = false
kafka-1          | 	confluent.cluster.link.local.reverse.connection.listener.map = null
kafka-1          | 	confluent.cluster.link.max.client.connections = 2147483647
kafka-1          | 	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
kafka-1          | 	confluent.cluster.link.metadata.topic.enable = false
kafka-1          | 	confluent.cluster.link.metadata.topic.min.isr = 2
kafka-1          | 	confluent.cluster.link.metadata.topic.partitions = 50
kafka-1          | 	confluent.cluster.link.metadata.topic.replication.factor = 3
kafka-1          | 	confluent.cluster.link.mirror.transition.batch.size = 10
kafka-1          | 	confluent.cluster.link.num.background.threads = 1
kafka-1          | 	confluent.cluster.link.num.fetchers = 1
kafka-1          | 	confluent.cluster.link.periodic.task.batch.size = 2147483647
kafka-1          | 	confluent.cluster.link.periodic.task.min.interval.ms = 1000
kafka-1          | 	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
kafka-1          | 	confluent.cluster.link.replica.fetch.connections.mode = combined
kafka-1          | 	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
kafka-1          | 	confluent.cluster.link.replication.quota.mode.per.tenant.overrides = 
kafka-1          | 	confluent.cluster.link.replication.quota.window.num = 11
kafka-1          | 	confluent.cluster.link.replication.quota.window.size.seconds = 2
kafka-1          | 	confluent.cluster.link.request.quota.capacity = 400
kafka-1          | 	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
kafka-1          | 	confluent.cluster.link.switchover.disabled.principals = []
kafka-1          | 	confluent.cluster.link.switchover.enable = false
kafka-1          | 	confluent.cluster.link.switchover.listeners = []
kafka-1          | 	confluent.cluster.link.switchover.server.states = []
kafka-1          | 	confluent.cluster.link.tenant.replication.quota.enable = false
kafka-1          | 	confluent.cluster.link.tenant.request.quota.enable = false
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.enable = false
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.upload.enable = false
kafka-1          | 	confluent.compacted.topic.prefer.tier.fetch.ms = -1
kafka-1          | 	confluent.connection.invalid.request.delay.enable = false
kafka-1          | 	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
kafka-1          | 	confluent.consumer.fetch.partition.pruning.enable = true
kafka-1          | 	confluent.consumer.lag.emitter.enabled = false
kafka-1          | 	confluent.consumer.lag.emitter.interval.ms = 60000
kafka-1          | 	confluent.dataflow.policy.watch.monitor.ms = 300000
kafka-1          | 	confluent.default.data.policy.enforcement = true
kafka-1          | 	confluent.defer.isr.shrink.enable = false
kafka-1          | 	confluent.describe.topic.partitions.enabled = true
kafka-1          | 	confluent.disk.io.manager.enable = false
kafka-1          | 	confluent.disk.throughput.headroom = 10485760
kafka-1          | 	confluent.disk.throughput.limit = 10485760000
kafka-1          | 	confluent.disk.throughput.quota.tier.archive = 1048576000
kafka-1          | 	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
kafka-1          | 	confluent.durability.audit.batch.flush.frequency.ms = 900000
kafka-1          | 	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
kafka-1          | 	confluent.durability.audit.enable = false
kafka-1          | 	confluent.durability.audit.idempotent.producer = false
kafka-1          | 	confluent.durability.audit.initial.job.delay.ms = 900000
kafka-1          | 	confluent.durability.audit.io.bytes.per.sec = 10485760
kafka-1          | 	confluent.durability.audit.log.ignored.event.types = 
kafka-1          | 	confluent.durability.audit.reporting.batch.ms = 1800000
kafka-1          | 	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
kafka-1          | 	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
kafka-1          | 	confluent.durability.topic.partition.count = 50
kafka-1          | 	confluent.durability.topic.replication.factor = 3
kafka-1          | 	confluent.e2e_checksum.protection.enabled = false
kafka-1          | 	confluent.e2e_checksum.protection.files = [none]
kafka-1          | 	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
kafka-1          | 	confluent.elastic.cku.enabled = false
kafka-1          | 	confluent.elastic.cku.scaletozero.enabled = false
kafka-1          | 	confluent.eligible.controllers = []
kafka-1          | 	confluent.emit.network.type.default = 
kafka-1          | 	confluent.emit.network.type.tag = false
kafka-1          | 	confluent.enable.broker.reporting.min.usage.mode = true
kafka-1          | 	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
kafka-1          | 	confluent.fail.unsatisfied.placement.constraints = false
kafka-1          | 	confluent.fetch.from.follower.require.leader.epoch.enable = false
kafka-1          | 	confluent.fetch.partition.pruning.enable = true
kafka-1          | 	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
kafka-1          | 	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
kafka-1          | 	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
kafka-1          | 	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
kafka-1          | 	confluent.flexible.fanout.enabled = false
kafka-1          | 	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
kafka-1          | 	confluent.flexible.fanout.mode = TENANT_QUOTA
kafka-1          | 	confluent.floor.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.floor.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.group.coordinator.dynamic.append.linger.enable = false
kafka-1          | 	confluent.group.coordinator.max.partition.queue.size = -1
kafka-1          | 	confluent.group.coordinator.offsets.batching.enable = false
kafka-1          | 	confluent.group.coordinator.offsets.writer.threads = 2
kafka-1          | 	confluent.group.coordinator.slow.event.log.count = 10
kafka-1          | 	confluent.group.coordinator.slow.event.log.interval.ms = -1
kafka-1          | 	confluent.group.coordinator.txn.offset.validation.enable = false
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.count = 10
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.enable = false
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
kafka-1          | 	confluent.group.metadata.load.threads = 32
kafka-1          | 	confluent.group.subscription.pattern.log.interval.ms = -1
kafka-1          | 	confluent.heap.tenured.notify.bytes = 0
kafka-1          | 	confluent.heap.tenured.notify.enabled = false
kafka-1          | 	confluent.hot.partition.ratio = 0.8
kafka-1          | 	confluent.http.server.start.timeout.ms = 60000
kafka-1          | 	confluent.http.server.stop.timeout.ms = 30000
kafka-1          | 	confluent.intelligent.replication.enable = false
kafka-1          | 	confluent.intelligent.replication.push.max.memory.buffer.bytes = 209715200
kafka-1          | 	confluent.intelligent.replication.push.max.threads = 4
kafka-1          | 	confluent.intelligent.replication.push.threads.per.remote.broker = 1
kafka-1          | 	confluent.internal.metrics.enable = false
kafka-1          | 	confluent.internal.rest.server.bind.port = null
kafka-1          | 	confluent.internal.rest.server.ssl.enable = false
kafka-1          | 	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
kafka-1          | 	confluent.lat.network.context.verification.enable = false
kafka-1          | 	confluent.leader.epoch.checkpoint.checksum.enabled = false
kafka-1          | 	confluent.listener.protocol = TCP
kafka-1          | 	confluent.log.cleaner.timestamp.validation.enable = true
kafka-1          | 	confluent.log.placement.constraints = 
kafka-1          | 	confluent.max.broker.load = 1.0
kafka-1          | 	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
kafka-1          | 	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
kafka-1          | 	confluent.max.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.max.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.max.connection.throttle.ms = null
kafka-1          | 	confluent.max.segment.ms = 9223372036854775807
kafka-1          | 	confluent.metadata.active.encryptor = null
kafka-1          | 	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
kafka-1          | 	confluent.metadata.encryptor.classes = null
kafka-1          | 	confluent.metadata.encryptor.required = false
kafka-1          | 	confluent.metadata.encryptor.secret.file = null
kafka-1          | 	confluent.metadata.encryptor.secrets = null
kafka-1          | 	confluent.metadata.jvm.warmup.ms = 60000
kafka-1          | 	confluent.metadata.leader.balance.slice.delay.ms = 100
kafka-1          | 	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
kafka-1          | 	confluent.metadata.max.leader.balance.changes.per.slice = 1000
kafka-1          | 	confluent.metadata.rbac_auth.read.controller.enable = false
kafka-1          | 	confluent.metadata.rbac_auth.update.controller.enable = false
kafka-1          | 	confluent.metadata.reject.when.throttled.enable = false
kafka-1          | 	confluent.metadata.server.cluster.registry.clusters = []
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.min.acks = 0
kafka-1          | 	confluent.min.connection.throttle.ms = 0
kafka-1          | 	confluent.min.segment.ms = 1
kafka-1          | 	confluent.missing.id.cache.ttl.sec = 60
kafka-1          | 	confluent.missing.id.query.range = 20000
kafka-1          | 	confluent.missing.schema.cache.ttl.sec = 60
kafka-1          | 	confluent.mtls.build.client.cert.chain.enable = false
kafka-1          | 	confluent.mtls.enable = false
kafka-1          | 	confluent.mtls.listener.name = EXTERNAL
kafka-1          | 	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
kafka-1          | 	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
kafka-1          | 	confluent.mtls.truststore.manager.class.name = null
kafka-1          | 	confluent.multitenant.authorizer.enable.acl.state = false
kafka-1          | 	confluent.multitenant.interceptor.balancer.apis.enabled = false
kafka-1          | 	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
kafka-1          | 	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
kafka-1          | 	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
kafka-1          | 	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
kafka-1          | 	confluent.multitenant.listener.names = null
kafka-1          | 	confluent.multitenant.parse.lkc.id.enable = false
kafka-1          | 	confluent.multitenant.parse.sni.host.name.enable = false
kafka-1          | 	confluent.network.health.manager.enabled = false
kafka-1          | 	confluent.network.health.manager.external.listener.name = EXTERNAL
kafka-1          | 	confluent.network.health.manager.externalconnectivitystartup.enabled = false
kafka-1          | 	confluent.network.health.manager.min.healthy.network.samples = 3
kafka-1          | 	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
kafka-1          | 	confluent.network.health.manager.mitigation.enabled = false
kafka-1          | 	confluent.network.health.manager.network.sample.window.size = 120
kafka-1          | 	confluent.network.health.manager.sample.duration.ms = 1000
kafka-1          | 	confluent.oauth.flat.networking.verification.enable = false
kafka-1          | 	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
kafka-1          | 	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1          | 	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
kafka-1          | 	confluent.offsets.topic.max.message.bytes = -1
kafka-1          | 	confluent.offsets.topic.placement.constraints = 
kafka-1          | 	confluent.omit.network.processor.metric.tag = false
kafka-1          | 	confluent.operator.managed = false
kafka-1          | 	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
kafka-1          | 	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
kafka-1          | 	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
kafka-1          | 	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
kafka-1          | 	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
kafka-1          | 	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
kafka-1          | 	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
kafka-1          | 	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.enable = false
kafka-1          | 	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.cloud = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.domain = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.region = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variables = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.templates = 
kafka-1          | 	confluent.prefer.tier.fetch.ms = -1
kafka-1          | 	confluent.produce.throttle.pre.check.enable = false
kafka-1          | 	confluent.produce.throttle.pre.check.for.new.connection.enable = false
kafka-1          | 	confluent.producer.id.cache.broker.hard.limit = -1
kafka-1          | 	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
kafka-1          | 	confluent.producer.id.cache.extra.eviction.percentage = 0
kafka-1          | 	confluent.producer.id.cache.limit = 2147483647
kafka-1          | 	confluent.producer.id.cache.partition.hard.limit = -1
kafka-1          | 	confluent.producer.id.cache.tenant.hard.limit = -1
kafka-1          | 	confluent.producer.id.quota.manager.enable = false
kafka-1          | 	confluent.producer.id.quota.window.num = 11
kafka-1          | 	confluent.producer.id.quota.window.size.seconds = 1
kafka-1          | 	confluent.producer.id.throttle.enable = false
kafka-1          | 	confluent.producer.id.throttle.enable.threshold.percentage = 100
kafka-1          | 	confluent.protocol.netty.http2.connection.window.size = 31457280
kafka-1          | 	confluent.protocol.netty.http2.flow.control.enabled = true
kafka-1          | 	confluent.protocol.netty.http2.initial.window.size = 153600
kafka-1          | 	confluent.protocol.netty.http2.max.frame.size = 16384
kafka-1          | 	confluent.protocol.netty.http2.stream.graceful.close.timeout.ms = 60000
kafka-1          | 	confluent.protocol.netty.num.boss.threads = 1
kafka-1          | 	confluent.protocol.netty.num.worker.threads = 4
kafka-1          | 	confluent.proxy.mode.local.default = false
kafka-1          | 	confluent.proxy.protocol.fallback.enabled = false
kafka-1          | 	confluent.proxy.protocol.parser = class io.confluent.kafka.common.network.CloudProxyTlvParser
kafka-1          | 	confluent.proxy.protocol.version = NONE
kafka-1          | 	confluent.quota.computing.usage.adjustment = 0.5
kafka-1          | 	confluent.quota.dynamic.adjustment.min.usage = 102400
kafka-1          | 	confluent.quota.dynamic.enable = false
kafka-1          | 	confluent.quota.dynamic.publishing.interval.ms = 60000
kafka-1          | 	confluent.quota.dynamic.reporting.interval.ms = 30000
kafka-1          | 	confluent.quota.tenant.broker.max.consumer.rate = 13107200
kafka-1          | 	confluent.quota.tenant.broker.max.producer.rate = 13107200
kafka-1          | 	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
kafka-1          | 	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
kafka-1          | 	confluent.quota.tenant.fetch.multiplier = 1.0
kafka-1          | 	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
kafka-1          | 	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
kafka-1          | 	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.broker.max.controller.mutation.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.throttling.enable = false
kafka-1          | 	confluent.quota.tenant.produce.multiplier = 1.0
kafka-1          | 	confluent.quota.tenant.user.quotas.enable = false
kafka-1          | 	confluent.rack.id.mapping = null
kafka-1          | 	confluent.regional.metadata.client.class = null
kafka-1          | 	confluent.regional.resource.manager.client.scheduler.threads = 2
kafka-1          | 	confluent.regional.resource.manager.endpoint = null
kafka-1          | 	confluent.regional.resource.manager.grpc.endpoint = null
kafka-1          | 	confluent.reject.invalid.sni.hostnames = false
kafka-1          | 	confluent.replica.fetch.backoff.max.ms = 1000
kafka-1          | 	confluent.replica.fetch.connections.mode = combined
kafka-1          | 	confluent.replication.mode = PULL
kafka-1          | 	confluent.replication.push.feature.enable = false
kafka-1          | 	confluent.reporters.telemetry.auto.enable = false
kafka-1          | 	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
kafka-1          | 	confluent.request.pipelining.enable = true
kafka-1          | 	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
kafka-1          | 	confluent.require.calling.resource.identity = false
kafka-1          | 	confluent.require.compatible.keystore.updates = true
kafka-1          | 	confluent.require.confluent.issuer = false
kafka-1          | 	confluent.roll.check.interval.ms = 300000
kafka-1          | 	confluent.schema.registry.max.cache.size = 10000
kafka-1          | 	confluent.schema.registry.max.retries = 1
kafka-1          | 	confluent.schema.registry.retries.wait.ms = 0
kafka-1          | 	confluent.schema.registry.url = null
kafka-1          | 	confluent.schema.validation.context.name.enable = false
kafka-1          | 	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
kafka-1          | 	confluent.schema.validator.multitenant.enable = false
kafka-1          | 	confluent.schema.validator.samples.per.min = 0
kafka-1          | 	confluent.security.bc.approved.mode.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.authorization.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
kafka-1          | 	confluent.security.event.logger.enable = true
kafka-1          | 	confluent.security.event.logger.kafka.request.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.physical.cluster.id = 
kafka-1          | 	confluent.security.event.router.config = 
kafka-1          | 	confluent.security.revoked.certificate.ids = 
kafka-1          | 	confluent.segment.eager.roll.enable = false
kafka-1          | 	confluent.segment.speculative.prefetch.enable = false
kafka-1          | 	confluent.share.coordinator.slow.event.log.count = 10
kafka-1          | 	confluent.share.coordinator.slow.event.log.interval.ms = -1
kafka-1          | 	confluent.share.metadata.load.threads = 32
kafka-1          | 	confluent.spiffe.id.principal.extraction.rules = 
kafka-1          | 	confluent.ssl.key.password = null
kafka-1          | 	confluent.ssl.keystore.location = null
kafka-1          | 	confluent.ssl.keystore.password = null
kafka-1          | 	confluent.ssl.keystore.type = null
kafka-1          | 	confluent.ssl.protocol = null
kafka-1          | 	confluent.ssl.truststore.location = null
kafka-1          | 	confluent.ssl.truststore.password = null
kafka-1          | 	confluent.ssl.truststore.type = null
kafka-1          | 	confluent.step.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.step.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.storage.probe.disk.metrics.collection.enabled = false
kafka-1          | 	confluent.storage.probe.period.ms = -1
kafka-1          | 	confluent.storage.probe.slow.write.threshold.ms = 5000
kafka-1          | 	confluent.stray.log.delete.delay.ms = 604800000
kafka-1          | 	confluent.stray.log.max.deletions.per.run = 72
kafka-1          | 	confluent.subdomain.prefix = null
kafka-1          | 	confluent.subdomain.separator.map = null
kafka-1          | 	confluent.subdomain.separator.variable = %sep
kafka-1          | 	confluent.system.time.roll.enable = false
kafka-1          | 	confluent.telemetry.enabled = false
kafka-1          | 	confluent.telemetry.external.client.metrics.delta.temporality = true
kafka-1          | 	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
kafka-1          | 	confluent.telemetry.external.client.metrics.push.enabled = false
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.match.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.supported.compression.types = [zstd, lz4, gzip, snappy]
kafka-1          | 	confluent.tenant.latency.metric.enabled = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.enable = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.proactive.key.generation.enable = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
kafka-1          | 	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
kafka-1          | 	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
kafka-1          | 	confluent.tier.archiver.num.threads = 2
kafka-1          | 	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
kafka-1          | 	confluent.tier.azure.block.blob.container = null
kafka-1          | 	confluent.tier.azure.block.blob.cred.file.path = null
kafka-1          | 	confluent.tier.azure.block.blob.endpoint = null
kafka-1          | 	confluent.tier.azure.block.blob.prefix = 
kafka-1          | 	confluent.tier.backend = 
kafka-1          | 	confluent.tier.bucket.probe.period.ms = -1
kafka-1          | 	confluent.tier.cleaner.compact.min.efficiency = 0.5
kafka-1          | 	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
kafka-1          | 	confluent.tier.cleaner.dedupe.buffer.size = 134217728
kafka-1          | 	confluent.tier.cleaner.dual.compaction = false
kafka-1          | 	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
kafka-1          | 	confluent.tier.cleaner.dual.compaction.validation.percent = 0
kafka-1          | 	confluent.tier.cleaner.enable = false
kafka-1          | 	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
kafka-1          | 	confluent.tier.cleaner.feature.enable = false
kafka-1          | 	confluent.tier.cleaner.io.buffer.load.factor = 0.9
kafka-1          | 	confluent.tier.cleaner.io.buffer.size = 10485760
kafka-1          | 	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1          | 	confluent.tier.cleaner.min.cleanable.ratio = 0.75
kafka-1          | 	confluent.tier.cleaner.num.threads = 2
kafka-1          | 	confluent.tier.enable = false
kafka-1          | 	confluent.tier.feature = false
kafka-1          | 	confluent.tier.fenced.segment.delete.delay.ms = 600000
kafka-1          | 	confluent.tier.fetcher.async.enable = false
kafka-1          | 	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
kafka-1          | 	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
kafka-1          | 	confluent.tier.fetcher.memorypool.bytes = 0
kafka-1          | 	confluent.tier.fetcher.num.threads = 4
kafka-1          | 	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
kafka-1          | 	confluent.tier.fetcher.offset.cache.period.ms = 60000
kafka-1          | 	confluent.tier.fetcher.offset.cache.size = 200000
kafka-1          | 	confluent.tier.gcs.bucket = null
kafka-1          | 	confluent.tier.gcs.cred.file.path = null
kafka-1          | 	confluent.tier.gcs.prefix = 
kafka-1          | 	confluent.tier.gcs.region = null
kafka-1          | 	confluent.tier.gcs.sse.customer.encryption.key = null
kafka-1          | 	confluent.tier.gcs.write.chunk.size = 0
kafka-1          | 	confluent.tier.local.hotset.bytes = -1
kafka-1          | 	confluent.tier.local.hotset.ms = 86400000
kafka-1          | 	confluent.tier.max.partition.fetch.bytes.override = 0
kafka-1          | 	confluent.tier.metadata.bootstrap.servers = null
kafka-1          | 	confluent.tier.metadata.catchup.max.poll.ms = 0
kafka-1          | 	confluent.tier.metadata.max.poll.ms = 100
kafka-1          | 	confluent.tier.metadata.namespace = null
kafka-1          | 	confluent.tier.metadata.num.partitions = 50
kafka-1          | 	confluent.tier.metadata.replication.factor = 3
kafka-1          | 	confluent.tier.metadata.request.timeout.ms = 30000
kafka-1          | 	confluent.tier.metadata.snapshots.enable = false
kafka-1          | 	confluent.tier.metadata.snapshots.interval.ms = 86400000
kafka-1          | 	confluent.tier.metadata.snapshots.retention.days = 7
kafka-1          | 	confluent.tier.metadata.snapshots.threads = 2
kafka-1          | 	confluent.tier.object.fetcher.num.threads = 1
kafka-1          | 	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
kafka-1          | 	confluent.tier.partition.state.cleanup.enable = false
kafka-1          | 	confluent.tier.partition.state.cleanup.interval.ms = 86400000
kafka-1          | 	confluent.tier.partition.state.commit.interval.ms = 15000
kafka-1          | 	confluent.tier.prefetch.cache.enable = false
kafka-1          | 	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
kafka-1          | 	confluent.tier.prefetch.cache.range.bytes = 5242880
kafka-1          | 	confluent.tier.prefetch.cache.total.size.bytes = 209715200
kafka-1          | 	confluent.tier.s3.assumerole.arn = null
kafka-1          | 	confluent.tier.s3.auto.abort.threshold.bytes = 500000
kafka-1          | 	confluent.tier.s3.aws.endpoint.override = null
kafka-1          | 	confluent.tier.s3.aws.signer.override = null
kafka-1          | 	confluent.tier.s3.bucket = null
kafka-1          | 	confluent.tier.s3.cred.file.path = null
kafka-1          | 	confluent.tier.s3.force.path.style.access = false
kafka-1          | 	confluent.tier.s3.ipv6.enabled = true
kafka-1          | 	confluent.tier.s3.prefix = 
kafka-1          | 	confluent.tier.s3.region = null
kafka-1          | 	confluent.tier.s3.security.providers = null
kafka-1          | 	confluent.tier.s3.sse.algorithm = AES256
kafka-1          | 	confluent.tier.s3.sse.customer.encryption.key = null
kafka-1          | 	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	confluent.tier.s3.ssl.key.password = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.location = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.password = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.type = null
kafka-1          | 	confluent.tier.s3.ssl.protocol = TLSv1.3
kafka-1          | 	confluent.tier.s3.ssl.provider = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.location = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.password = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.type = null
kafka-1          | 	confluent.tier.s3.storage.class.override = 
kafka-1          | 	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
kafka-1          | 	confluent.tier.s3.v2.enabled = false
kafka-1          | 	confluent.tier.segment.hotset.roll.min.bytes = 104857600
kafka-1          | 	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
kafka-1          | 	confluent.tier.topic.data.loss.validation.fencing.enable = false
kafka-1          | 	confluent.tier.topic.delete.backoff.ms = 21600000
kafka-1          | 	confluent.tier.topic.delete.check.interval.ms = 300000
kafka-1          | 	confluent.tier.topic.delete.max.inprogress.partitions = 100
kafka-1          | 	confluent.tier.topic.head.data.loss.validation.enable = true
kafka-1          | 	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
kafka-1          | 	confluent.tier.topic.materialization.from.snapshot.enable = false
kafka-1          | 	confluent.tier.topic.producer.enable.idempotence = true
kafka-1          | 	confluent.tier.topic.snapshots.enable = false
kafka-1          | 	confluent.tier.topic.snapshots.interval.ms = 300000
kafka-1          | 	confluent.tier.topic.snapshots.max.records = 100000
kafka-1          | 	confluent.tier.topic.snapshots.retention.hours = 168
kafka-1          | 	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
kafka-1          | 	confluent.topic.partition.default.placement = 2
kafka-1          | 	confluent.topic.policy.use.computed.assignments = false
kafka-1          | 	confluent.topic.replica.assignor.builder.class = 
kafka-1          | 	confluent.track.api.key.per.ip = false
kafka-1          | 	confluent.track.per.ip.max.size = 100000
kafka-1          | 	confluent.track.tenant.id.per.ip = false
kafka-1          | 	confluent.traffic.cdc.network.id.routes.enable = false
kafka-1          | 	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
kafka-1          | 	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
kafka-1          | 	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
kafka-1          | 	confluent.traffic.network.id = 
kafka-1          | 	confluent.traffic.network.type = 
kafka-1          | 	confluent.transaction.2pc.timeout.ms = -1
kafka-1          | 	confluent.transaction.logging.verbosity = 0
kafka-1          | 	confluent.transaction.state.log.placement.constraints = 
kafka-1          | 	confluent.unique.deprecated.request.metrics.per.tenant = 1000
kafka-1          | 	confluent.valid.broker.rack.set = null
kafka-1          | 	confluent.valid.sni.hostnames = 
kafka-1          | 	confluent.valid.sni.hostnames.exclude.suffix = 
kafka-1          | 	confluent.verify.group.subscription.prefix = false
kafka-1          | 	confluent.virtual.topic.creation.enabled = false
kafka-1          | 	confluent.zone.tagged.request.metrics.enable = false
kafka-1          | 	connection.failed.authentication.delay.ms = 100
kafka-1          | 	connection.min.expire.interval.ms = 250
kafka-1          | 	connections.max.age.ms = 3153600000000
kafka-1          | 	connections.max.idle.ms = 600000
kafka-1          | 	connections.max.reauth.ms = 0
kafka-1          | 	controlled.shutdown.enable = true
kafka-1          | 	controller.listener.names = CONTROLLER
kafka-1          | 	controller.performance.always.log.threshold.ms = 2000
kafka-1          | 	controller.performance.sample.period.ms = 60000
kafka-1          | 	controller.quorum.append.linger.ms = 25
kafka-1          | 	controller.quorum.bootstrap.servers = []
kafka-1          | 	controller.quorum.election.backoff.max.ms = 1000
kafka-1          | 	controller.quorum.election.timeout.ms = 1000
kafka-1          | 	controller.quorum.fetch.timeout.ms = 2000
kafka-1          | 	controller.quorum.request.timeout.ms = 2000
kafka-1          | 	controller.quorum.retry.backoff.ms = 20
kafka-1          | 	controller.quorum.voters = [1@controller-1:19091]
kafka-1          | 	controller.quota.window.num = 11
kafka-1          | 	controller.quota.window.size.seconds = 1
kafka-1          | 	controller.socket.timeout.ms = 30000
kafka-1          | 	create.cluster.link.policy.class.name = null
kafka-1          | 	create.topic.policy.class.name = null
kafka-1          | 	default.replication.factor = 1
kafka-1          | 	delegation.token.expiry.check.interval.ms = 3600000
kafka-1          | 	delegation.token.expiry.time.ms = 86400000
kafka-1          | 	delegation.token.max.lifetime.ms = 604800000
kafka-1          | 	delegation.token.secret.key = null
kafka-1          | 	delete.records.purgatory.purge.interval.requests = 1
kafka-1          | 	delete.topic.enable = true
kafka-1          | 	early.start.listeners = null
kafka-1          | 	enable.fips = false
kafka-1          | 	fetch.max.bytes = 57671680
kafka-1          | 	fetch.purgatory.purge.interval.requests = 1000
kafka-1          | 	floor.max.connection.creation.rate = null
kafka-1          | 	follower.replication.throttled.rate = 9223372036854775807
kafka-1          | 	follower.replication.throttled.replicas = none
kafka-1          | 	group.consumer.assignors = [uniform, range]
kafka-1          | 	group.consumer.heartbeat.interval.ms = 5000
kafka-1          | 	group.consumer.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.consumer.max.session.timeout.ms = 60000
kafka-1          | 	group.consumer.max.size = 2147483647
kafka-1          | 	group.consumer.migration.policy = bidirectional
kafka-1          | 	group.consumer.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.consumer.min.session.timeout.ms = 45000
kafka-1          | 	group.consumer.regex.refresh.interval.ms = 600000
kafka-1          | 	group.consumer.session.timeout.ms = 45000
kafka-1          | 	group.coordinator.append.linger.ms = 5
kafka-1          | 	group.coordinator.rebalance.protocols = [classic, consumer, share, streams]
kafka-1          | 	group.coordinator.threads = 4
kafka-1          | 	group.initial.rebalance.delay.ms = 0
kafka-1          | 	group.max.session.timeout.ms = 1800000
kafka-1          | 	group.max.size = 2147483647
kafka-1          | 	group.min.session.timeout.ms = 6000
kafka-1          | 	group.share.assignors = [simple]
kafka-1          | 	group.share.delivery.count.limit = 5
kafka-1          | 	group.share.enable = false
kafka-1          | 	group.share.heartbeat.interval.ms = 5000
kafka-1          | 	group.share.initialize.retry.interval.ms = 30000
kafka-1          | 	group.share.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.share.max.record.lock.duration.ms = 60000
kafka-1          | 	group.share.max.session.timeout.ms = 60000
kafka-1          | 	group.share.max.share.sessions = 2000
kafka-1          | 	group.share.max.size = 200
kafka-1          | 	group.share.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.share.min.record.lock.duration.ms = 15000
kafka-1          | 	group.share.min.session.timeout.ms = 45000
kafka-1          | 	group.share.partition.max.record.locks = 2000
kafka-1          | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafka-1          | 	group.share.record.lock.duration.ms = 30000
kafka-1          | 	group.share.rollout.ready = true
kafka-1          | 	group.share.session.timeout.ms = 45000
kafka-1          | 	group.streams.heartbeat.interval.ms = 5000
kafka-1          | 	group.streams.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.streams.max.session.timeout.ms = 60000
kafka-1          | 	group.streams.max.size = 2147483647
kafka-1          | 	group.streams.max.standby.replicas = 2
kafka-1          | 	group.streams.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.streams.min.session.timeout.ms = 45000
kafka-1          | 	group.streams.num.standby.replicas = 0
kafka-1          | 	group.streams.session.timeout.ms = 45000
kafka-1          | 	initial.broker.registration.timeout.ms = 60000
kafka-1          | 	inter.broker.listener.name = PLAINTEXT
kafka-1          | 	internal.metadata.delete.delay.millis = 60000
kafka-1          | 	internal.metadata.log.segment.bytes = null
kafka-1          | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafka-1          | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafka-1          | 	k2.stack.builder.class.name = null
kafka-1          | 	k2.startup.timeout.ms = 60000
kafka-1          | 	k2.topic.metadata.refresh.ms = 10000
kafka-1          | 	kafka.metrics.polling.interval.secs = 10
kafka-1          | 	kafka.metrics.reporters = []
kafka-1          | 	leader.imbalance.check.interval.seconds = 300
kafka-1          | 	leader.replication.throttled.rate = 9223372036854775807
kafka-1          | 	leader.replication.throttled.replicas = none
kafka-1          | 	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
kafka-1          | 	listeners = PLAINTEXT://kafka-1:19092, EXTERNAL://0.0.0.0:9091
kafka-1          | 	log.cleaner.backoff.ms = 15000
kafka-1          | 	log.cleaner.dedupe.buffer.size = 134217728
kafka-1          | 	log.cleaner.delete.retention.ms = 86400000
kafka-1          | 	log.cleaner.enable = true
kafka-1          | 	log.cleaner.hash.algorithm = MD5
kafka-1          | 	log.cleaner.io.buffer.load.factor = 0.9
kafka-1          | 	log.cleaner.io.buffer.size = 524288
kafka-1          | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1          | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1          | 	log.cleaner.min.cleanable.ratio = 0.5
kafka-1          | 	log.cleaner.min.compaction.lag.ms = 0
kafka-1          | 	log.cleaner.threads = 1
kafka-1          | 	log.cleanup.policy = [delete]
kafka-1          | 	log.cleanup.policy.empty.validation = none
kafka-1          | 	log.deletion.max.segments.per.run = 2147483647
kafka-1          | 	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
kafka-1          | 	log.dir = /tmp/kafka-logs
kafka-1          | 	log.dir.failure.timeout.ms = 30000
kafka-1          | 	log.dirs = /var/lib/kafka/data
kafka-1          | 	log.flush.interval.messages = 9223372036854775807
kafka-1          | 	log.flush.interval.ms = null
kafka-1          | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka-1          | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka-1          | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka-1          | 	log.index.interval.bytes = 4096
kafka-1          | 	log.index.size.max.bytes = 10485760
kafka-1          | 	log.initial.task.delay.ms = 30000
kafka-1          | 	log.local.retention.bytes = -2
kafka-1          | 	log.local.retention.ms = -2
kafka-1          | 	log.message.timestamp.after.max.ms = 3600000
kafka-1          | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafka-1          | 	log.message.timestamp.type = CreateTime
kafka-1          | 	log.preallocate = false
kafka-1          | 	log.retention.bytes = -1
kafka-1          | 	log.retention.check.interval.ms = 300000
kafka-1          | 	log.retention.hours = 168
kafka-1          | 	log.retention.minutes = null
kafka-1          | 	log.retention.ms = null
kafka-1          | 	log.roll.hours = 168
kafka-1          | 	log.roll.jitter.hours = 0
kafka-1          | 	log.roll.jitter.ms = null
kafka-1          | 	log.roll.ms = null
kafka-1          | 	log.segment.bytes = 1073741824
kafka-1          | 	log.segment.delete.delay.ms = 60000
kafka-1          | 	max.connection.creation.rate = 1.7976931348623157E308
kafka-1          | 	max.connection.creation.rate.per.ip.enable.threshold = 0.0
kafka-1          | 	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
kafka-1          | 	max.connections = 2147483647
kafka-1          | 	max.connections.per.ip = 2147483647
kafka-1          | 	max.connections.per.ip.overrides = 
kafka-1          | 	max.connections.per.tenant = 0
kafka-1          | 	max.connections.protected.listeners = []
kafka-1          | 	max.connections.reap.amount = 0
kafka-1          | 	max.incremental.fetch.session.cache.slots = 1000
kafka-1          | 	max.request.partition.size.limit = 2000
kafka-1          | 	message.max.bytes = 1048588
kafka-1          | 	metadata.log.dir = null
kafka-1          | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafka-1          | 	metadata.log.max.snapshot.interval.ms = 3600000
kafka-1          | 	metadata.log.segment.bytes = 1073741824
kafka-1          | 	metadata.log.segment.ms = 604800000
kafka-1          | 	metadata.max.idle.interval.ms = 500
kafka-1          | 	metadata.max.retention.bytes = 104857600
kafka-1          | 	metadata.max.retention.ms = 604800000
kafka-1          | 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	min.insync.replicas = 1
kafka-1          | 	multitenant.authorizer.support.resource.ids = false
kafka-1          | 	multitenant.metadata.class = null
kafka-1          | 	multitenant.metadata.dir = null
kafka-1          | 	multitenant.metadata.reload.delay.ms = 120000
kafka-1          | 	multitenant.metadata.ssl.certs.path = null
kafka-1          | 	multitenant.tenant.delete.batch.size = 10
kafka-1          | 	multitenant.tenant.delete.check.ms = 120000
kafka-1          | 	multitenant.tenant.delete.delay = 604800000
kafka-1          | 	node.id = 2
kafka-1          | 	num.io.threads = 8
kafka-1          | 	num.network.threads = 3
kafka-1          | 	num.partitions = 1
kafka-1          | 	num.recovery.threads.per.data.dir = 2
kafka-1          | 	num.replica.alter.log.dirs.threads = null
kafka-1          | 	num.replica.fetchers = 1
kafka-1          | 	offset.metadata.max.bytes = 4096
kafka-1          | 	offsets.commit.timeout.ms = 5000
kafka-1          | 	offsets.load.buffer.size = 5242880
kafka-1          | 	offsets.retention.check.interval.ms = 600000
kafka-1          | 	offsets.retention.minutes = 10080
kafka-1          | 	offsets.topic.compression.codec = 0
kafka-1          | 	offsets.topic.num.partitions = 50
kafka-1          | 	offsets.topic.replication.factor = 3
kafka-1          | 	offsets.topic.segment.bytes = 104857600
kafka-1          | 	otel.exporter.otlp.custom.endpoint = default
kafka-1          | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka-1          | 	process.roles = [broker]
kafka-1          | 	producer.id.expiration.check.interval.ms = 600000
kafka-1          | 	producer.id.expiration.ms = 86400000
kafka-1          | 	producer.purgatory.purge.interval.requests = 1000
kafka-1          | 	queued.max.request.bytes = -1
kafka-1          | 	queued.max.requests = 500
kafka-1          | 	quota.window.num = 11
kafka-1          | 	quota.window.size.seconds = 1
kafka-1          | 	quotas.consumption.expiration.time.ms = 600000
kafka-1          | 	quotas.expiration.interval.ms = 3600000
kafka-1          | 	quotas.expiration.time.ms = 604800000
kafka-1          | 	quotas.lazy.evaluation.threshold = 0.5
kafka-1          | 	quotas.topic.append.timeout.ms = 5000
kafka-1          | 	quotas.topic.compression.codec = 3
kafka-1          | 	quotas.topic.load.buffer.size = 5242880
kafka-1          | 	quotas.topic.num.partitions = 50
kafka-1          | 	quotas.topic.placement.constraints = 
kafka-1          | 	quotas.topic.replication.factor = 3
kafka-1          | 	quotas.topic.segment.bytes = 104857600
kafka-1          | 	remote.fetch.max.wait.ms = 500
kafka-1          | 	remote.list.offsets.request.timeout.ms = 30000
kafka-1          | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafka-1          | 	remote.log.manager.copier.thread.pool.size = 10
kafka-1          | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafka-1          | 	remote.log.manager.copy.quota.window.num = 11
kafka-1          | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafka-1          | 	remote.log.manager.expiration.thread.pool.size = 10
kafka-1          | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafka-1          | 	remote.log.manager.fetch.quota.window.num = 11
kafka-1          | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafka-1          | 	remote.log.manager.task.interval.ms = 30000
kafka-1          | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafka-1          | 	remote.log.manager.task.retry.backoff.ms = 500
kafka-1          | 	remote.log.manager.task.retry.jitter = 0.2
kafka-1          | 	remote.log.manager.thread.pool.size = 2
kafka-1          | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafka-1          | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafka-1          | 	remote.log.metadata.manager.class.path = null
kafka-1          | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafka-1          | 	remote.log.metadata.manager.listener.name = null
kafka-1          | 	remote.log.reader.max.pending.tasks = 100
kafka-1          | 	remote.log.reader.threads = 10
kafka-1          | 	remote.log.storage.manager.class.name = null
kafka-1          | 	remote.log.storage.manager.class.path = null
kafka-1          | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafka-1          | 	remote.log.storage.system.enable = false
kafka-1          | 	replica.fetch.backoff.ms = 1000
kafka-1          | 	replica.fetch.max.bytes = 1048576
kafka-1          | 	replica.fetch.min.bytes = 1
kafka-1          | 	replica.fetch.response.max.bytes = 10485760
kafka-1          | 	replica.fetch.wait.max.ms = 500
kafka-1          | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka-1          | 	replica.lag.time.max.ms = 30000
kafka-1          | 	replica.selector.class = null
kafka-1          | 	replica.socket.receive.buffer.bytes = 65536
kafka-1          | 	replica.socket.timeout.ms = 30000
kafka-1          | 	replication.quota.window.num = 11
kafka-1          | 	replication.quota.window.size.seconds = 1
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.enabled.mechanisms = [GSSAPI]
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism.controller.protocol = GSSAPI
kafka-1          | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	sasl.server.authn.async.enable = false
kafka-1          | 	sasl.server.authn.async.max.threads = 1
kafka-1          | 	sasl.server.authn.async.timeout.ms = 30000
kafka-1          | 	sasl.server.callback.handler.class = null
kafka-1          | 	sasl.server.max.receive.size = 524288
kafka-1          | 	security.inter.broker.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	server.max.startup.time.ms = 9223372036854775807
kafka-1          | 	share.coordinator.append.linger.ms = 5
kafka-1          | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafka-1          | 	share.coordinator.load.buffer.size = 5242880
kafka-1          | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafka-1          | 	share.coordinator.state.topic.compression.codec = 0
kafka-1          | 	share.coordinator.state.topic.min.isr = 2
kafka-1          | 	share.coordinator.state.topic.num.partitions = 50
kafka-1          | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafka-1          | 	share.coordinator.state.topic.replication.factor = 3
kafka-1          | 	share.coordinator.state.topic.segment.bytes = 104857600
kafka-1          | 	share.coordinator.threads = 1
kafka-1          | 	share.coordinator.write.timeout.ms = 5000
kafka-1          | 	share.fetch.purgatory.purge.interval.requests = 1000
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	socket.listen.backlog.size = 50
kafka-1          | 	socket.receive.buffer.bytes = 102400
kafka-1          | 	socket.request.max.bytes = 104857600
kafka-1          | 	socket.send.buffer.bytes = 102400
kafka-1          | 	ssl.allow.dn.changes = false
kafka-1          | 	ssl.allow.san.changes = false
kafka-1          | 	ssl.cipher.suites = []
kafka-1          | 	ssl.client.auth = none
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.principal.mapping.rules = DEFAULT
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	telemetry.max.bytes = 1048576
kafka-1          | 	throughput.quota.window.num = 11
kafka-1          | 	token.impersonation.validation = true
kafka-1          | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka-1          | 	transaction.max.timeout.ms = 900000
kafka-1          | 	transaction.metadata.load.threads = 32
kafka-1          | 	transaction.partition.verification.enable = true
kafka-1          | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka-1          | 	transaction.state.log.load.buffer.size = 5242880
kafka-1          | 	transaction.state.log.min.isr = 2
kafka-1          | 	transaction.state.log.num.partitions = 50
kafka-1          | 	transaction.state.log.replication.factor = 3
kafka-1          | 	transaction.state.log.segment.bytes = 104857600
kafka-1          | 	transaction.two.phase.commit.enable = false
kafka-1          | 	transactional.id.expiration.ms = 604800000
kafka-1          | 	unclean.leader.election.enable = false
kafka-1          | 	unclean.leader.election.interval.ms = 300000
kafka-1          | 	unstable.api.versions.enable = false
kafka-1          | 	unstable.feature.versions.enable = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:01,350] INFO [BrokerServer id=2] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,350] INFO [BrokerServer id=2] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
controller-1     | [2025-11-13 18:48:01,355] INFO [ControllerServer id=1] The request from broker 2 to unfence has been granted because it has caught up with the offset of its register broker record 10. (org.apache.kafka.controller.BrokerHeartbeatManager)
controller-1     | [2025-11-13 18:48:01,369] INFO [ControllerServer id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 2: BrokerRegistrationChangeRecord(brokerId=2, brokerEpoch=10, fenced=-1, inControlledShutdown=0, degradedComponents=null, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1          | [2025-11-13 18:48:01,393] INFO [BrokerLifecycleManager id=2] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
kafka-1          | [2025-11-13 18:48:01,393] INFO [BrokerLifecycleManager id=2] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
kafka-1          | [2025-11-13 18:48:01,394] INFO [BrokerServer id=2] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,394] INFO [BrokerServer id=2] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,394] INFO [SocketServer listenerType=BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
kafka-1          | [2025-11-13 18:48:01,394] INFO [SocketServer listenerType=BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
controller-1     | [2025-11-13 18:48:01,393] INFO SBC Event SbcMetadataUpdateEvent-11 generated 1 more events to enqueue in the following order - [SbcKraftBrokerAdditionEvent-12]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:01,396] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
kafka-1          | [2025-11-13 18:48:01,399] INFO Awaiting socket connections on 0.0.0.0:9091. (kafka.network.DataPlaneAcceptor)
kafka-1          | [2025-11-13 18:48:01,399] INFO Awaiting socket connections on 0.0.0.0:9091. (kafka.network.DataPlaneAcceptor)
kafka-1          | [2025-11-13 18:48:01,405] INFO Awaiting socket connections on kafka-1:19092. (kafka.network.DataPlaneAcceptor)
kafka-1          | [2025-11-13 18:48:01,405] INFO Awaiting socket connections on kafka-1:19092. (kafka.network.DataPlaneAcceptor)
controller-1     | [2025-11-13 18:48:01,407] INFO Balancer notified of a config change: ConfigurationsDelta(changes={ConfigResource(type=BROKER, name='')=ConfigurationDelta(changedKeys=[min.insync.replicas])}) (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:01,409] INFO There were 0 change(s) and 0 deletion(s) to balancer configs. Changed Configs: {}, Deleted Configs: [] (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:01,410] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:01,411] INFO Balancer Status state for brokers [1] transitioned from BALANCER_EVENT_RECEIVED to STARTING due to event INITIALIZING_CRUISE_CONTROL. (io.confluent.databalancer.operation.StateMachine)
controller-1     | [2025-11-13 18:48:01,411] INFO DataBalancer: Activating SBC with io.confluent.databalancer.BrokersMetadataSnapshot@74c042b7 (io.confluent.databalancer.KafkaDataBalanceManager)
controller-1     | [2025-11-13 18:48:01,416] INFO DataBalancer: Scheduling DataBalanceEngine Startup (io.confluent.databalancer.ConfluentDataBalanceEngine)
kafka-1          | [2025-11-13 18:48:01,417] INFO [BrokerServer id=2] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,417] INFO [BrokerServer id=2] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,418] INFO [BrokerServer id=2] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,418] INFO [BrokerServer id=2] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,418] INFO [BrokerServer id=2] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,418] INFO [BrokerServer id=2] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,419] INFO [BrokerServer id=2] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:01,419] INFO [BrokerServer id=2] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
controller-1     | [2025-11-13 18:48:01,426] INFO Handling event SbcKraftBrokerAdditionEvent-12 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:01,428] INFO Topics Image not present, pausing broker addition event of brokers (new brokers: [2]) until it is received. (io.confluent.databalancer.event.SbcKraftBrokerAdditionEvent)
controller-1     | [2025-11-13 18:48:01,431] INFO DataBalancer: Bootstrap server endpoint is Endpoint(listenerName='PLAINTEXT', securityProtocol=PLAINTEXT, host='kafka-1', port=19092) (io.confluent.databalancer.startup.CruiseControlStartable)
controller-1     | [2025-11-13 18:48:01,432] INFO DataBalancer: BOOTSTRAP_SERVERS determined to be kafka-1:19092 (io.confluent.databalancer.startup.CruiseControlStartable)
controller-1     | [2025-11-13 18:48:01,437] INFO KafkaCruiseControlConfig values: 
controller-1     | 	alter.configs.response.timeout.ms = 30000
controller-1     | 	anomaly.detection.allow.capacity.estimation = true
controller-1     | 	anomaly.detection.goals = [io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal]
controller-1     | 	anomaly.detection.interval.ms = 60000
controller-1     | 	bootstrap.servers = [kafka-1:19092]
controller-1     | 	broker.addition.detector.allowed.topic.balancing.operation.time.threshold.min = 90
controller-1     | 	broker.addition.elapsed.time.ms.completion.threshold = 57600000
controller-1     | 	broker.addition.mean.cpu.percent.completion.threshold = 0.5
controller-1     | 	broker.capacity.config.resolver.class = class com.linkedin.kafka.cruisecontrol.config.BrokerCapacityResolver
controller-1     | 	broker.failure.alert.threshold.ms = 0
controller-1     | 	broker.failure.exclude.recently.removed.brokers = true
controller-1     | 	broker.failure.self.healing.threshold.ms = 3600000
controller-1     | 	broker.metric.sample.aggregator.completeness.cache.size = 5
controller-1     | 	broker.removal.shutdown.timeout.ms = 600000
controller-1     | 	broker.removal.subtasks.max.attempts = 3
controller-1     | 	broker.removal.subtasks.retry.interval.ms = 1000
controller-1     | 	broker.replica.exclusion.timeout.ms = 120000
controller-1     | 	bytes.cpu.contribution.weight = 0.2
controller-1     | 	calculated.throttle.ratio = 0.8
controller-1     | 	capacity.goal.minimum.improvement.step.percentage = 0.01
controller-1     | 	capacity.threshold.upper.limit = 0.95
controller-1     | 	cdbe.shutdown.wait.ms = 15000
controller-1     | 	cell.load.upper.bound = 0.7
controller-1     | 	cell.overload.detection.interval.ms = 3600000
controller-1     | 	cell.overload.duration.ms = 86400000
controller-1     | 	client.id = kafka-cruise-control
controller-1     | 	confluent.balancer.additional.invalidation.duration.ms = 60000
controller-1     | 	confluent.cells.enable = false
controller-1     | 	confluent.rack.id.mapping = null
controller-1     | 	connections.max.idle.ms = 540000
controller-1     | 	consume.out.bound.should.balance.FFF.traffic = true
controller-1     | 	consumer.out.max.bytes.per.second = 9223372036854775807
controller-1     | 	consumer.outbound.capacity.threshold = 0.9
controller-1     | 	cpu.balance.threshold = 1.1
controller-1     | 	cpu.capacity.threshold = 1.0
controller-1     | 	cpu.goal.act.as.capacity.goal = false
controller-1     | 	cpu.low.utilization.threshold = 0.2
controller-1     | 	cpu.low.utilization.threshold.for.broker.addition = 0.2
controller-1     | 	cpu.utilization.detector.duration.ms = 600000
controller-1     | 	cpu.utilization.detector.overutilization.threshold = 80.0
controller-1     | 	cpu.utilization.detector.underutilization.threshold = 50.0
controller-1     | 	default.api.timeout.ms = 60000
controller-1     | 	default.replica.movement.strategies = [com.linkedin.kafka.cruisecontrol.executor.strategy.BaseReplicaMovementStrategy]
controller-1     | 	describe.broker.exclusion.timeout.ms = 60000
controller-1     | 	describe.cluster.response.timeout.ms = 30000
controller-1     | 	describe.configs.batch.size = 1000
controller-1     | 	describe.configs.response.timeout.ms = 30000
controller-1     | 	describe.topics.response.timeout.ms = 30000
controller-1     | 	disk.balance.threshold = 1.1
controller-1     | 	disk.low.utilization.threshold = 0.2
controller-1     | 	disk.max.load = 0.85
controller-1     | 	disk.min.free.space.gb = 0
controller-1     | 	disk.min.free.space.lower.limit.gb = 0
controller-1     | 	disk.read.ratio = 0.2
controller-1     | 	disk.utilization.detector.duration.ms = 600000
controller-1     | 	disk.utilization.detector.overutilization.threshold = 80.0
controller-1     | 	disk.utilization.detector.reserved.capacity = 150000.0
controller-1     | 	disk.utilization.detector.underutilization.threshold = 35.0
controller-1     | 	dynamic.throttling.enabled = true
controller-1     | 	enable.network.capacity.metric.ingestion = false
controller-1     | 	execution.progress.check.interval.ms = 7000
controller-1     | 	executor.leader.action.timeout.ms = 180000
controller-1     | 	executor.notifier.class = class com.linkedin.kafka.cruisecontrol.executor.ExecutorNoopNotifier
controller-1     | 	executor.reservation.refresh.time.ms = 60000
controller-1     | 	flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
controller-1     | 	goal.balancedness.priority.weight = 1.1
controller-1     | 	goal.balancedness.strictness.weight = 1.5
controller-1     | 	goal.violation.delay.on.new.brokers.ms = 1800000
controller-1     | 	goal.violation.distribution.threshold.multiplier = 1.1
controller-1     | 	goal.violation.exclude.recently.removed.brokers = true
controller-1     | 	goals = [com.linkedin.kafka.cruisecontrol.analyzer.goals.MovementExclusionGoal, io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.MirrorInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ConsumerOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.SystemTopicEvenDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.TopicReplicaDistributionGoal]
controller-1     | 	hot.partition.capacity.utilization.threshold = 0.2
controller-1     | 	incremental.balancing.cpu.top.proposal.tracking.enabled = true
controller-1     | 	incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
controller-1     | 	incremental.balancing.enabled = false
controller-1     | 	incremental.balancing.goals = [com.linkedin.kafka.cruisecontrol.analyzer.goals.MovementExclusionGoal, io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.MirrorInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ConsumerOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.IncrementalCPUResourceDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.IncrementalTopicReplicaDistributionGoal]
controller-1     | 	incremental.balancing.lower.bound = 0.02
controller-1     | 	incremental.balancing.min.valid.windows = 5
controller-1     | 	incremental.balancing.step.ratio = 0.2
controller-1     | 	inter.cell.balancing.enabled = false
controller-1     | 	inter.cell.movements.excluded.tenant.ids = []
controller-1     | 	invalid.replica.assignment.retry.timeout.ms = 300000
controller-1     | 	leader.replica.count.balance.threshold = 1.1
controller-1     | 	logdir.response.timeout.ms = 30000
controller-1     | 	max.allowed.extrapolations.per.broker = 5
controller-1     | 	max.allowed.extrapolations.per.partition = 5
controller-1     | 	max.capacity.balancing.delta.percentage = 0.0
controller-1     | 	max.replicas = 2147483647
controller-1     | 	max.volume.throughput.mb = 0
controller-1     | 	maximum.allocated.percentage.for.network.in.capacity.bytes = 0.8
controller-1     | 	metadata.client.timeout.ms = 180000
controller-1     | 	metadata.ttl = 10000
controller-1     | 	metric.sampler.class = class io.confluent.cruisecontrol.metricsreporter.ConfluentTelemetryReporterSampler
controller-1     | 	min.samples.per.partition.metrics.window = 1
controller-1     | 	min.valid.partition.ratio = 0.95
controller-1     | 	minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
controller-1     | 	network.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	network.inbound.balance.threshold = 1.1
controller-1     | 	network.inbound.capacity.threshold = 0.8
controller-1     | 	network.inbound.low.utilization.threshold = 0.2
controller-1     | 	network.out.max.bytes.per.second = 9223372036854775807
controller-1     | 	network.outbound.balance.threshold = 1.1
controller-1     | 	network.outbound.capacity.threshold = 0.8
controller-1     | 	network.outbound.low.utilization.threshold = 0.2
controller-1     | 	num.cached.recent.anomaly.states = 10
controller-1     | 	num.concurrent.leader.movements = 1000
controller-1     | 	num.concurrent.partition.movements.per.broker = 5
controller-1     | 	num.concurrent.replica.movements.as.destination.per.broker = 18
controller-1     | 	num.concurrent.replica.movements.as.source.per.broker = 12
controller-1     | 	num.metric.fetchers = 1
controller-1     | 	num.partition.metrics.windows = 12
controller-1     | 	partition.metric.sample.aggregator.completeness.cache.size = 5
controller-1     | 	partition.metrics.window.ms = 180000
controller-1     | 	plan.computation.retry.timeout.ms = 3600000
controller-1     | 	populate.default.disk.capacity.from.local = true
controller-1     | 	producer.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	producer.inbound.capacity.threshold = 0.9
controller-1     | 	read.throughput.multiplier = 1.0
controller-1     | 	receive.buffer.bytes = 32768
controller-1     | 	reconnect.backoff.ms = 50
controller-1     | 	removal.history.retention.time.ms = 86400000
controller-1     | 	replica.count.balance.threshold = 1.1
controller-1     | 	replica.movement.strategies = [com.linkedin.kafka.cruisecontrol.executor.strategy.PostponeUrpReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizePartitionsWithMoreReplicaAdditionsStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeLargeReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeSmallReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.BaseReplicaMovementStrategy]
controller-1     | 	replication.in.max.bytes.per.second = 9223372036854775807
controller-1     | 	replication.inbound.capacity.threshold = 0.9
controller-1     | 	request.cpu.contribution.weight = 0.8
controller-1     | 	request.timeout.ms = 30000
controller-1     | 	resource.utilization.detector.interval.ms = 60000
controller-1     | 	sampling.allow.cpu.capacity.estimation = true
controller-1     | 	sasl.client.callback.handler.class = null
controller-1     | 	sasl.jaas.config = null
controller-1     | 	sasl.jaas.config.jndi.allowlist = null
controller-1     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
controller-1     | 	sasl.kerberos.min.time.before.relogin = 60000
controller-1     | 	sasl.kerberos.service.name = null
controller-1     | 	sasl.kerberos.ticket.renew.jitter = 0.05
controller-1     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
controller-1     | 	sasl.login.callback.handler.class = null
controller-1     | 	sasl.login.class = null
controller-1     | 	sasl.login.connect.timeout.ms = null
controller-1     | 	sasl.login.read.timeout.ms = null
controller-1     | 	sasl.login.refresh.buffer.seconds = 300
controller-1     | 	sasl.login.refresh.min.period.seconds = 60
controller-1     | 	sasl.login.refresh.window.factor = 0.8
controller-1     | 	sasl.login.refresh.window.jitter = 0.05
controller-1     | 	sasl.login.retry.backoff.max.ms = 10000
controller-1     | 	sasl.login.retry.backoff.ms = 100
controller-1     | 	sasl.mechanism = GSSAPI
controller-1     | 	sasl.oauthbearer.assertion.algorithm = RS256
controller-1     | 	sasl.oauthbearer.assertion.claim.aud = null
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
controller-1     | 	sasl.oauthbearer.assertion.claim.iss = null
controller-1     | 	sasl.oauthbearer.assertion.claim.jti.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
controller-1     | 	sasl.oauthbearer.assertion.claim.sub = null
controller-1     | 	sasl.oauthbearer.assertion.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
controller-1     | 	sasl.oauthbearer.assertion.template.file = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.id = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.secret = null
controller-1     | 	sasl.oauthbearer.clock.skew.seconds = 30
controller-1     | 	sasl.oauthbearer.expected.audience = null
controller-1     | 	sasl.oauthbearer.expected.issuer = null
controller-1     | 	sasl.oauthbearer.header.urlencode = false
controller-1     | 	sasl.oauthbearer.iat.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jti.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
controller-1     | 	sasl.oauthbearer.jwks.endpoint.url = null
controller-1     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
controller-1     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
controller-1     | 	sasl.oauthbearer.scope = null
controller-1     | 	sasl.oauthbearer.scope.claim.name = scope
controller-1     | 	sasl.oauthbearer.sub.claim.name = sub
controller-1     | 	sasl.oauthbearer.token.endpoint.url = null
controller-1     | 	sbc.metrics.parser.enabled = false
controller-1     | 	security.protocol = PLAINTEXT
controller-1     | 	self.healing.broker.failure.enabled = true
controller-1     | 	self.healing.goal.violation.enabled = false
controller-1     | 	self.healing.maximum.rounds = 1
controller-1     | 	send.buffer.bytes = 131072
controller-1     | 	ssl.cipher.suites = null
controller-1     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
controller-1     | 	ssl.endpoint.identification.algorithm = https
controller-1     | 	ssl.engine.factory.class = null
controller-1     | 	ssl.key.password = null
controller-1     | 	ssl.keymanager.algorithm = SunX509
controller-1     | 	ssl.keystore.certificate.chain = null
controller-1     | 	ssl.keystore.key = null
controller-1     | 	ssl.keystore.location = null
controller-1     | 	ssl.keystore.password = null
controller-1     | 	ssl.keystore.type = JKS
controller-1     | 	ssl.protocol = TLSv1.3
controller-1     | 	ssl.provider = null
controller-1     | 	ssl.secure.random.implementation = null
controller-1     | 	ssl.trustmanager.algorithm = PKIX
controller-1     | 	ssl.truststore.certificates = null
controller-1     | 	ssl.truststore.location = null
controller-1     | 	ssl.truststore.password = null
controller-1     | 	ssl.truststore.type = JKS
controller-1     | 	startup.retry.delay.minutes = 5
controller-1     | 	startup.retry.max.hours = 2
controller-1     | 	static.throttle.rate.override.enabled = false
controller-1     | 	tenant.maximum.movements = 0
controller-1     | 	tenant.striping.counter.threshold.consume_out = 3
controller-1     | 	tenant.striping.counter.threshold.cpu = 3
controller-1     | 	tenant.striping.counter.threshold.nw_in = 3
controller-1     | 	tenant.striping.counter.threshold.nw_out = 3
controller-1     | 	tenant.striping.counter.threshold.produce_in = 3
controller-1     | 	tenant.striping.counter.threshold.replica_count = 3
controller-1     | 	tenant.striping.desired.stripe.usage.consume_out = 614400.0
controller-1     | 	tenant.striping.desired.stripe.usage.cpu = 300.0
controller-1     | 	tenant.striping.desired.stripe.usage.nw_in = 204800.0
controller-1     | 	tenant.striping.desired.stripe.usage.nw_out = 614400.0
controller-1     | 	tenant.striping.desired.stripe.usage.produce_in = 204800.0
controller-1     | 	tenant.striping.desired.stripe.usage.replica_count = 45000.0
controller-1     | 	tenant.striping.enable.dry.run.mode = true
controller-1     | 	tenant.striping.enabled = false
controller-1     | 	tenant.striping.expiry.counter.threshold = 10
controller-1     | 	tenant.striping.rate.limit = 3
controller-1     | 	tenant.striping.resource.usage.expiry.ms = 3600000
controller-1     | 	tenant.suspension.ms = 86400000
controller-1     | 	throttle.bytes.per.second = 10485760
controller-1     | 	topic.balancing.badly.imbalanced.topic.imbalance.score.threshold = 0.3
controller-1     | 	topic.balancing.balance.threshold.multiplier = 1.0
controller-1     | 	topic.balancing.broker.addition.detector.with.trdg.enabled = false
controller-1     | 	topic.balancing.itrdg.with.hard.goals.enabled = false
controller-1     | 	topic.balancing.max.reassignments.per.iteration = -1
controller-1     | 	topic.balancing.slightly.imbalanced.topic.imbalance.score.threshold = 0.05
controller-1     | 	topic.balancing.slightly.imbalanced.topics.percentage.trigger = 0.2
controller-1     | 	topic.balancing.trigger.threshold.multiplier = 3.0
controller-1     | 	topic.partition.maximum.movements = 3
controller-1     | 	topic.partition.movement.expiration.ms = 3600000
controller-1     | 	topic.partition.movements.history.limit = 900
controller-1     | 	topic.partition.suspension.ms = 3600000
controller-1     | 	topics.excluded.from.partition.movement = 
controller-1     | 	v2.addition.enabled = false
controller-1     | 	v2.addition.reassignment.cancellations.enabled = false
controller-1     | 	v2.executor.enabled = false
controller-1     | 	write.throughput.multiplier = 1.0
controller-1     | 	zookeeper.connect = null
controller-1     | 	zookeeper.security.enabled = false
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:01,442] INFO DataBalancer: Instantiating DataBalanceEngine (io.confluent.databalancer.ConfluentDataBalanceEngine)
controller-1     | [2025-11-13 18:48:01,458] INFO DataBalancer: Checking startup components (io.confluent.databalancer.startup.CruiseControlStartable)
controller-1     | [2025-11-13 18:48:01,459] INFO DataBalancer: Checking startup component StartupComponent ConfluentTelemetryReporterSampler (io.confluent.databalancer.startup.StartupComponents)
controller-1     | [2025-11-13 18:48:01,499] WARN Disabling exponential reconnect backoff because reconnect.backoff.ms is set, but reconnect.backoff.max.ms is not. (org.apache.kafka.clients.CommonClientConfigs)
controller-1     | [2025-11-13 18:48:01,501] INFO ConsumerConfig values: 
controller-1     | 	allow.auto.create.topics = true
controller-1     | 	auto.commit.interval.ms = 5000
controller-1     | 	auto.offset.reset = latest
controller-1     | 	bootstrap.servers = [kafka-1:19092]
controller-1     | 	check.crcs = true
controller-1     | 	client.dns.lookup = use_all_dns_ips
controller-1     | 	client.id = kafka-cruise-control
controller-1     | 	client.rack = 
controller-1     | 	confluent.client.switchover.disable = false
controller-1     | 	confluent.lkc.id = null
controller-1     | 	confluent.proxy.protocol.client.address = null
controller-1     | 	confluent.proxy.protocol.client.mode = PROXY
controller-1     | 	confluent.proxy.protocol.client.port = null
controller-1     | 	confluent.proxy.protocol.client.version = NONE
controller-1     | 	confluent.selectable.plugin.class = null
controller-1     | 	connections.max.idle.ms = 540000
controller-1     | 	default.api.timeout.ms = 60000
controller-1     | 	enable.auto.commit = false
controller-1     | 	enable.metrics.push = false
controller-1     | 	exclude.internal.topics = true
controller-1     | 	fetch.max.bytes = 52428800
controller-1     | 	fetch.max.wait.ms = 500
controller-1     | 	fetch.min.bytes = 1
controller-1     | 	group.id = ConfluentTelemetryReporterSampler--2339039893306426714
controller-1     | 	group.instance.id = null
controller-1     | 	group.protocol = classic
controller-1     | 	group.remote.assignor = null
controller-1     | 	heartbeat.interval.ms = 3000
controller-1     | 	interceptor.classes = []
controller-1     | 	internal.leave.group.on.close = true
controller-1     | 	internal.throw.on.fetch.stable.offset.unsupported = false
controller-1     | 	isolation.level = read_uncommitted
controller-1     | 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
controller-1     | 	max.partition.fetch.bytes = 1048576
controller-1     | 	max.poll.interval.ms = 2147483647
controller-1     | 	max.poll.records = 2147483647
controller-1     | 	metadata.max.age.ms = 300000
controller-1     | 	metadata.recovery.rebootstrap.trigger.ms = 300000
controller-1     | 	metadata.recovery.strategy = none
controller-1     | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
controller-1     | 	metrics.num.samples = 2
controller-1     | 	metrics.recording.level = INFO
controller-1     | 	metrics.sample.window.ms = 30000
controller-1     | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
controller-1     | 	receive.buffer.bytes = 32768
controller-1     | 	reconnect.backoff.max.ms = 50
controller-1     | 	reconnect.backoff.ms = 50
controller-1     | 	request.timeout.ms = 30000
controller-1     | 	retry.backoff.max.ms = 1000
controller-1     | 	retry.backoff.ms = 100
controller-1     | 	sasl.client.callback.handler.class = null
controller-1     | 	sasl.jaas.config = null
controller-1     | 	sasl.jaas.config.jndi.allowlist = null
controller-1     | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
controller-1     | 	sasl.kerberos.min.time.before.relogin = 60000
controller-1     | 	sasl.kerberos.service.name = null
controller-1     | 	sasl.kerberos.ticket.renew.jitter = 0.05
controller-1     | 	sasl.kerberos.ticket.renew.window.factor = 0.8
controller-1     | 	sasl.login.callback.handler.class = null
controller-1     | 	sasl.login.class = null
controller-1     | 	sasl.login.connect.timeout.ms = null
controller-1     | 	sasl.login.read.timeout.ms = null
controller-1     | 	sasl.login.refresh.buffer.seconds = 300
controller-1     | 	sasl.login.refresh.min.period.seconds = 60
controller-1     | 	sasl.login.refresh.window.factor = 0.8
controller-1     | 	sasl.login.refresh.window.jitter = 0.05
controller-1     | 	sasl.login.retry.backoff.max.ms = 10000
controller-1     | 	sasl.login.retry.backoff.ms = 100
controller-1     | 	sasl.mechanism = GSSAPI
controller-1     | 	sasl.oauthbearer.assertion.algorithm = RS256
controller-1     | 	sasl.oauthbearer.assertion.claim.aud = null
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
controller-1     | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
controller-1     | 	sasl.oauthbearer.assertion.claim.iss = null
controller-1     | 	sasl.oauthbearer.assertion.claim.jti.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.include = false
controller-1     | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
controller-1     | 	sasl.oauthbearer.assertion.claim.sub = null
controller-1     | 	sasl.oauthbearer.assertion.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.file = null
controller-1     | 	sasl.oauthbearer.assertion.private.key.passphrase = null
controller-1     | 	sasl.oauthbearer.assertion.template.file = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.id = null
controller-1     | 	sasl.oauthbearer.client.credentials.client.secret = null
controller-1     | 	sasl.oauthbearer.clock.skew.seconds = 30
controller-1     | 	sasl.oauthbearer.expected.audience = null
controller-1     | 	sasl.oauthbearer.expected.issuer = null
controller-1     | 	sasl.oauthbearer.header.urlencode = false
controller-1     | 	sasl.oauthbearer.iat.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jti.validation.enabled = false
controller-1     | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
controller-1     | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
controller-1     | 	sasl.oauthbearer.jwks.endpoint.url = null
controller-1     | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
controller-1     | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
controller-1     | 	sasl.oauthbearer.scope = null
controller-1     | 	sasl.oauthbearer.scope.claim.name = scope
controller-1     | 	sasl.oauthbearer.sub.claim.name = sub
controller-1     | 	sasl.oauthbearer.token.endpoint.url = null
controller-1     | 	security.protocol = PLAINTEXT
controller-1     | 	security.providers = null
controller-1     | 	send.buffer.bytes = 131072
controller-1     | 	session.timeout.ms = 45000
controller-1     | 	share.acknowledgement.mode = implicit
controller-1     | 	socket.connection.setup.timeout.max.ms = 30000
controller-1     | 	socket.connection.setup.timeout.ms = 10000
controller-1     | 	ssl.cipher.suites = null
controller-1     | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
controller-1     | 	ssl.endpoint.identification.algorithm = https
controller-1     | 	ssl.engine.factory.class = null
controller-1     | 	ssl.key.password = null
controller-1     | 	ssl.keymanager.algorithm = SunX509
controller-1     | 	ssl.keystore.certificate.chain = null
controller-1     | 	ssl.keystore.key = null
controller-1     | 	ssl.keystore.location = null
controller-1     | 	ssl.keystore.password = null
controller-1     | 	ssl.keystore.type = JKS
controller-1     | 	ssl.protocol = TLSv1.3
controller-1     | 	ssl.provider = null
controller-1     | 	ssl.secure.random.implementation = null
controller-1     | 	ssl.trustmanager.algorithm = PKIX
controller-1     | 	ssl.truststore.certificates = null
controller-1     | 	ssl.truststore.location = null
controller-1     | 	ssl.truststore.password = null
controller-1     | 	ssl.truststore.type = JKS
controller-1     | 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:01,632] INFO These configurations '[sasl.oauthbearer.jwks.endpoint.refresh.ms, sasl.kerberos.ticket.renew.window.factor, sasl.oauthbearer.jti.validation.enabled, sasl.oauthbearer.jwt.validator.class, ssl.keystore.type, sasl.oauthbearer.header.urlencode, ssl.endpoint.identification.algorithm, sasl.login.refresh.buffer.seconds, sasl.login.retry.backoff.max.ms, sasl.oauthbearer.assertion.claim.exp.seconds, ssl.truststore.type, sasl.oauthbearer.clock.skew.seconds, sasl.oauthbearer.assertion.algorithm, sasl.oauthbearer.assertion.claim.exp.minutes, sasl.login.refresh.min.period.seconds, sasl.oauthbearer.scope.claim.name, sasl.login.refresh.window.factor, sasl.login.retry.backoff.ms, sasl.kerberos.kinit.cmd, sasl.oauthbearer.assertion.claim.nbf.include, sasl.kerberos.ticket.renew.jitter, ssl.trustmanager.algorithm, sasl.kerberos.min.time.before.relogin, sasl.oauthbearer.iat.validation.enabled, ssl.protocol, ssl.enabled.protocols, sasl.oauthbearer.sub.claim.name, sasl.oauthbearer.assertion.claim.nbf.seconds, sasl.oauthbearer.jwt.retriever.class, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms, ssl.keymanager.algorithm, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms, sasl.oauthbearer.assertion.claim.jti.include, sasl.login.refresh.window.jitter]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:01,632] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:48:01,633] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:48:01,633] INFO Kafka startTimeMs: 1763059681632 (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:48:01,635] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--2339039893306426714] Subscribed to pattern: '_confluent-telemetry-metrics' (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
kafka-1          | [2025-11-13 18:48:01,638] INFO Application provider 'MetadataApiApplicationProvider' provided 1 instance(s). (io.confluent.http.server.KafkaHttpApplicationLoader)
kafka-1          | [2025-11-13 18:48:01,642] INFO MetadataServerConfig values: 
kafka-1          | 	confluent.http.server.listeners = [http://0.0.0.0:8090]
kafka-1          | 	confluent.metadata.server.advertised.listeners = null
kafka-1          | 	confluent.metadata.server.enable = false
kafka-1          | 	confluent.metadata.server.kraft.controller.enabled = false
kafka-1          | 	confluent.metadata.server.listeners = null
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:01,642] INFO Application provider 'RbacApplicationProvider' did not provide any instances. (io.confluent.http.server.KafkaHttpApplicationLoader)
kafka-1          | [2025-11-13 18:48:01,662] INFO KafkaConfig values: 
kafka-1          | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafka-1          | 	add.partitions.to.txn.retry.backoff.ms = 20
kafka-1          | 	advertised.listeners = PLAINTEXT://kafka-1:19092, EXTERNAL://localhost:9091
kafka-1          | 	alter.config.policy.class.name = null
kafka-1          | 	alter.log.dirs.replication.quota.window.num = 11
kafka-1          | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka-1          | 	authorizer.class.name = 
kafka-1          | 	auto.create.topics.enable = true
kafka-1          | 	auto.leader.rebalance.enable = true
kafka-1          | 	background.threads = 10
kafka-1          | 	broker.heartbeat.interval.ms = 2000
kafka-1          | 	broker.id = 2
kafka-1          | 	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
kafka-1          | 	broker.rack = rack-0
kafka-1          | 	broker.session.timeout.ms = 9000
kafka-1          | 	broker.session.uuid = Cq1QTtEwT2CoFqEpv4E8ZA
kafka-1          | 	client.quota.callback.class = null
kafka-1          | 	client.quota.max.throttle.time.in.response.ms = 60000
kafka-1          | 	client.quota.max.throttle.time.ms = 5000
kafka-1          | 	compression.gzip.level = -1
kafka-1          | 	compression.lz4.level = 9
kafka-1          | 	compression.type = producer
kafka-1          | 	compression.zstd.level = 3
kafka-1          | 	confluent.accp.enabled = false
kafka-1          | 	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
kafka-1          | 	confluent.alter.broker.health.max.demoted.brokers = 2147483647
kafka-1          | 	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
kafka-1          | 	confluent.ansible.managed = false
kafka-1          | 	confluent.api.visibility = DEFAULT
kafka-1          | 	confluent.append.record.interceptor.classes = []
kafka-1          | 	confluent.apply.create.topic.policy.to.create.partitions = false
kafka-1          | 	confluent.authorizer.authority.name = 
kafka-1          | 	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
kafka-1          | 	confluent.backpressure.disk.enable = false
kafka-1          | 	confluent.backpressure.disk.free.threshold.bytes = 21474836480
kafka-1          | 	confluent.backpressure.disk.produce.bytes.per.second = 131072
kafka-1          | 	confluent.backpressure.disk.threshold.recovery.factor = 1.5
kafka-1          | 	confluent.backpressure.request.min.broker.limit = 200
kafka-1          | 	confluent.backpressure.request.queue.size.percentile = p95
kafka-1          | 	confluent.backpressure.types = null
kafka-1          | 	confluent.balancer.api.state.topic = _confluent_balancer_api_state
kafka-1          | 	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
kafka-1          | 	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
kafka-1          | 	confluent.balancer.capacity.threshold.upper.limit = 0.95
kafka-1          | 	confluent.balancer.cell.load.upper.bound = 0.7
kafka-1          | 	confluent.balancer.cell.overload.detection.interval.ms = 3600000
kafka-1          | 	confluent.balancer.cell.overload.duration.ms = 86400000
kafka-1          | 	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
kafka-1          | 	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.cpu.balance.threshold = 1.1
kafka-1          | 	confluent.balancer.cpu.goal.act.as.capacity.goal = false
kafka-1          | 	confluent.balancer.cpu.low.utilization.threshold = 0.2
kafka-1          | 	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
kafka-1          | 	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
kafka-1          | 	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
kafka-1          | 	confluent.balancer.disk.max.load = 0.85
kafka-1          | 	confluent.balancer.disk.min.free.space.gb = 0
kafka-1          | 	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
kafka-1          | 	confluent.balancer.disk.utilization.detector.duration.ms = 600000
kafka-1          | 	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
kafka-1          | 	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
kafka-1          | 	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
kafka-1          | 	confluent.balancer.enable = true
kafka-1          | 	confluent.balancer.enable.network.capacity.metric.ingestion = false
kafka-1          | 	confluent.balancer.exclude.topic.names = []
kafka-1          | 	confluent.balancer.exclude.topic.prefixes = []
kafka-1          | 	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
kafka-1          | 	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
kafka-1          | 	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
kafka-1          | 	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
kafka-1          | 	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
kafka-1          | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
kafka-1          | 	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
kafka-1          | 	confluent.balancer.incremental.balancing.enabled = false
kafka-1          | 	confluent.balancer.incremental.balancing.goals = []
kafka-1          | 	confluent.balancer.incremental.balancing.lower.bound = 0.02
kafka-1          | 	confluent.balancer.incremental.balancing.min.valid.windows = 5
kafka-1          | 	confluent.balancer.incremental.balancing.step.ratio = 0.2
kafka-1          | 	confluent.balancer.inter.cell.balancing.enabled = false
kafka-1          | 	confluent.balancer.inter.cell.movements.excluded.tenant.ids = []
kafka-1          | 	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
kafka-1          | 	confluent.balancer.max.replicas = 2147483647
kafka-1          | 	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
kafka-1          | 	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
kafka-1          | 	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
kafka-1          | 	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
kafka-1          | 	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.rebalancing.goals = []
kafka-1          | 	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.balancer.resource.utilization.detector.interval.ms = 60000
kafka-1          | 	confluent.balancer.sbc.metrics.parser.enabled = false
kafka-1          | 	confluent.balancer.self.healing.maximum.rounds = 1
kafka-1          | 	confluent.balancer.task.history.retention.days = 30
kafka-1          | 	confluent.balancer.tenant.maximum.movements = 0
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.consume_out = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.cpu = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.nw_in = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.nw_out = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.produce_in = 3
kafka-1          | 	confluent.balancer.tenant.striping.counter.threshold.replica_count = 3
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.consume_out = 614400.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.cpu = 300.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_in = 204800.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.nw_out = 614400.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.produce_in = 204800.0
kafka-1          | 	confluent.balancer.tenant.striping.desired.stripe.usage.replica_count = 45000.0
kafka-1          | 	confluent.balancer.tenant.striping.enable.dry.run.mode = true
kafka-1          | 	confluent.balancer.tenant.striping.enabled = false
kafka-1          | 	confluent.balancer.tenant.striping.expiry.counter.threshold = 10
kafka-1          | 	confluent.balancer.tenant.striping.rate.limit = 3
kafka-1          | 	confluent.balancer.tenant.striping.resource.usage.expiry.ms = 3600000
kafka-1          | 	confluent.balancer.tenant.suspension.ms = 86400000
kafka-1          | 	confluent.balancer.throttle.bytes.per.second = 10485760
kafka-1          | 	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
kafka-1          | 	confluent.balancer.topic.partition.maximum.movements = 3
kafka-1          | 	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
kafka-1          | 	confluent.balancer.topic.partition.movements.history.limit = 900
kafka-1          | 	confluent.balancer.topic.partition.suspension.ms = 3600000
kafka-1          | 	confluent.balancer.topic.replication.factor = 3
kafka-1          | 	confluent.balancer.triggering.goals = []
kafka-1          | 	confluent.balancer.v2.addition.enabled = false
kafka-1          | 	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
kafka-1          | 	confluent.balancer.v2.executor.enabled = false
kafka-1          | 	confluent.basic.auth.credentials.source = null
kafka-1          | 	confluent.basic.auth.user.info = null
kafka-1          | 	confluent.bearer.assertion.claim.aud = null
kafka-1          | 	confluent.bearer.assertion.claim.exp.minutes = null
kafka-1          | 	confluent.bearer.assertion.claim.iss = null
kafka-1          | 	confluent.bearer.assertion.claim.jti.include = null
kafka-1          | 	confluent.bearer.assertion.claim.nbf.include = null
kafka-1          | 	confluent.bearer.assertion.claim.sub = null
kafka-1          | 	confluent.bearer.assertion.file = null
kafka-1          | 	confluent.bearer.assertion.private.key.file = null
kafka-1          | 	confluent.bearer.assertion.private.key.passphrase = null
kafka-1          | 	confluent.bearer.assertion.template.file = null
kafka-1          | 	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
kafka-1          | 	confluent.bearer.auth.client.id = null
kafka-1          | 	confluent.bearer.auth.client.secret = null
kafka-1          | 	confluent.bearer.auth.credentials.source = null
kafka-1          | 	confluent.bearer.auth.identity.pool.id = null
kafka-1          | 	confluent.bearer.auth.issuer.endpoint.url = null
kafka-1          | 	confluent.bearer.auth.logical.cluster = null
kafka-1          | 	confluent.bearer.auth.scope = null
kafka-1          | 	confluent.bearer.auth.scope.claim.name = scope
kafka-1          | 	confluent.bearer.auth.sub.claim.name = sub
kafka-1          | 	confluent.bearer.auth.token = null
kafka-1          | 	confluent.broker.health.manager.enabled = true
kafka-1          | 	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
kafka-1          | 	confluent.broker.health.manager.hard.kill.duration.ms = 60000
kafka-1          | 	confluent.broker.health.manager.mitigation.enabled = false
kafka-1          | 	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
kafka-1          | 	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
kafka-1          | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
kafka-1          | 	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
kafka-1          | 	confluent.broker.health.manager.sample.duration.ms = 1000
kafka-1          | 	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
kafka-1          | 	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.broker.load.advertised.limit.load = 0.8
kafka-1          | 	confluent.broker.load.average.service.request.time.ms = 0.1
kafka-1          | 	confluent.broker.load.delay.metric.start.ms = 180000
kafka-1          | 	confluent.broker.load.enabled = false
kafka-1          | 	confluent.broker.load.num.samples = 60
kafka-1          | 	confluent.broker.load.tenant.metric.enable = false
kafka-1          | 	confluent.broker.load.update.metric.tags.interval.ms = 60000
kafka-1          | 	confluent.broker.load.window.size.ms = 60000
kafka-1          | 	confluent.broker.load.workload.coefficient = 20.0
kafka-1          | 	confluent.broker.registration.delay.ms = 0
kafka-1          | 	confluent.broker.type = confluent_platform
kafka-1          | 	confluent.broker.type.topic.enabled = true
kafka-1          | 	confluent.calling.resource.identity.type.map = 
kafka-1          | 	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
kafka-1          | 	confluent.catalog.collector.enable = false
kafka-1          | 	confluent.catalog.collector.full.configs.enable = false
kafka-1          | 	confluent.catalog.collector.max.bytes.per.snapshot = 850000
kafka-1          | 	confluent.catalog.collector.max.topics.process = 500
kafka-1          | 	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
kafka-1          | 	confluent.catalog.collector.multitenant.topics.enable = true
kafka-1          | 	confluent.catalog.collector.snapshot.init.delay.sec = 60
kafka-1          | 	confluent.catalog.collector.snapshot.interval.sec = 300
kafka-1          | 	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
kafka-1          | 	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
kafka-1          | 	confluent.cdc.api.keys.topic = 
kafka-1          | 	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
kafka-1          | 	confluent.cdc.client.quotas.enable = false
kafka-1          | 	confluent.cdc.client.quotas.topic.name = 
kafka-1          | 	confluent.cdc.lkc.metadata.topic = 
kafka-1          | 	confluent.cdc.user.metadata.enable = false
kafka-1          | 	confluent.cdc.user.metadata.topic = _confluent-user_metadata
kafka-1          | 	confluent.cell.metrics.refresh.period.ms = 60000
kafka-1          | 	confluent.cells.default.size = 15
kafka-1          | 	confluent.cells.enable = false
kafka-1          | 	confluent.cells.implicit.creation.enable = false
kafka-1          | 	confluent.cells.k2.base.broker.index = -1
kafka-1          | 	confluent.cells.load.refresher.enable = true
kafka-1          | 	confluent.cells.max.size = 15
kafka-1          | 	confluent.cells.min.size = 6
kafka-1          | 	confluent.checksum.enabled.files = [none]
kafka-1          | 	confluent.client.topic.max.metrics.count = 1000
kafka-1          | 	confluent.client.topic.metrics.expiry.sec = 3600
kafka-1          | 	confluent.client.topic.metrics.ignore_client_id_pattern = (?:link-.*-)?broker-\d+-fetcher-\d+(?:-pool-.*)?
kafka-1          | 	confluent.client.topic.metrics.ignore_internal_topic_pattern = _.*
kafka-1          | 	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
kafka-1          | 	confluent.clm.enabled = false
kafka-1          | 	confluent.clm.frequency.in.hours = 6
kafka-1          | 	confluent.clm.list.object.thread_pool.size = 1
kafka-1          | 	confluent.clm.max.backup.days = 3
kafka-1          | 	confluent.clm.min.delay.in.minutes = 30
kafka-1          | 	confluent.clm.thread.pool.size = 2
kafka-1          | 	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
kafka-1          | 	confluent.close.connections.on.credential.delete = false
kafka-1          | 	confluent.cluster.link.admin.max.in.flight.requests = 1000
kafka-1          | 	confluent.cluster.link.admin.request.batch.size = 1
kafka-1          | 	confluent.cluster.link.allow.config.providers = true
kafka-1          | 	confluent.cluster.link.allow.legacy.message.format = false
kafka-1          | 	confluent.cluster.link.allow.truncation.below.hwm = false
kafka-1          | 	confluent.cluster.link.availability.check.mode = ALL
kafka-1          | 	confluent.cluster.link.background.thread.affinity = LINK
kafka-1          | 	confluent.cluster.link.bootstrap.translation.feature.enable = true
kafka-1          | 	confluent.cluster.link.clients.max.idle.ms = 3153600000000
kafka-1          | 	confluent.cluster.link.enable = false
kafka-1          | 	confluent.cluster.link.enable.local.admin = false
kafka-1          | 	confluent.cluster.link.enable.metrics.reduction = false
kafka-1          | 	confluent.cluster.link.enable.metrics.reduction.advanced = false
kafka-1          | 	confluent.cluster.link.fetch.response.min.bytes = 1
kafka-1          | 	confluent.cluster.link.fetch.response.total.bytes = 2147483647
kafka-1          | 	confluent.cluster.link.fetcher.auto.tune.enable = false
kafka-1          | 	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
kafka-1          | 	confluent.cluster.link.insync.fetch.response.min.bytes = 1
kafka-1          | 	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
kafka-1          | 	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
kafka-1          | 	confluent.cluster.link.intranet.connectivity.enable = false
kafka-1          | 	confluent.cluster.link.intranet.connectivity.migration.enable = false
kafka-1          | 	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.cluster.link.k1.to.k2.migration.enable = false
kafka-1          | 	confluent.cluster.link.k2.mirror.topic.metadata.enable = false
kafka-1          | 	confluent.cluster.link.local.admin.multitenant.enable = false
kafka-1          | 	confluent.cluster.link.local.reverse.connection.listener.map = null
kafka-1          | 	confluent.cluster.link.max.client.connections = 2147483647
kafka-1          | 	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
kafka-1          | 	confluent.cluster.link.metadata.topic.enable = false
kafka-1          | 	confluent.cluster.link.metadata.topic.min.isr = 2
kafka-1          | 	confluent.cluster.link.metadata.topic.partitions = 50
kafka-1          | 	confluent.cluster.link.metadata.topic.replication.factor = 3
kafka-1          | 	confluent.cluster.link.mirror.transition.batch.size = 10
kafka-1          | 	confluent.cluster.link.num.background.threads = 1
kafka-1          | 	confluent.cluster.link.num.fetchers = 1
kafka-1          | 	confluent.cluster.link.periodic.task.batch.size = 2147483647
kafka-1          | 	confluent.cluster.link.periodic.task.min.interval.ms = 1000
kafka-1          | 	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
kafka-1          | 	confluent.cluster.link.replica.fetch.connections.mode = combined
kafka-1          | 	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
kafka-1          | 	confluent.cluster.link.replication.quota.mode.per.tenant.overrides = 
kafka-1          | 	confluent.cluster.link.replication.quota.window.num = 11
kafka-1          | 	confluent.cluster.link.replication.quota.window.size.seconds = 2
kafka-1          | 	confluent.cluster.link.request.quota.capacity = 400
kafka-1          | 	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
kafka-1          | 	confluent.cluster.link.switchover.disabled.principals = []
kafka-1          | 	confluent.cluster.link.switchover.enable = false
kafka-1          | 	confluent.cluster.link.switchover.listeners = []
kafka-1          | 	confluent.cluster.link.switchover.server.states = []
kafka-1          | 	confluent.cluster.link.tenant.replication.quota.enable = false
kafka-1          | 	confluent.cluster.link.tenant.request.quota.enable = false
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.enable = false
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
kafka-1          | 	confluent.cluster.metadata.snapshot.tier.upload.enable = false
kafka-1          | 	confluent.compacted.topic.prefer.tier.fetch.ms = -1
kafka-1          | 	confluent.connection.invalid.request.delay.enable = false
kafka-1          | 	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
kafka-1          | 	confluent.consumer.fetch.partition.pruning.enable = true
kafka-1          | 	confluent.consumer.lag.emitter.enabled = false
kafka-1          | 	confluent.consumer.lag.emitter.interval.ms = 60000
kafka-1          | 	confluent.dataflow.policy.watch.monitor.ms = 300000
kafka-1          | 	confluent.default.data.policy.enforcement = true
kafka-1          | 	confluent.defer.isr.shrink.enable = false
kafka-1          | 	confluent.describe.topic.partitions.enabled = true
kafka-1          | 	confluent.disk.io.manager.enable = false
kafka-1          | 	confluent.disk.throughput.headroom = 10485760
kafka-1          | 	confluent.disk.throughput.limit = 10485760000
kafka-1          | 	confluent.disk.throughput.quota.tier.archive = 1048576000
kafka-1          | 	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
kafka-1          | 	confluent.durability.audit.batch.flush.frequency.ms = 900000
kafka-1          | 	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
kafka-1          | 	confluent.durability.audit.enable = false
kafka-1          | 	confluent.durability.audit.idempotent.producer = false
kafka-1          | 	confluent.durability.audit.initial.job.delay.ms = 900000
kafka-1          | 	confluent.durability.audit.io.bytes.per.sec = 10485760
kafka-1          | 	confluent.durability.audit.log.ignored.event.types = 
kafka-1          | 	confluent.durability.audit.reporting.batch.ms = 1800000
kafka-1          | 	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
kafka-1          | 	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
kafka-1          | 	confluent.durability.topic.partition.count = 50
kafka-1          | 	confluent.durability.topic.replication.factor = 3
kafka-1          | 	confluent.e2e_checksum.protection.enabled = false
kafka-1          | 	confluent.e2e_checksum.protection.files = [none]
kafka-1          | 	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
kafka-1          | 	confluent.elastic.cku.enabled = false
kafka-1          | 	confluent.elastic.cku.scaletozero.enabled = false
kafka-1          | 	confluent.eligible.controllers = []
kafka-1          | 	confluent.emit.network.type.default = 
kafka-1          | 	confluent.emit.network.type.tag = false
kafka-1          | 	confluent.enable.broker.reporting.min.usage.mode = true
kafka-1          | 	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
kafka-1          | 	confluent.fail.unsatisfied.placement.constraints = false
kafka-1          | 	confluent.fetch.from.follower.require.leader.epoch.enable = false
kafka-1          | 	confluent.fetch.partition.pruning.enable = true
kafka-1          | 	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
kafka-1          | 	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
kafka-1          | 	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
kafka-1          | 	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
kafka-1          | 	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
kafka-1          | 	confluent.flexible.fanout.enabled = false
kafka-1          | 	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
kafka-1          | 	confluent.flexible.fanout.mode = TENANT_QUOTA
kafka-1          | 	confluent.floor.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.floor.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.group.coordinator.dynamic.append.linger.enable = false
kafka-1          | 	confluent.group.coordinator.max.partition.queue.size = -1
kafka-1          | 	confluent.group.coordinator.offsets.batching.enable = false
kafka-1          | 	confluent.group.coordinator.offsets.writer.threads = 2
kafka-1          | 	confluent.group.coordinator.slow.event.log.count = 10
kafka-1          | 	confluent.group.coordinator.slow.event.log.interval.ms = -1
kafka-1          | 	confluent.group.coordinator.txn.offset.validation.enable = false
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.count = 10
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.enable = false
kafka-1          | 	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
kafka-1          | 	confluent.group.metadata.load.threads = 32
kafka-1          | 	confluent.group.subscription.pattern.log.interval.ms = -1
kafka-1          | 	confluent.heap.tenured.notify.bytes = 0
kafka-1          | 	confluent.heap.tenured.notify.enabled = false
kafka-1          | 	confluent.hot.partition.ratio = 0.8
kafka-1          | 	confluent.http.server.start.timeout.ms = 60000
kafka-1          | 	confluent.http.server.stop.timeout.ms = 30000
kafka-1          | 	confluent.intelligent.replication.enable = false
kafka-1          | 	confluent.intelligent.replication.push.max.memory.buffer.bytes = 209715200
kafka-1          | 	confluent.intelligent.replication.push.max.threads = 4
kafka-1          | 	confluent.intelligent.replication.push.threads.per.remote.broker = 1
kafka-1          | 	confluent.internal.metrics.enable = false
kafka-1          | 	confluent.internal.rest.server.bind.port = null
kafka-1          | 	confluent.internal.rest.server.ssl.enable = false
kafka-1          | 	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
kafka-1          | 	confluent.lat.network.context.verification.enable = false
kafka-1          | 	confluent.leader.epoch.checkpoint.checksum.enabled = false
kafka-1          | 	confluent.listener.protocol = TCP
kafka-1          | 	confluent.log.cleaner.timestamp.validation.enable = true
kafka-1          | 	confluent.log.placement.constraints = 
kafka-1          | 	confluent.max.broker.load = 1.0
kafka-1          | 	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
kafka-1          | 	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
kafka-1          | 	confluent.max.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.max.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.max.connection.throttle.ms = null
kafka-1          | 	confluent.max.segment.ms = 9223372036854775807
kafka-1          | 	confluent.metadata.active.encryptor = null
kafka-1          | 	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
kafka-1          | 	confluent.metadata.encryptor.classes = null
kafka-1          | 	confluent.metadata.encryptor.required = false
kafka-1          | 	confluent.metadata.encryptor.secret.file = null
kafka-1          | 	confluent.metadata.encryptor.secrets = null
kafka-1          | 	confluent.metadata.jvm.warmup.ms = 60000
kafka-1          | 	confluent.metadata.leader.balance.slice.delay.ms = 100
kafka-1          | 	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
kafka-1          | 	confluent.metadata.max.leader.balance.changes.per.slice = 1000
kafka-1          | 	confluent.metadata.rbac_auth.read.controller.enable = false
kafka-1          | 	confluent.metadata.rbac_auth.update.controller.enable = false
kafka-1          | 	confluent.metadata.reject.when.throttled.enable = false
kafka-1          | 	confluent.metadata.server.cluster.registry.clusters = []
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.min.acks = 0
kafka-1          | 	confluent.min.connection.throttle.ms = 0
kafka-1          | 	confluent.min.segment.ms = 1
kafka-1          | 	confluent.missing.id.cache.ttl.sec = 60
kafka-1          | 	confluent.missing.id.query.range = 20000
kafka-1          | 	confluent.missing.schema.cache.ttl.sec = 60
kafka-1          | 	confluent.mtls.build.client.cert.chain.enable = false
kafka-1          | 	confluent.mtls.enable = false
kafka-1          | 	confluent.mtls.listener.name = EXTERNAL
kafka-1          | 	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
kafka-1          | 	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
kafka-1          | 	confluent.mtls.truststore.manager.class.name = null
kafka-1          | 	confluent.multitenant.authorizer.enable.acl.state = false
kafka-1          | 	confluent.multitenant.interceptor.balancer.apis.enabled = false
kafka-1          | 	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
kafka-1          | 	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
kafka-1          | 	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
kafka-1          | 	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
kafka-1          | 	confluent.multitenant.listener.names = null
kafka-1          | 	confluent.multitenant.parse.lkc.id.enable = false
kafka-1          | 	confluent.multitenant.parse.sni.host.name.enable = false
kafka-1          | 	confluent.network.health.manager.enabled = false
kafka-1          | 	confluent.network.health.manager.external.listener.name = EXTERNAL
kafka-1          | 	confluent.network.health.manager.externalconnectivitystartup.enabled = false
kafka-1          | 	confluent.network.health.manager.min.healthy.network.samples = 3
kafka-1          | 	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
kafka-1          | 	confluent.network.health.manager.mitigation.enabled = false
kafka-1          | 	confluent.network.health.manager.network.sample.window.size = 120
kafka-1          | 	confluent.network.health.manager.sample.duration.ms = 1000
kafka-1          | 	confluent.oauth.flat.networking.verification.enable = false
kafka-1          | 	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
kafka-1          | 	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1          | 	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
kafka-1          | 	confluent.offsets.topic.max.message.bytes = -1
kafka-1          | 	confluent.offsets.topic.placement.constraints = 
kafka-1          | 	confluent.omit.network.processor.metric.tag = false
kafka-1          | 	confluent.operator.managed = false
kafka-1          | 	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
kafka-1          | 	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
kafka-1          | 	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
kafka-1          | 	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
kafka-1          | 	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
kafka-1          | 	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
kafka-1          | 	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
kafka-1          | 	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.enable = false
kafka-1          | 	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.cloud = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.domain = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variable.region = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.template.variables = 
kafka-1          | 	confluent.ppv2.endpoint.scheme.templates = 
kafka-1          | 	confluent.prefer.tier.fetch.ms = -1
kafka-1          | 	confluent.produce.throttle.pre.check.enable = false
kafka-1          | 	confluent.produce.throttle.pre.check.for.new.connection.enable = false
kafka-1          | 	confluent.producer.id.cache.broker.hard.limit = -1
kafka-1          | 	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
kafka-1          | 	confluent.producer.id.cache.extra.eviction.percentage = 0
kafka-1          | 	confluent.producer.id.cache.limit = 2147483647
kafka-1          | 	confluent.producer.id.cache.partition.hard.limit = -1
kafka-1          | 	confluent.producer.id.cache.tenant.hard.limit = -1
kafka-1          | 	confluent.producer.id.quota.manager.enable = false
kafka-1          | 	confluent.producer.id.quota.window.num = 11
kafka-1          | 	confluent.producer.id.quota.window.size.seconds = 1
kafka-1          | 	confluent.producer.id.throttle.enable = false
kafka-1          | 	confluent.producer.id.throttle.enable.threshold.percentage = 100
kafka-1          | 	confluent.protocol.netty.http2.connection.window.size = 31457280
kafka-1          | 	confluent.protocol.netty.http2.flow.control.enabled = true
kafka-1          | 	confluent.protocol.netty.http2.initial.window.size = 153600
kafka-1          | 	confluent.protocol.netty.http2.max.frame.size = 16384
kafka-1          | 	confluent.protocol.netty.http2.stream.graceful.close.timeout.ms = 60000
kafka-1          | 	confluent.protocol.netty.num.boss.threads = 1
kafka-1          | 	confluent.protocol.netty.num.worker.threads = 4
kafka-1          | 	confluent.proxy.mode.local.default = false
kafka-1          | 	confluent.proxy.protocol.fallback.enabled = false
kafka-1          | 	confluent.proxy.protocol.parser = class io.confluent.kafka.common.network.CloudProxyTlvParser
kafka-1          | 	confluent.proxy.protocol.version = NONE
kafka-1          | 	confluent.quota.computing.usage.adjustment = 0.5
kafka-1          | 	confluent.quota.dynamic.adjustment.min.usage = 102400
kafka-1          | 	confluent.quota.dynamic.enable = false
kafka-1          | 	confluent.quota.dynamic.publishing.interval.ms = 60000
kafka-1          | 	confluent.quota.dynamic.reporting.interval.ms = 30000
kafka-1          | 	confluent.quota.tenant.broker.max.consumer.rate = 13107200
kafka-1          | 	confluent.quota.tenant.broker.max.producer.rate = 13107200
kafka-1          | 	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
kafka-1          | 	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
kafka-1          | 	confluent.quota.tenant.fetch.multiplier = 1.0
kafka-1          | 	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
kafka-1          | 	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
kafka-1          | 	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.broker.max.controller.mutation.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
kafka-1          | 	confluent.quota.tenant.internal.throttling.enable = false
kafka-1          | 	confluent.quota.tenant.produce.multiplier = 1.0
kafka-1          | 	confluent.quota.tenant.user.quotas.enable = false
kafka-1          | 	confluent.rack.id.mapping = null
kafka-1          | 	confluent.regional.metadata.client.class = null
kafka-1          | 	confluent.regional.resource.manager.client.scheduler.threads = 2
kafka-1          | 	confluent.regional.resource.manager.endpoint = null
kafka-1          | 	confluent.regional.resource.manager.grpc.endpoint = null
kafka-1          | 	confluent.reject.invalid.sni.hostnames = false
kafka-1          | 	confluent.replica.fetch.backoff.max.ms = 1000
kafka-1          | 	confluent.replica.fetch.connections.mode = combined
kafka-1          | 	confluent.replication.mode = PULL
kafka-1          | 	confluent.replication.push.feature.enable = false
kafka-1          | 	confluent.reporters.telemetry.auto.enable = false
kafka-1          | 	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
kafka-1          | 	confluent.request.pipelining.enable = true
kafka-1          | 	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
kafka-1          | 	confluent.require.calling.resource.identity = false
kafka-1          | 	confluent.require.compatible.keystore.updates = true
kafka-1          | 	confluent.require.confluent.issuer = false
kafka-1          | 	confluent.roll.check.interval.ms = 300000
kafka-1          | 	confluent.schema.registry.max.cache.size = 10000
kafka-1          | 	confluent.schema.registry.max.retries = 1
kafka-1          | 	confluent.schema.registry.retries.wait.ms = 0
kafka-1          | 	confluent.schema.registry.url = null
kafka-1          | 	confluent.schema.validation.context.name.enable = false
kafka-1          | 	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
kafka-1          | 	confluent.schema.validator.multitenant.enable = false
kafka-1          | 	confluent.schema.validator.samples.per.min = 0
kafka-1          | 	confluent.security.bc.approved.mode.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.enable = false
kafka-1          | 	confluent.security.event.logger.authentication.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.authorization.event.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
kafka-1          | 	confluent.security.event.logger.enable = true
kafka-1          | 	confluent.security.event.logger.kafka.request.rate.limit = -1
kafka-1          | 	confluent.security.event.logger.physical.cluster.id = 
kafka-1          | 	confluent.security.event.router.config = 
kafka-1          | 	confluent.security.revoked.certificate.ids = 
kafka-1          | 	confluent.segment.eager.roll.enable = false
kafka-1          | 	confluent.segment.speculative.prefetch.enable = false
kafka-1          | 	confluent.share.coordinator.slow.event.log.count = 10
kafka-1          | 	confluent.share.coordinator.slow.event.log.interval.ms = -1
kafka-1          | 	confluent.share.metadata.load.threads = 32
kafka-1          | 	confluent.spiffe.id.principal.extraction.rules = 
kafka-1          | 	confluent.ssl.key.password = null
kafka-1          | 	confluent.ssl.keystore.location = null
kafka-1          | 	confluent.ssl.keystore.password = null
kafka-1          | 	confluent.ssl.keystore.type = null
kafka-1          | 	confluent.ssl.protocol = null
kafka-1          | 	confluent.ssl.truststore.location = null
kafka-1          | 	confluent.ssl.truststore.password = null
kafka-1          | 	confluent.ssl.truststore.type = null
kafka-1          | 	confluent.step.connection.rate.per.ip = -1.0
kafka-1          | 	confluent.step.connection.rate.per.tenant = -1.0
kafka-1          | 	confluent.storage.probe.disk.metrics.collection.enabled = false
kafka-1          | 	confluent.storage.probe.period.ms = -1
kafka-1          | 	confluent.storage.probe.slow.write.threshold.ms = 5000
kafka-1          | 	confluent.stray.log.delete.delay.ms = 604800000
kafka-1          | 	confluent.stray.log.max.deletions.per.run = 72
kafka-1          | 	confluent.subdomain.prefix = null
kafka-1          | 	confluent.subdomain.separator.map = null
kafka-1          | 	confluent.subdomain.separator.variable = %sep
kafka-1          | 	confluent.system.time.roll.enable = false
kafka-1          | 	confluent.telemetry.enabled = false
kafka-1          | 	confluent.telemetry.external.client.metrics.delta.temporality = true
kafka-1          | 	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
kafka-1          | 	confluent.telemetry.external.client.metrics.push.enabled = false
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.match.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
kafka-1          | 	confluent.telemetry.external.client.metrics.supported.compression.types = [zstd, lz4, gzip, snappy]
kafka-1          | 	confluent.tenant.latency.metric.enabled = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.enable = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.proactive.key.generation.enable = false
kafka-1          | 	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
kafka-1          | 	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
kafka-1          | 	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
kafka-1          | 	confluent.tier.archiver.num.threads = 2
kafka-1          | 	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
kafka-1          | 	confluent.tier.azure.block.blob.container = null
kafka-1          | 	confluent.tier.azure.block.blob.cred.file.path = null
kafka-1          | 	confluent.tier.azure.block.blob.endpoint = null
kafka-1          | 	confluent.tier.azure.block.blob.prefix = 
kafka-1          | 	confluent.tier.backend = 
kafka-1          | 	confluent.tier.bucket.probe.period.ms = -1
kafka-1          | 	confluent.tier.cleaner.compact.min.efficiency = 0.5
kafka-1          | 	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
kafka-1          | 	confluent.tier.cleaner.dedupe.buffer.size = 134217728
kafka-1          | 	confluent.tier.cleaner.dual.compaction = false
kafka-1          | 	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
kafka-1          | 	confluent.tier.cleaner.dual.compaction.validation.percent = 0
kafka-1          | 	confluent.tier.cleaner.enable = false
kafka-1          | 	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
kafka-1          | 	confluent.tier.cleaner.feature.enable = false
kafka-1          | 	confluent.tier.cleaner.io.buffer.load.factor = 0.9
kafka-1          | 	confluent.tier.cleaner.io.buffer.size = 10485760
kafka-1          | 	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1          | 	confluent.tier.cleaner.min.cleanable.ratio = 0.75
kafka-1          | 	confluent.tier.cleaner.num.threads = 2
kafka-1          | 	confluent.tier.enable = false
kafka-1          | 	confluent.tier.feature = false
kafka-1          | 	confluent.tier.fenced.segment.delete.delay.ms = 600000
kafka-1          | 	confluent.tier.fetcher.async.enable = false
kafka-1          | 	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
kafka-1          | 	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
kafka-1          | 	confluent.tier.fetcher.memorypool.bytes = 0
kafka-1          | 	confluent.tier.fetcher.num.threads = 4
kafka-1          | 	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
kafka-1          | 	confluent.tier.fetcher.offset.cache.period.ms = 60000
kafka-1          | 	confluent.tier.fetcher.offset.cache.size = 200000
kafka-1          | 	confluent.tier.gcs.bucket = null
kafka-1          | 	confluent.tier.gcs.cred.file.path = null
kafka-1          | 	confluent.tier.gcs.prefix = 
kafka-1          | 	confluent.tier.gcs.region = null
kafka-1          | 	confluent.tier.gcs.sse.customer.encryption.key = null
kafka-1          | 	confluent.tier.gcs.write.chunk.size = 0
kafka-1          | 	confluent.tier.local.hotset.bytes = -1
kafka-1          | 	confluent.tier.local.hotset.ms = 86400000
kafka-1          | 	confluent.tier.max.partition.fetch.bytes.override = 0
kafka-1          | 	confluent.tier.metadata.bootstrap.servers = null
kafka-1          | 	confluent.tier.metadata.catchup.max.poll.ms = 0
kafka-1          | 	confluent.tier.metadata.max.poll.ms = 100
kafka-1          | 	confluent.tier.metadata.namespace = null
kafka-1          | 	confluent.tier.metadata.num.partitions = 50
kafka-1          | 	confluent.tier.metadata.replication.factor = 3
kafka-1          | 	confluent.tier.metadata.request.timeout.ms = 30000
kafka-1          | 	confluent.tier.metadata.snapshots.enable = false
kafka-1          | 	confluent.tier.metadata.snapshots.interval.ms = 86400000
kafka-1          | 	confluent.tier.metadata.snapshots.retention.days = 7
kafka-1          | 	confluent.tier.metadata.snapshots.threads = 2
kafka-1          | 	confluent.tier.object.fetcher.num.threads = 1
kafka-1          | 	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
kafka-1          | 	confluent.tier.partition.state.cleanup.enable = false
kafka-1          | 	confluent.tier.partition.state.cleanup.interval.ms = 86400000
kafka-1          | 	confluent.tier.partition.state.commit.interval.ms = 15000
kafka-1          | 	confluent.tier.prefetch.cache.enable = false
kafka-1          | 	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
kafka-1          | 	confluent.tier.prefetch.cache.range.bytes = 5242880
kafka-1          | 	confluent.tier.prefetch.cache.total.size.bytes = 209715200
kafka-1          | 	confluent.tier.s3.assumerole.arn = null
kafka-1          | 	confluent.tier.s3.auto.abort.threshold.bytes = 500000
kafka-1          | 	confluent.tier.s3.aws.endpoint.override = null
kafka-1          | 	confluent.tier.s3.aws.signer.override = null
kafka-1          | 	confluent.tier.s3.bucket = null
kafka-1          | 	confluent.tier.s3.cred.file.path = null
kafka-1          | 	confluent.tier.s3.force.path.style.access = false
kafka-1          | 	confluent.tier.s3.ipv6.enabled = true
kafka-1          | 	confluent.tier.s3.prefix = 
kafka-1          | 	confluent.tier.s3.region = null
kafka-1          | 	confluent.tier.s3.security.providers = null
kafka-1          | 	confluent.tier.s3.sse.algorithm = AES256
kafka-1          | 	confluent.tier.s3.sse.customer.encryption.key = null
kafka-1          | 	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	confluent.tier.s3.ssl.key.password = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.location = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.password = null
kafka-1          | 	confluent.tier.s3.ssl.keystore.type = null
kafka-1          | 	confluent.tier.s3.ssl.protocol = TLSv1.3
kafka-1          | 	confluent.tier.s3.ssl.provider = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.location = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.password = null
kafka-1          | 	confluent.tier.s3.ssl.truststore.type = null
kafka-1          | 	confluent.tier.s3.storage.class.override = 
kafka-1          | 	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
kafka-1          | 	confluent.tier.s3.v2.enabled = false
kafka-1          | 	confluent.tier.segment.hotset.roll.min.bytes = 104857600
kafka-1          | 	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
kafka-1          | 	confluent.tier.topic.data.loss.validation.fencing.enable = false
kafka-1          | 	confluent.tier.topic.delete.backoff.ms = 21600000
kafka-1          | 	confluent.tier.topic.delete.check.interval.ms = 300000
kafka-1          | 	confluent.tier.topic.delete.max.inprogress.partitions = 100
kafka-1          | 	confluent.tier.topic.head.data.loss.validation.enable = true
kafka-1          | 	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
kafka-1          | 	confluent.tier.topic.materialization.from.snapshot.enable = false
kafka-1          | 	confluent.tier.topic.producer.enable.idempotence = true
kafka-1          | 	confluent.tier.topic.snapshots.enable = false
kafka-1          | 	confluent.tier.topic.snapshots.interval.ms = 300000
kafka-1          | 	confluent.tier.topic.snapshots.max.records = 100000
kafka-1          | 	confluent.tier.topic.snapshots.retention.hours = 168
kafka-1          | 	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
kafka-1          | 	confluent.topic.partition.default.placement = 2
kafka-1          | 	confluent.topic.policy.use.computed.assignments = false
kafka-1          | 	confluent.topic.replica.assignor.builder.class = 
kafka-1          | 	confluent.track.api.key.per.ip = false
kafka-1          | 	confluent.track.per.ip.max.size = 100000
kafka-1          | 	confluent.track.tenant.id.per.ip = false
kafka-1          | 	confluent.traffic.cdc.network.id.routes.enable = false
kafka-1          | 	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
kafka-1          | 	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
kafka-1          | 	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
kafka-1          | 	confluent.traffic.network.id = 
kafka-1          | 	confluent.traffic.network.type = 
kafka-1          | 	confluent.transaction.2pc.timeout.ms = -1
kafka-1          | 	confluent.transaction.logging.verbosity = 0
kafka-1          | 	confluent.transaction.state.log.placement.constraints = 
kafka-1          | 	confluent.unique.deprecated.request.metrics.per.tenant = 1000
kafka-1          | 	confluent.valid.broker.rack.set = null
kafka-1          | 	confluent.valid.sni.hostnames = 
kafka-1          | 	confluent.valid.sni.hostnames.exclude.suffix = 
kafka-1          | 	confluent.verify.group.subscription.prefix = false
kafka-1          | 	confluent.virtual.topic.creation.enabled = false
kafka-1          | 	confluent.zone.tagged.request.metrics.enable = false
kafka-1          | 	connection.failed.authentication.delay.ms = 100
kafka-1          | 	connection.min.expire.interval.ms = 250
kafka-1          | 	connections.max.age.ms = 3153600000000
kafka-1          | 	connections.max.idle.ms = 600000
kafka-1          | 	connections.max.reauth.ms = 0
kafka-1          | 	controlled.shutdown.enable = true
kafka-1          | 	controller.listener.names = CONTROLLER
kafka-1          | 	controller.performance.always.log.threshold.ms = 2000
kafka-1          | 	controller.performance.sample.period.ms = 60000
kafka-1          | 	controller.quorum.append.linger.ms = 25
kafka-1          | 	controller.quorum.bootstrap.servers = []
kafka-1          | 	controller.quorum.election.backoff.max.ms = 1000
kafka-1          | 	controller.quorum.election.timeout.ms = 1000
kafka-1          | 	controller.quorum.fetch.timeout.ms = 2000
kafka-1          | 	controller.quorum.request.timeout.ms = 2000
kafka-1          | 	controller.quorum.retry.backoff.ms = 20
kafka-1          | 	controller.quorum.voters = [1@controller-1:19091]
kafka-1          | 	controller.quota.window.num = 11
kafka-1          | 	controller.quota.window.size.seconds = 1
kafka-1          | 	controller.socket.timeout.ms = 30000
kafka-1          | 	create.cluster.link.policy.class.name = null
kafka-1          | 	create.topic.policy.class.name = null
kafka-1          | 	default.replication.factor = 1
kafka-1          | 	delegation.token.expiry.check.interval.ms = 3600000
kafka-1          | 	delegation.token.expiry.time.ms = 86400000
kafka-1          | 	delegation.token.max.lifetime.ms = 604800000
kafka-1          | 	delegation.token.secret.key = null
kafka-1          | 	delete.records.purgatory.purge.interval.requests = 1
kafka-1          | 	delete.topic.enable = true
kafka-1          | 	early.start.listeners = null
kafka-1          | 	enable.fips = false
kafka-1          | 	fetch.max.bytes = 57671680
kafka-1          | 	fetch.purgatory.purge.interval.requests = 1000
kafka-1          | 	floor.max.connection.creation.rate = null
kafka-1          | 	follower.replication.throttled.rate = 9223372036854775807
kafka-1          | 	follower.replication.throttled.replicas = none
kafka-1          | 	group.consumer.assignors = [uniform, range]
kafka-1          | 	group.consumer.heartbeat.interval.ms = 5000
kafka-1          | 	group.consumer.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.consumer.max.session.timeout.ms = 60000
kafka-1          | 	group.consumer.max.size = 2147483647
kafka-1          | 	group.consumer.migration.policy = bidirectional
kafka-1          | 	group.consumer.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.consumer.min.session.timeout.ms = 45000
kafka-1          | 	group.consumer.regex.refresh.interval.ms = 600000
kafka-1          | 	group.consumer.session.timeout.ms = 45000
kafka-1          | 	group.coordinator.append.linger.ms = 5
kafka-1          | 	group.coordinator.rebalance.protocols = [classic, consumer, share, streams]
kafka-1          | 	group.coordinator.threads = 4
kafka-1          | 	group.initial.rebalance.delay.ms = 0
kafka-1          | 	group.max.session.timeout.ms = 1800000
kafka-1          | 	group.max.size = 2147483647
kafka-1          | 	group.min.session.timeout.ms = 6000
kafka-1          | 	group.share.assignors = [simple]
kafka-1          | 	group.share.delivery.count.limit = 5
kafka-1          | 	group.share.enable = false
kafka-1          | 	group.share.heartbeat.interval.ms = 5000
kafka-1          | 	group.share.initialize.retry.interval.ms = 30000
kafka-1          | 	group.share.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.share.max.record.lock.duration.ms = 60000
kafka-1          | 	group.share.max.session.timeout.ms = 60000
kafka-1          | 	group.share.max.share.sessions = 2000
kafka-1          | 	group.share.max.size = 200
kafka-1          | 	group.share.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.share.min.record.lock.duration.ms = 15000
kafka-1          | 	group.share.min.session.timeout.ms = 45000
kafka-1          | 	group.share.partition.max.record.locks = 2000
kafka-1          | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafka-1          | 	group.share.record.lock.duration.ms = 30000
kafka-1          | 	group.share.rollout.ready = true
kafka-1          | 	group.share.session.timeout.ms = 45000
kafka-1          | 	group.streams.heartbeat.interval.ms = 5000
kafka-1          | 	group.streams.max.heartbeat.interval.ms = 15000
kafka-1          | 	group.streams.max.session.timeout.ms = 60000
kafka-1          | 	group.streams.max.size = 2147483647
kafka-1          | 	group.streams.max.standby.replicas = 2
kafka-1          | 	group.streams.min.heartbeat.interval.ms = 5000
kafka-1          | 	group.streams.min.session.timeout.ms = 45000
kafka-1          | 	group.streams.num.standby.replicas = 0
kafka-1          | 	group.streams.session.timeout.ms = 45000
kafka-1          | 	initial.broker.registration.timeout.ms = 60000
kafka-1          | 	inter.broker.listener.name = PLAINTEXT
kafka-1          | 	internal.metadata.delete.delay.millis = 60000
kafka-1          | 	internal.metadata.log.segment.bytes = null
kafka-1          | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafka-1          | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafka-1          | 	k2.stack.builder.class.name = null
kafka-1          | 	k2.startup.timeout.ms = 60000
kafka-1          | 	k2.topic.metadata.refresh.ms = 10000
kafka-1          | 	kafka.metrics.polling.interval.secs = 10
kafka-1          | 	kafka.metrics.reporters = []
kafka-1          | 	leader.imbalance.check.interval.seconds = 300
kafka-1          | 	leader.replication.throttled.rate = 9223372036854775807
kafka-1          | 	leader.replication.throttled.replicas = none
kafka-1          | 	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
kafka-1          | 	listeners = PLAINTEXT://kafka-1:19092, EXTERNAL://0.0.0.0:9091
kafka-1          | 	log.cleaner.backoff.ms = 15000
kafka-1          | 	log.cleaner.dedupe.buffer.size = 134217728
kafka-1          | 	log.cleaner.delete.retention.ms = 86400000
kafka-1          | 	log.cleaner.enable = true
kafka-1          | 	log.cleaner.hash.algorithm = MD5
kafka-1          | 	log.cleaner.io.buffer.load.factor = 0.9
kafka-1          | 	log.cleaner.io.buffer.size = 524288
kafka-1          | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1          | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1          | 	log.cleaner.min.cleanable.ratio = 0.5
kafka-1          | 	log.cleaner.min.compaction.lag.ms = 0
kafka-1          | 	log.cleaner.threads = 1
kafka-1          | 	log.cleanup.policy = [delete]
kafka-1          | 	log.cleanup.policy.empty.validation = none
kafka-1          | 	log.deletion.max.segments.per.run = 2147483647
kafka-1          | 	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
kafka-1          | 	log.dir = /tmp/kafka-logs
kafka-1          | 	log.dir.failure.timeout.ms = 30000
kafka-1          | 	log.dirs = /var/lib/kafka/data
kafka-1          | 	log.flush.interval.messages = 9223372036854775807
kafka-1          | 	log.flush.interval.ms = null
kafka-1          | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka-1          | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka-1          | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka-1          | 	log.index.interval.bytes = 4096
kafka-1          | 	log.index.size.max.bytes = 10485760
kafka-1          | 	log.initial.task.delay.ms = 30000
kafka-1          | 	log.local.retention.bytes = -2
kafka-1          | 	log.local.retention.ms = -2
kafka-1          | 	log.message.timestamp.after.max.ms = 3600000
kafka-1          | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafka-1          | 	log.message.timestamp.type = CreateTime
kafka-1          | 	log.preallocate = false
kafka-1          | 	log.retention.bytes = -1
kafka-1          | 	log.retention.check.interval.ms = 300000
kafka-1          | 	log.retention.hours = 168
kafka-1          | 	log.retention.minutes = null
kafka-1          | 	log.retention.ms = null
kafka-1          | 	log.roll.hours = 168
kafka-1          | 	log.roll.jitter.hours = 0
kafka-1          | 	log.roll.jitter.ms = null
kafka-1          | 	log.roll.ms = null
kafka-1          | 	log.segment.bytes = 1073741824
kafka-1          | 	log.segment.delete.delay.ms = 60000
kafka-1          | 	max.connection.creation.rate = 1.7976931348623157E308
kafka-1          | 	max.connection.creation.rate.per.ip.enable.threshold = 0.0
kafka-1          | 	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
kafka-1          | 	max.connections = 2147483647
kafka-1          | 	max.connections.per.ip = 2147483647
kafka-1          | 	max.connections.per.ip.overrides = 
kafka-1          | 	max.connections.per.tenant = 0
kafka-1          | 	max.connections.protected.listeners = []
kafka-1          | 	max.connections.reap.amount = 0
kafka-1          | 	max.incremental.fetch.session.cache.slots = 1000
kafka-1          | 	max.request.partition.size.limit = 2000
kafka-1          | 	message.max.bytes = 1048588
kafka-1          | 	metadata.log.dir = null
kafka-1          | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafka-1          | 	metadata.log.max.snapshot.interval.ms = 3600000
kafka-1          | 	metadata.log.segment.bytes = 1073741824
kafka-1          | 	metadata.log.segment.ms = 604800000
kafka-1          | 	metadata.max.idle.interval.ms = 500
kafka-1          | 	metadata.max.retention.bytes = 104857600
kafka-1          | 	metadata.max.retention.ms = 604800000
kafka-1          | 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	min.insync.replicas = 1
kafka-1          | 	multitenant.authorizer.support.resource.ids = false
kafka-1          | 	multitenant.metadata.class = null
kafka-1          | 	multitenant.metadata.dir = null
kafka-1          | 	multitenant.metadata.reload.delay.ms = 120000
kafka-1          | 	multitenant.metadata.ssl.certs.path = null
kafka-1          | 	multitenant.tenant.delete.batch.size = 10
kafka-1          | 	multitenant.tenant.delete.check.ms = 120000
kafka-1          | 	multitenant.tenant.delete.delay = 604800000
kafka-1          | 	node.id = 2
kafka-1          | 	num.io.threads = 8
kafka-1          | 	num.network.threads = 3
kafka-1          | 	num.partitions = 1
kafka-1          | 	num.recovery.threads.per.data.dir = 2
kafka-1          | 	num.replica.alter.log.dirs.threads = null
kafka-1          | 	num.replica.fetchers = 1
kafka-1          | 	offset.metadata.max.bytes = 4096
kafka-1          | 	offsets.commit.timeout.ms = 5000
kafka-1          | 	offsets.load.buffer.size = 5242880
kafka-1          | 	offsets.retention.check.interval.ms = 600000
kafka-1          | 	offsets.retention.minutes = 10080
kafka-1          | 	offsets.topic.compression.codec = 0
kafka-1          | 	offsets.topic.num.partitions = 50
kafka-1          | 	offsets.topic.replication.factor = 3
kafka-1          | 	offsets.topic.segment.bytes = 104857600
kafka-1          | 	otel.exporter.otlp.custom.endpoint = default
kafka-1          | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka-1          | 	process.roles = [broker]
kafka-1          | 	producer.id.expiration.check.interval.ms = 600000
kafka-1          | 	producer.id.expiration.ms = 86400000
kafka-1          | 	producer.purgatory.purge.interval.requests = 1000
kafka-1          | 	queued.max.request.bytes = -1
kafka-1          | 	queued.max.requests = 500
kafka-1          | 	quota.window.num = 11
kafka-1          | 	quota.window.size.seconds = 1
kafka-1          | 	quotas.consumption.expiration.time.ms = 600000
kafka-1          | 	quotas.expiration.interval.ms = 3600000
kafka-1          | 	quotas.expiration.time.ms = 604800000
kafka-1          | 	quotas.lazy.evaluation.threshold = 0.5
kafka-1          | 	quotas.topic.append.timeout.ms = 5000
kafka-1          | 	quotas.topic.compression.codec = 3
kafka-1          | 	quotas.topic.load.buffer.size = 5242880
kafka-1          | 	quotas.topic.num.partitions = 50
kafka-1          | 	quotas.topic.placement.constraints = 
kafka-1          | 	quotas.topic.replication.factor = 3
kafka-1          | 	quotas.topic.segment.bytes = 104857600
kafka-1          | 	remote.fetch.max.wait.ms = 500
kafka-1          | 	remote.list.offsets.request.timeout.ms = 30000
kafka-1          | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafka-1          | 	remote.log.manager.copier.thread.pool.size = 10
kafka-1          | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafka-1          | 	remote.log.manager.copy.quota.window.num = 11
kafka-1          | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafka-1          | 	remote.log.manager.expiration.thread.pool.size = 10
kafka-1          | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafka-1          | 	remote.log.manager.fetch.quota.window.num = 11
kafka-1          | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafka-1          | 	remote.log.manager.task.interval.ms = 30000
kafka-1          | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafka-1          | 	remote.log.manager.task.retry.backoff.ms = 500
kafka-1          | 	remote.log.manager.task.retry.jitter = 0.2
kafka-1          | 	remote.log.manager.thread.pool.size = 2
kafka-1          | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafka-1          | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafka-1          | 	remote.log.metadata.manager.class.path = null
kafka-1          | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafka-1          | 	remote.log.metadata.manager.listener.name = null
kafka-1          | 	remote.log.reader.max.pending.tasks = 100
kafka-1          | 	remote.log.reader.threads = 10
kafka-1          | 	remote.log.storage.manager.class.name = null
kafka-1          | 	remote.log.storage.manager.class.path = null
kafka-1          | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafka-1          | 	remote.log.storage.system.enable = false
kafka-1          | 	replica.fetch.backoff.ms = 1000
kafka-1          | 	replica.fetch.max.bytes = 1048576
kafka-1          | 	replica.fetch.min.bytes = 1
kafka-1          | 	replica.fetch.response.max.bytes = 10485760
kafka-1          | 	replica.fetch.wait.max.ms = 500
kafka-1          | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka-1          | 	replica.lag.time.max.ms = 30000
kafka-1          | 	replica.selector.class = null
kafka-1          | 	replica.socket.receive.buffer.bytes = 65536
kafka-1          | 	replica.socket.timeout.ms = 30000
kafka-1          | 	replication.quota.window.num = 11
kafka-1          | 	replication.quota.window.size.seconds = 1
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.enabled.mechanisms = [GSSAPI]
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism.controller.protocol = GSSAPI
kafka-1          | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	sasl.server.authn.async.enable = false
kafka-1          | 	sasl.server.authn.async.max.threads = 1
kafka-1          | 	sasl.server.authn.async.timeout.ms = 30000
kafka-1          | 	sasl.server.callback.handler.class = null
kafka-1          | 	sasl.server.max.receive.size = 524288
kafka-1          | 	security.inter.broker.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	server.max.startup.time.ms = 9223372036854775807
kafka-1          | 	share.coordinator.append.linger.ms = 5
kafka-1          | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafka-1          | 	share.coordinator.load.buffer.size = 5242880
kafka-1          | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafka-1          | 	share.coordinator.state.topic.compression.codec = 0
kafka-1          | 	share.coordinator.state.topic.min.isr = 2
kafka-1          | 	share.coordinator.state.topic.num.partitions = 50
kafka-1          | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafka-1          | 	share.coordinator.state.topic.replication.factor = 3
kafka-1          | 	share.coordinator.state.topic.segment.bytes = 104857600
kafka-1          | 	share.coordinator.threads = 1
kafka-1          | 	share.coordinator.write.timeout.ms = 5000
kafka-1          | 	share.fetch.purgatory.purge.interval.requests = 1000
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	socket.listen.backlog.size = 50
kafka-1          | 	socket.receive.buffer.bytes = 102400
kafka-1          | 	socket.request.max.bytes = 104857600
kafka-1          | 	socket.send.buffer.bytes = 102400
kafka-1          | 	ssl.allow.dn.changes = false
kafka-1          | 	ssl.allow.san.changes = false
kafka-1          | 	ssl.cipher.suites = []
kafka-1          | 	ssl.client.auth = none
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.principal.mapping.rules = DEFAULT
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	telemetry.max.bytes = 1048576
kafka-1          | 	throughput.quota.window.num = 11
kafka-1          | 	token.impersonation.validation = true
kafka-1          | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka-1          | 	transaction.max.timeout.ms = 900000
kafka-1          | 	transaction.metadata.load.threads = 32
kafka-1          | 	transaction.partition.verification.enable = true
kafka-1          | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka-1          | 	transaction.state.log.load.buffer.size = 5242880
kafka-1          | 	transaction.state.log.min.isr = 2
kafka-1          | 	transaction.state.log.num.partitions = 50
kafka-1          | 	transaction.state.log.replication.factor = 3
kafka-1          | 	transaction.state.log.segment.bytes = 104857600
kafka-1          | 	transaction.two.phase.commit.enable = false
kafka-1          | 	transactional.id.expiration.ms = 604800000
kafka-1          | 	unclean.leader.election.enable = false
kafka-1          | 	unclean.leader.election.interval.ms = 300000
kafka-1          | 	unstable.api.versions.enable = false
kafka-1          | 	unstable.feature.versions.enable = false
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:01,686] INFO [Producer clientId=confluent-metrics-reporter] Cluster ID: Nk018hRAQFytWskYqtQduw (org.apache.kafka.clients.Metadata)
controller-1     | [2025-11-13 18:48:01,688] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--2339039893306426714] Cluster ID: Nk018hRAQFytWskYqtQduw (org.apache.kafka.clients.Metadata)
controller-1     | [2025-11-13 18:48:01,692] INFO Waiting for 1 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
kafka-1          | [2025-11-13 18:48:01,716] INFO Unexpected credentials store injected: null (io.confluent.kafkarest.servlet.KafkaRestApplicationProvider)
kafka-1          | [2025-11-13 18:48:01,727] INFO For rest-app with listener null, configuring custom request logging (io.confluent.kafkarest.KafkaRestApplication)
kafka-1          | [2025-11-13 18:48:01,735] WARN REST security extensions are not configured. If an Enterprise license is expected to be configured, please install and activate the security plugins component following instructions on this website: https://docs.confluent.io/platform/current/confluent-security-plugins/kafka-rest.html#kafka-rest-security-plugins-install. Confluent does not offer Enterprise support for any self-managed (Confluent Platform) components without a valid Enterprise license. Please ignore this warning if not using an Enterprise edition of this software. (io.confluent.kafkarest.KafkaRestApplication)
kafka-1          | [2025-11-13 18:48:01,736] INFO Application provider 'KafkaRestApplicationProvider' provided 1 instance(s). (io.confluent.http.server.KafkaHttpApplicationLoader)
springcoreapi-1  | 18:48:01.715 [main] INFO org.springframework.boot.devtools.restart.RestartApplicationListener -- Restart disabled due to context in which it is running
kafka-1          | [2025-11-13 18:48:01,767] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
controller-1     | [2025-11-13 18:48:01,935] INFO HttpExporterConfig values: 
controller-1     | 	api.key = null
controller-1     | 	api.secret = null
controller-1     | 	buffer.batch.duration.max.ms = null
controller-1     | 	buffer.batch.items.max = null
controller-1     | 	buffer.inflight.submissions.max = null
controller-1     | 	buffer.pending.batches.max = null
controller-1     | 	client.attempts.max = null
controller-1     | 	client.base.url = https://collector.telemetry.confluent.cloud
controller-1     | 	client.compression = null
controller-1     | 	client.connect.timeout.ms = null
controller-1     | 	client.request.timeout.ms = null
controller-1     | 	client.retry.delay.seconds = null
controller-1     | 	enabled = true
controller-1     | 	events.enabled = true
controller-1     | 	filtering.enabled = false
controller-1     | 	filtering.routes.allowed = []
controller-1     | 	metrics.enabled = true
controller-1     | 	proxy.password = null
controller-1     | 	proxy.url = null
controller-1     | 	proxy.username = null
controller-1     | 	type = http
controller-1     |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:02,119] INFO Starting Confluent telemetry reporter with an interval of 60000 ms) (io.confluent.telemetry.reporter.TelemetryReporter)
kafka-1          | [2025-11-13 18:48:02,160] INFO Adding listener with HTTP/2: NamedURI{uri=http://0.0.0.0:8090, name='null'} (io.confluent.rest.ApplicationServer)
controller-1     | [2025-11-13 18:48:02,162] INFO [Producer clientId=confluent-metrics-reporter] Cluster ID: Nk018hRAQFytWskYqtQduw (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:02,216] INFO Loaded KafkaHttpServer implementation class io.confluent.http.server.KafkaHttpServerImpl (io.confluent.kafka.http.server.KafkaHttpServerLoader)
kafka-1          | [2025-11-13 18:48:02,218] INFO KafkaHttpServer transitioned from NEW to STARTING.. (io.confluent.http.server.KafkaHttpServerImpl)
kafka-1          | [2025-11-13 18:48:02,234] INFO Registered CombinedNetworkTrafficListener to network connector null of listener: null (io.confluent.rest.ApplicationServer)
controller-1     | [2025-11-13 18:48:02,442] ERROR Unable to submit events without credentials (io.confluent.telemetry.events.exporter.http.HttpExporter)
controller-1     | [2025-11-13 18:48:02,469] INFO Starting Confluent metrics reporter for cluster id Nk018hRAQFytWskYqtQduw with an interval of 15000 ms (io.confluent.metrics.reporter.ConfluentMetricsReporter)
controller-1     | [2025-11-13 18:48:02,476] INFO DynamicMetricsReporters initiated successfully. (kafka.server.DynamicMetricsReportersScheduler)
controller-1     | [2025-11-13 18:48:02,476] INFO DynamicMetricsReporters initiated successfully. (kafka.server.DynamicMetricsReportersScheduler)
controller-1     | [2025-11-13 18:48:02,477] INFO Stopping DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
controller-1     | [2025-11-13 18:48:02,477] INFO Stopping DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
kafka-1          | [2025-11-13 18:48:02,493] INFO Binding MetadataApiApplication to all listeners. (io.confluent.rest.Application)
kafka-1          | [2025-11-13 18:48:02,523] INFO Registered CombinedNetworkTrafficListener to network connector null of listener: null (io.confluent.rest.ApplicationServer)
kafka-1          | [2025-11-13 18:48:02,690] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
kafka-1          | [2025-11-13 18:48:02,692] INFO SchemaRegistryConfig values: 
kafka-1          | 	auto.register.schemas = false
kafka-1          | 	basic.auth.credentials.source = URL
kafka-1          | 	basic.auth.user.info = [hidden]
kafka-1          | 	bearer.auth.cache.expiry.buffer.seconds = 300
kafka-1          | 	bearer.auth.client.id = null
kafka-1          | 	bearer.auth.client.secret = null
kafka-1          | 	bearer.auth.credentials.source = STATIC_TOKEN
kafka-1          | 	bearer.auth.custom.provider.class = null
kafka-1          | 	bearer.auth.identity.pool.id = null
kafka-1          | 	bearer.auth.issuer.endpoint.url = null
kafka-1          | 	bearer.auth.logical.cluster = null
kafka-1          | 	bearer.auth.scope = null
kafka-1          | 	bearer.auth.scope.claim.name = scope
kafka-1          | 	bearer.auth.sub.claim.name = sub
kafka-1          | 	bearer.auth.token = [hidden]
kafka-1          | 	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
kafka-1          | 	http.connect.timeout.ms = 60000
kafka-1          | 	http.read.timeout.ms = 60000
kafka-1          | 	id.compatibility.strict = true
kafka-1          | 	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
kafka-1          | 	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
kafka-1          | 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
kafka-1          | 	latest.cache.size = 1000
kafka-1          | 	latest.cache.ttl.sec = -1
kafka-1          | 	latest.compatibility.strict = true
kafka-1          | 	max.retries = 3
kafka-1          | 	max.schemas.per.subject = 1000
kafka-1          | 	normalize.schemas = false
kafka-1          | 	propagate.schema.tags = false
kafka-1          | 	proxy.host = 
kafka-1          | 	proxy.port = -1
kafka-1          | 	retries.max.wait.ms = 20000
kafka-1          | 	retries.wait.ms = 1000
kafka-1          | 	rule.actions = []
kafka-1          | 	rule.executors = []
kafka-1          | 	rule.service.loader.enable = true
kafka-1          | 	schema.format = null
kafka-1          | 	schema.reflection = false
kafka-1          | 	schema.registry.basic.auth.user.info = [hidden]
kafka-1          | 	schema.registry.ssl.cipher.suites = null
kafka-1          | 	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	schema.registry.ssl.endpoint.identification.algorithm = https
kafka-1          | 	schema.registry.ssl.engine.factory.class = null
kafka-1          | 	schema.registry.ssl.key.password = null
kafka-1          | 	schema.registry.ssl.keymanager.algorithm = SunX509
kafka-1          | 	schema.registry.ssl.keystore.certificate.chain = null
kafka-1          | 	schema.registry.ssl.keystore.key = null
kafka-1          | 	schema.registry.ssl.keystore.location = null
kafka-1          | 	schema.registry.ssl.keystore.password = null
kafka-1          | 	schema.registry.ssl.keystore.type = JKS
kafka-1          | 	schema.registry.ssl.protocol = TLSv1.3
kafka-1          | 	schema.registry.ssl.provider = null
kafka-1          | 	schema.registry.ssl.secure.random.implementation = null
kafka-1          | 	schema.registry.ssl.trustmanager.algorithm = PKIX
kafka-1          | 	schema.registry.ssl.truststore.certificates = null
kafka-1          | 	schema.registry.ssl.truststore.location = null
kafka-1          | 	schema.registry.ssl.truststore.password = null
kafka-1          | 	schema.registry.ssl.truststore.type = JKS
kafka-1          | 	schema.registry.url = [http://localhost:8081]
kafka-1          | 	schema.registry.url.randomize = false
kafka-1          | 	use.latest.version = false
kafka-1          | 	use.latest.with.metadata = null
kafka-1          | 	use.schema.id = -1
kafka-1          | 	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
kafka-1          | 	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
kafka-1          | 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
controller-1     | [2025-11-13 18:48:02,711] INFO Waiting for 2 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
kafka-1          | [2025-11-13 18:48:02,718] INFO Binding EmbeddedKafkaRestApplication to all listeners. (io.confluent.rest.Application)
springcoreapi-1  | 
springcoreapi-1  |   .   ____          _            __ _ _
springcoreapi-1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
springcoreapi-1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
springcoreapi-1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
springcoreapi-1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
springcoreapi-1  |  =========|_|==============|___/=/_/_/_/
springcoreapi-1  | 
springcoreapi-1  |  :: Spring Boot ::                (v3.5.7)
springcoreapi-1  | 
kafka-1          | [2025-11-13 18:48:02,785] INFO jetty-12.0.25; built: 2025-08-11T23:52:37.219Z; git: a862b76d8372e24205765182d9ae1d1d333ce2ea; jvm 21.0.8+9-LTS (org.eclipse.jetty.server.Server)
kafka-ui-1       | [30m2025-11-13 18:48:02,822[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
kafka-1          | [2025-11-13 18:48:02,927] INFO Session workerName=node0 (org.eclipse.jetty.session.DefaultSessionIdManager)
kafka-1          | [2025-11-13 18:48:02,948] INFO Started oeje10s.ServletContextHandler@5686b5fc{/v1/metadata,/v1/metadata,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@22026cf1{STARTED}} (org.eclipse.jetty.server.handler.ContextHandler)
springcoreapi-1  | 2025-11-13T18:48:02.899Z  INFO 118 --- [feedback-api] [           main] c.j.s.g.p.f.FeedbackApiApplicationTests  : Starting FeedbackApiApplicationTests using Java 25.0.1 with PID 118 (started by root in /app)
springcoreapi-1  | 2025-11-13T18:48:02.903Z  INFO 118 --- [feedback-api] [           main] c.j.s.g.p.f.FeedbackApiApplicationTests  : No active profile set, falling back to 1 default profile: "default"
kafka-1          | [2025-11-13 18:48:03,538] INFO HV000001: Hibernate Validator 8.0.1.Final (org.hibernate.validator.internal.util.Version)
kafka-ui-1       | [30m2025-11-13 18:48:03,727[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 3 endpoint(s) beneath base path '/actuator'
kafka-1          | [2025-11-13 18:48:03,899] INFO Started oeje10s.ServletContextHandler@5686b5fc{/v1/metadata,/v1/metadata,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@22026cf1{STARTED}} (org.eclipse.jetty.ee10.servlet.ServletContextHandler)
kafka-1          | [2025-11-13 18:48:03,902] INFO Started oeje10s.ServletContextHandler@556969a1{/kafka,/kafka,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@68f0d6a8{STARTED}} (org.eclipse.jetty.server.handler.ContextHandler)
kafka-1          | [2025-11-13 18:48:03,956] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
kafka-1          | [2025-11-13 18:48:03,961] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
kafka-1          | [2025-11-13 18:48:03,981] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
kafka-1          | [2025-11-13 18:48:04,002] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
controller-1     | [2025-11-13 18:48:04,715] INFO Waiting for 4 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
kafka-1          | [2025-11-13 18:48:04,895] INFO Started oeje10s.ServletContextHandler@556969a1{/kafka,/kafka,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@68f0d6a8{STARTED}} (org.eclipse.jetty.ee10.servlet.ServletContextHandler)
kafka-1          | [2025-11-13 18:48:04,977] INFO Started oeje10s.ServletContextHandler@439157a8{/ws,/ws,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@79b45a7d{STARTED}} (org.eclipse.jetty.server.handler.ContextHandler)
kafka-1          | [2025-11-13 18:48:04,978] INFO Started oeje10s.ServletContextHandler@439157a8{/ws,/ws,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@79b45a7d{STARTED}} (org.eclipse.jetty.ee10.servlet.ServletContextHandler)
springcoreapi-1  | 2025-11-13T18:48:04.897Z  INFO 118 --- [feedback-api] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
kafka-1          | [2025-11-13 18:48:04,982] INFO Started oeje10s.ServletContextHandler@73f80e4{/ws,/ws,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@1e77d895{STARTED}} (org.eclipse.jetty.server.handler.ContextHandler)
kafka-1          | [2025-11-13 18:48:04,982] INFO Started oeje10s.ServletContextHandler@73f80e4{/ws,/ws,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@1e77d895{STARTED}} (org.eclipse.jetty.ee10.servlet.ServletContextHandler)
kafka-1          | [2025-11-13 18:48:04,991] INFO Getter/setter type mismatch for mbean attribute formEncodedMethods in class org.eclipse.jetty.server.HttpConfiguration, attribute will be read-only (org.eclipse.jetty.jmx.MetaData)
kafka-1          | [2025-11-13 18:48:05,014] INFO Started NetworkTrafficServerConnector@17ae13d5{HTTP/1.1, (http/1.1, h2c)}{0.0.0.0:8090} (org.eclipse.jetty.server.AbstractConnector)
kafka-1          | [2025-11-13 18:48:05,018] INFO Started icr.ApplicationServer@287ad0da{STARTING}[12.0.25,sto=5000] @11649ms (org.eclipse.jetty.server.Server)
kafka-1          | [2025-11-13 18:48:05,018] INFO KafkaHttpServer transitioned from STARTING to RUNNING.. (io.confluent.http.server.KafkaHttpServerImpl)
kafka-1          | [2025-11-13 18:48:05,051] INFO LicenseConfig values: 
kafka-1          | 	confluent.license = [hidden]
kafka-1          | 	confluent.license.retry.backoff.max.ms = 100000
kafka-1          | 	confluent.license.retry.backoff.min.ms = 1000
kafka-1          | 	confluent.license.topic = _confluent-license
kafka-1          | 	confluent.license.topic.create.timeout.ms = 600000
kafka-1          | 	confluent.license.topic.replication.factor = 1
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,051] INFO LicenseConfig values: 
kafka-1          | 	confluent.license = [hidden]
kafka-1          | 	confluent.license.retry.backoff.max.ms = 100000
kafka-1          | 	confluent.license.retry.backoff.min.ms = 1000
kafka-1          | 	confluent.license.topic = _confluent-license
kafka-1          | 	confluent.license.topic.create.timeout.ms = 600000
kafka-1          | 	confluent.license.topic.replication.factor = 1
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,074] INFO AdminClientConfig values: 
kafka-1          | 	bootstrap.controllers = []
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = _confluent-license-admin-2
kafka-1          | 	confluent.admin.client.describe.topic.partitions.enabled = true
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 300000
kafka-1          | 	default.api.timeout.ms = 60000
kafka-1          | 	enable.metrics.push = false
kafka-1          | 	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = none
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	receive.buffer.bytes = 65536
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	retries = 2147483647
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 100
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
springcoreapi-1  | 2025-11-13T18:48:05.072Z  INFO 118 --- [feedback-api] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 143 ms. Found 1 JPA repository interface.
kafka-1          | [2025-11-13 18:48:05,126] INFO These configurations '[replication.factor, confluent.metrics.reporter.bootstrap.servers, jmx.hostname, allow.auto.create.topics, min.insync.replicas, jmx.port]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,127] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,127] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,127] INFO Kafka startTimeMs: 1763059685126 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,179] INFO App info kafka.admin.client for _confluent-license-admin-2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,204] INFO Starting License Store (io.confluent.license.LicenseStore)
kafka-1          | [2025-11-13 18:48:05,205] INFO Starting KafkaBasedLog with topic _confluent-command reportErrorsToCallback=false (io.confluent.license.util.LicenseKafkaBasedLog)
kafka-1          | [2025-11-13 18:48:05,206] INFO AdminClientConfig values: 
kafka-1          | 	bootstrap.controllers = []
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = _confluent-license-admin-2
kafka-1          | 	confluent.admin.client.describe.topic.partitions.enabled = true
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 300000
kafka-1          | 	default.api.timeout.ms = 60000
kafka-1          | 	enable.metrics.push = false
kafka-1          | 	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = none
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	receive.buffer.bytes = 65536
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	retries = 2147483647
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 100
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,209] INFO These configurations '[replication.factor, confluent.metrics.reporter.bootstrap.servers, jmx.hostname, allow.auto.create.topics, min.insync.replicas, jmx.port]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,210] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,211] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,211] INFO Kafka startTimeMs: 1763059685210 (org.apache.kafka.common.utils.AppInfoParser)
controller-1     | [2025-11-13 18:48:05,286] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-command. (kafka.assignor.ConfluentReplicaPlacer)
controller-1     | [2025-11-13 18:48:05,286] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-command. (kafka.assignor.ConfluentReplicaPlacer)
controller-1     | [2025-11-13 18:48:05,307] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-command', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='1')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): SUCCESS (org.apache.kafka.controller.ReplicationControlManager)
controller-1     | [2025-11-13 18:48:05,309] INFO [ControllerServer id=1] Replayed TopicRecord for topic _confluent-command with topic ID guYMj4njQYCVx_wliKlG0Q. (org.apache.kafka.controller.ReplicationControlManager)
controller-1     | [2025-11-13 18:48:05,309] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-command') which set configuration cleanup.policy to compact (org.apache.kafka.controller.ConfigurationControlManager)
controller-1     | [2025-11-13 18:48:05,310] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-command') which set configuration min.insync.replicas to 1 (org.apache.kafka.controller.ConfigurationControlManager)
controller-1     | [2025-11-13 18:48:05,311] INFO [ControllerServer id=1] Removed ELRs from 0 partitions of topic _confluent-command. (org.apache.kafka.controller.ReplicationControlManager)
controller-1     | [2025-11-13 18:48:05,320] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-command-0 with topic ID guYMj4njQYCVx_wliKlG0Q and PartitionRegistration(replicas=[2], observers=[], directories=[6bCTz2tZ517tPjzYLk0jFQ], isr=[2], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=2, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
controller-1     | [2025-11-13 18:48:05,344] INFO SBC Event SbcMetadataUpdateEvent-21 generated 1 more events to enqueue in the following order - [SbcConfigUpdateEvent-22]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:05,344] INFO Handling event SbcKraftBrokerAdditionEvent-12 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:05,345] INFO Processing SbcKraftBrokerAdditionEvent-12 event with data: empty_brokers: [], new_brokers: [2] (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:05,345] WARN Notified of broker additions (empty broker ids [], new brokers [2]) but DataBalancer is disabled -- ignoring for now (io.confluent.databalancer.KafkaDataBalanceManager)
controller-1     | [2025-11-13 18:48:05,345] INFO Handling event SbcConfigUpdateEvent-22 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:05,346] INFO Balancer notified of a config change: ConfigurationsDelta(changes={ConfigResource(type=TOPIC, name='_confluent-command')=ConfigurationDelta(changedKeys=[cleanup.policy, min.insync.replicas])}) (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:05,346] INFO There were 0 change(s) and 0 deletion(s) to balancer configs. Changed Configs: {}, Deleted Configs: [] (io.confluent.databalancer.event.SbcEvent)
kafka-1          | [2025-11-13 18:48:05,358] INFO App info kafka.admin.client for _confluent-license-admin-2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,362] INFO [Broker id=2] Transitioning 1 partition(s) to local leaders. (state.change.logger)
kafka-1          | [2025-11-13 18:48:05,362] INFO [Broker id=2] Transitioning 1 partition(s) to local leaders. (state.change.logger)
kafka-1          | [2025-11-13 18:48:05,364] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-command-0) (kafka.server.ReplicaFetcherManager)
kafka-1          | [2025-11-13 18:48:05,364] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-command-0) (kafka.server.ReplicaFetcherManager)
kafka-1          | [2025-11-13 18:48:05,365] INFO ConsumerConfig values: 
kafka-1          | 	allow.auto.create.topics = true
kafka-1          | 	auto.commit.interval.ms = 5000
kafka-1          | 	auto.offset.reset = latest
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	check.crcs = true
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = _confluent-license-consumer-2
kafka-1          | 	client.rack = 
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 540000
kafka-1          | 	default.api.timeout.ms = 60000
kafka-1          | 	enable.auto.commit = false
kafka-1          | 	enable.metrics.push = false
kafka-1          | 	exclude.internal.topics = true
kafka-1          | 	fetch.max.bytes = 52428800
kafka-1          | 	fetch.max.wait.ms = 500
kafka-1          | 	fetch.min.bytes = 1
kafka-1          | 	group.id = null
kafka-1          | 	group.instance.id = null
kafka-1          | 	group.protocol = classic
kafka-1          | 	group.remote.assignor = null
kafka-1          | 	heartbeat.interval.ms = 3000
kafka-1          | 	interceptor.classes = []
kafka-1          | 	internal.leave.group.on.close = true
kafka-1          | 	internal.throw.on.fetch.stable.offset.unsupported = false
kafka-1          | 	isolation.level = read_uncommitted
kafka-1          | 	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
kafka-1          | 	max.partition.fetch.bytes = 1048576
kafka-1          | 	max.poll.interval.ms = 300000
kafka-1          | 	max.poll.records = 500
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = none
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
kafka-1          | 	receive.buffer.bytes = 65536
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 120000
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 100
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	session.timeout.ms = 45000
kafka-1          | 	share.acknowledgement.mode = implicit
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,368] INFO [Broker id=2] Creating new partition _confluent-command-0 with topic id guYMj4njQYCVx_wliKlG0Q. (state.change.logger)
kafka-1          | [2025-11-13 18:48:05,368] INFO [Broker id=2] Creating new partition _confluent-command-0 with topic id guYMj4njQYCVx_wliKlG0Q. (state.change.logger)
kafka-1          | [2025-11-13 18:48:05,394] INFO [Broker id=2] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
kafka-1          | [2025-11-13 18:48:05,394] INFO [Broker id=2] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
kafka-1          | [2025-11-13 18:48:05,417] INFO These configurations '[confluent.metrics.reporter.bootstrap.servers, jmx.hostname, jmx.port]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,417] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,417] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,417] INFO Kafka startTimeMs: 1763059685417 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,423] INFO [MergedLog partition=_confluent-command-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
kafka-1          | [2025-11-13 18:48:05,426] INFO Created log for partition _confluent-command-0 in /var/lib/kafka/data/_confluent-command-0 with properties {cleanup.policy=compact, min.insync.replicas=1} (kafka.log.LogManager)
kafka-ui-1       | [30m2025-11-13 18:48:05,425[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
kafka-1          | [2025-11-13 18:48:05,426] INFO Created log for partition _confluent-command-0 in /var/lib/kafka/data/_confluent-command-0 with properties {cleanup.policy=compact, min.insync.replicas=1} (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:05,428] INFO [Partition _confluent-command-0 broker=2] No checkpointed highwatermark is found for partition _confluent-command-0 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:05,428] INFO [Partition _confluent-command-0 broker=2] No checkpointed highwatermark is found for partition _confluent-command-0 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:05,431] INFO [Consumer clientId=_confluent-license-consumer-2, groupId=null] Cluster ID: Nk018hRAQFytWskYqtQduw (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:05,431] INFO [Partition _confluent-command-0 broker=2] Log loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:05,431] INFO [Partition _confluent-command-0 broker=2] Log loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:05,435] INFO Setting topicIdPartition guYMj4njQYCVx_wliKlG0Q:_confluent-command-0 (kafka.tier.state.FileTierPartitionState)
kafka-1          | [2025-11-13 18:48:05,435] INFO Setting topicIdPartition guYMj4njQYCVx_wliKlG0Q:_confluent-command-0 (kafka.tier.state.FileTierPartitionState)
kafka-1          | [2025-11-13 18:48:05,440] INFO [MergedLog partition=_confluent-command-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-command-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
kafka-1          | [2025-11-13 18:48:05,440] INFO [MergedLog partition=_confluent-command-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-command-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
kafka-1          | [2025-11-13 18:48:05,459] INFO App info kafka.consumer for _confluent-license-consumer-2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,460] INFO ProducerConfig values: 
kafka-1          | 	acks = -1
kafka-1          | 	batch.size = 16384
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	buffer.memory = 33554432
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = _confluent-license-producer-2
kafka-1          | 	compression.gzip.level = -1
kafka-1          | 	compression.lz4.level = 9
kafka-1          | 	compression.type = none
kafka-1          | 	compression.zstd.level = 3
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 540000
kafka-1          | 	delivery.timeout.ms = 120000
kafka-1          | 	enable.idempotence = false
kafka-1          | 	enable.metrics.push = false
kafka-1          | 	interceptor.classes = []
kafka-1          | 	key.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde
kafka-1          | 	linger.ms = 5
kafka-1          | 	max.block.ms = 60000
kafka-1          | 	max.in.flight.requests.per.connection = 1
kafka-1          | 	max.request.size = 1048576
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.max.idle.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = none
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	partitioner.adaptive.partitioning.enable = true
kafka-1          | 	partitioner.availability.timeout.ms = 0
kafka-1          | 	partitioner.class = null
kafka-1          | 	partitioner.ignore.keys = false
kafka-1          | 	receive.buffer.bytes = 32768
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	retries = 2147483647
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 100
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	transaction.timeout.ms = 60000
kafka-1          | 	transaction.two.phase.commit.enable = false
kafka-1          | 	transactional.id = null
kafka-1          | 	value.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,461] INFO [Broker id=2] Leader _confluent-command-0 with topic id Some(guYMj4njQYCVx_wliKlG0Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [2], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
kafka-1          | [2025-11-13 18:48:05,461] INFO [Broker id=2] Leader _confluent-command-0 with topic id Some(guYMj4njQYCVx_wliKlG0Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [2], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
kafka-1          | [2025-11-13 18:48:05,467] INFO These configurations '[confluent.metrics.reporter.bootstrap.servers, jmx.hostname, allow.auto.create.topics, jmx.port]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,467] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,467] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,467] INFO Kafka startTimeMs: 1763059685467 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,468] INFO ConsumerConfig values: 
kafka-1          | 	allow.auto.create.topics = true
kafka-1          | 	auto.commit.interval.ms = 5000
kafka-1          | 	auto.offset.reset = earliest
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	check.crcs = true
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = _confluent-license-consumer-2
kafka-1          | 	client.rack = 
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 540000
kafka-1          | 	default.api.timeout.ms = 60000
kafka-1          | 	enable.auto.commit = false
kafka-1          | 	enable.metrics.push = false
kafka-1          | 	exclude.internal.topics = true
kafka-1          | 	fetch.max.bytes = 52428800
kafka-1          | 	fetch.max.wait.ms = 500
kafka-1          | 	fetch.min.bytes = 1
kafka-1          | 	group.id = null
kafka-1          | 	group.instance.id = null
kafka-1          | 	group.protocol = classic
kafka-1          | 	group.remote.assignor = null
kafka-1          | 	heartbeat.interval.ms = 3000
kafka-1          | 	interceptor.classes = []
kafka-1          | 	internal.leave.group.on.close = true
kafka-1          | 	internal.throw.on.fetch.stable.offset.unsupported = false
kafka-1          | 	isolation.level = read_uncommitted
kafka-1          | 	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
kafka-1          | 	max.partition.fetch.bytes = 1048576
kafka-1          | 	max.poll.interval.ms = 300000
kafka-1          | 	max.poll.records = 500
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = none
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
kafka-1          | 	receive.buffer.bytes = 65536
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 120000
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 100
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	session.timeout.ms = 45000
kafka-1          | 	share.acknowledgement.mode = implicit
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,474] INFO These configurations '[confluent.metrics.reporter.bootstrap.servers, jmx.hostname, jmx.port]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:05,474] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,474] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,474] INFO Kafka startTimeMs: 1763059685474 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:05,480] INFO [Producer clientId=_confluent-license-producer-2] Cluster ID: Nk018hRAQFytWskYqtQduw (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:05,483] INFO [DynamicConfigPublisher broker id=2] Updating topic _confluent-command with new configuration : cleanup.policy -> compact,min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafka-1          | [2025-11-13 18:48:05,483] INFO [DynamicConfigPublisher broker id=2] Updating topic _confluent-command with new configuration : cleanup.policy -> compact,min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafka-1          | [2025-11-13 18:48:05,487] INFO [Consumer clientId=_confluent-license-consumer-2, groupId=null] Cluster ID: Nk018hRAQFytWskYqtQduw (org.apache.kafka.clients.Metadata)
kafka-1          | [2025-11-13 18:48:05,492] INFO [Consumer clientId=_confluent-license-consumer-2, groupId=null] Assigned to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
kafka-1          | [2025-11-13 18:48:05,497] INFO [Consumer clientId=_confluent-license-consumer-2, groupId=null] Seeking to AutoOffsetResetStrategy{type=earliest} offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
kafka-ui-1       | [30m2025-11-13 18:48:05,506[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 19.43 seconds (process running for 22.615)
kafka-1          | [2025-11-13 18:48:05,556] INFO Finished reading KafkaBasedLog for topic _confluent-command (io.confluent.license.util.LicenseKafkaBasedLog)
kafka-1          | [2025-11-13 18:48:05,556] INFO Started KafkaBasedLog for topic _confluent-command (io.confluent.license.util.LicenseKafkaBasedLog)
kafka-1          | [2025-11-13 18:48:05,557] INFO Started License Store (io.confluent.license.LicenseStore)
kafka-1          | [2025-11-13 18:48:06,118] INFO AdminClientConfig values: 
kafka-1          | 	bootstrap.controllers = []
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = _confluent-license-admin-2
kafka-1          | 	confluent.admin.client.describe.topic.partitions.enabled = true
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 300000
kafka-1          | 	default.api.timeout.ms = 60000
kafka-1          | 	enable.metrics.push = false
kafka-1          | 	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = none
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	receive.buffer.bytes = 65536
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	retries = 2147483647
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 100
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:06,122] INFO These configurations '[replication.factor, confluent.metrics.reporter.bootstrap.servers, jmx.hostname, allow.auto.create.topics, min.insync.replicas, jmx.port]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:06,122] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,123] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,123] INFO Kafka startTimeMs: 1763059686122 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,147] INFO App info kafka.admin.client for _confluent-license-admin-2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,286] INFO AdminClientConfig values: 
kafka-1          | 	bootstrap.controllers = []
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = _confluent-license-admin-2
kafka-1          | 	confluent.admin.client.describe.topic.partitions.enabled = true
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.metrics.reporter.bootstrap.servers = kafka-1:19092
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 300000
kafka-1          | 	default.api.timeout.ms = 60000
kafka-1          | 	enable.metrics.push = false
kafka-1          | 	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = none
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	receive.buffer.bytes = 65536
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	retries = 2147483647
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 100
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:06,290] INFO These configurations '[replication.factor, confluent.metrics.reporter.bootstrap.servers, jmx.hostname, allow.auto.create.topics, min.insync.replicas, jmx.port]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:06,291] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,291] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,291] INFO Kafka startTimeMs: 1763059686291 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,309] INFO App info kafka.admin.client for _confluent-license-admin-2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,314] INFO License for single cluster, single node (io.confluent.license.LicenseManager)
kafka-1          | [2025-11-13 18:48:06,329] INFO [BrokerServer id=2] Transition from STARTING to STARTED (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:06,329] INFO [BrokerServer id=2] Transition from STARTING to STARTED (kafka.server.BrokerServer)
kafka-1          | [2025-11-13 18:48:06,330] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,330] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,330] INFO Kafka startTimeMs: 1763059686330 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,330] INFO [KafkaRaftServer nodeId=2] Kafka Server started (kafka.server.KafkaRaftServer)
kafka-1          | [2025-11-13 18:48:06,330] INFO [KafkaRaftServer nodeId=2] Kafka Server started (kafka.server.KafkaRaftServer)
kafka-1          | [2025-11-13 18:48:06,332] INFO Try creating topic __internal_confluent_only_broker_info (kafka.server.BrokerTypeTopicCreator)
kafka-1          | [2025-11-13 18:48:06,332] INFO Try creating topic __internal_confluent_only_broker_info (kafka.server.BrokerTypeTopicCreator)
controller-1     | [2025-11-13 18:48:06,352] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic __internal_confluent_only_broker_info. (kafka.assignor.ConfluentReplicaPlacer)
controller-1     | [2025-11-13 18:48:06,352] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic __internal_confluent_only_broker_info. (kafka.assignor.ConfluentReplicaPlacer)
controller-1     | [2025-11-13 18:48:06,354] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='__internal_confluent_only_broker_info', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): SUCCESS (org.apache.kafka.controller.ReplicationControlManager)
controller-1     | [2025-11-13 18:48:06,357] INFO [ControllerServer id=1] Replayed TopicRecord for topic __internal_confluent_only_broker_info with topic ID ZXPKAUH-QK-mWNqO-V5w-Q. (org.apache.kafka.controller.ReplicationControlManager)
controller-1     | [2025-11-13 18:48:06,358] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__internal_confluent_only_broker_info') which set configuration cleanup.policy to compact (org.apache.kafka.controller.ConfigurationControlManager)
controller-1     | [2025-11-13 18:48:06,358] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __internal_confluent_only_broker_info-0 with topic ID ZXPKAUH-QK-mWNqO-V5w-Q and PartitionRegistration(replicas=[2], observers=[], directories=[6bCTz2tZ517tPjzYLk0jFQ], isr=[2], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=2, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
controller-1     | [2025-11-13 18:48:06,389] INFO SBC Event SbcMetadataUpdateEvent-25 generated 1 more events to enqueue in the following order - [SbcConfigUpdateEvent-26]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:06,389] INFO Handling event SbcConfigUpdateEvent-26 (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:06,390] INFO Balancer notified of a config change: ConfigurationsDelta(changes={ConfigResource(type=TOPIC, name='__internal_confluent_only_broker_info')=ConfigurationDelta(changedKeys=[cleanup.policy])}) (io.confluent.databalancer.event.SbcEvent)
controller-1     | [2025-11-13 18:48:06,391] INFO There were 0 change(s) and 0 deletion(s) to balancer configs. Changed Configs: {}, Deleted Configs: [] (io.confluent.databalancer.event.SbcEvent)
springcoreapi-1  | 2025-11-13T18:48:06.312Z  INFO 118 --- [feedback-api] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
kafka-1          | [2025-11-13 18:48:06,396] INFO [Broker id=2] Transitioning 1 partition(s) to local leaders. (state.change.logger)
kafka-1          | [2025-11-13 18:48:06,396] INFO [Broker id=2] Transitioning 1 partition(s) to local leaders. (state.change.logger)
kafka-1          | [2025-11-13 18:48:06,396] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__internal_confluent_only_broker_info-0) (kafka.server.ReplicaFetcherManager)
kafka-1          | [2025-11-13 18:48:06,396] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__internal_confluent_only_broker_info-0) (kafka.server.ReplicaFetcherManager)
kafka-1          | [2025-11-13 18:48:06,397] INFO [Broker id=2] Creating new partition __internal_confluent_only_broker_info-0 with topic id ZXPKAUH-QK-mWNqO-V5w-Q. (state.change.logger)
kafka-1          | [2025-11-13 18:48:06,397] INFO [Broker id=2] Creating new partition __internal_confluent_only_broker_info-0 with topic id ZXPKAUH-QK-mWNqO-V5w-Q. (state.change.logger)
kafka-1          | [2025-11-13 18:48:06,401] INFO [Broker id=2] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
kafka-1          | [2025-11-13 18:48:06,401] INFO [Broker id=2] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
kafka-1          | [2025-11-13 18:48:06,402] INFO Created topic __internal_confluent_only_broker_info with 1 partitions (kafka.server.KraftInternalAdmin)
kafka-1          | [2025-11-13 18:48:06,402] INFO Created topic __internal_confluent_only_broker_info with 1 partitions (kafka.server.KraftInternalAdmin)
kafka-1          | [2025-11-13 18:48:06,410] INFO [MergedLog partition=__internal_confluent_only_broker_info-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
kafka-1          | [2025-11-13 18:48:06,410] INFO ProducerConfig values: 
kafka-1          | 	acks = -1
kafka-1          | 	batch.size = 16384
kafka-1          | 	bootstrap.servers = [kafka-1:19092]
kafka-1          | 	buffer.memory = 33554432
kafka-1          | 	client.dns.lookup = use_all_dns_ips
kafka-1          | 	client.id = __kafka.brokerTypeTopicClient-Nk018hRAQFytWskYqtQduw-2
kafka-1          | 	compression.gzip.level = -1
kafka-1          | 	compression.lz4.level = 9
kafka-1          | 	compression.type = none
kafka-1          | 	compression.zstd.level = 3
kafka-1          | 	confluent.client.switchover.disable = false
kafka-1          | 	confluent.lkc.id = null
kafka-1          | 	confluent.proxy.protocol.client.address = null
kafka-1          | 	confluent.proxy.protocol.client.mode = PROXY
kafka-1          | 	confluent.proxy.protocol.client.port = null
kafka-1          | 	confluent.proxy.protocol.client.version = NONE
kafka-1          | 	confluent.selectable.plugin.class = null
kafka-1          | 	connections.max.idle.ms = 540000
kafka-1          | 	delivery.timeout.ms = 120000
kafka-1          | 	enable.idempotence = true
kafka-1          | 	enable.metrics.push = false
kafka-1          | 	interceptor.classes = []
kafka-1          | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
kafka-1          | 	linger.ms = 5
kafka-1          | 	max.block.ms = 60000
kafka-1          | 	max.in.flight.requests.per.connection = 1
kafka-1          | 	max.request.size = 1048576
kafka-1          | 	metadata.max.age.ms = 300000
kafka-1          | 	metadata.max.idle.ms = 300000
kafka-1          | 	metadata.recovery.rebootstrap.trigger.ms = 300000
kafka-1          | 	metadata.recovery.strategy = none
kafka-1          | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafka-1          | 	metrics.num.samples = 2
kafka-1          | 	metrics.recording.level = INFO
kafka-1          | 	metrics.sample.window.ms = 30000
kafka-1          | 	partitioner.adaptive.partitioning.enable = true
kafka-1          | 	partitioner.availability.timeout.ms = 0
kafka-1          | 	partitioner.class = null
kafka-1          | 	partitioner.ignore.keys = false
kafka-1          | 	receive.buffer.bytes = 32768
kafka-1          | 	reconnect.backoff.max.ms = 1000
kafka-1          | 	reconnect.backoff.ms = 50
kafka-1          | 	request.timeout.ms = 30000
kafka-1          | 	retries = 5
kafka-1          | 	retry.backoff.max.ms = 1000
kafka-1          | 	retry.backoff.ms = 100
kafka-1          | 	sasl.client.callback.handler.class = null
kafka-1          | 	sasl.jaas.config = null
kafka-1          | 	sasl.jaas.config.jndi.allowlist = null
kafka-1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-1          | 	sasl.kerberos.service.name = null
kafka-1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1          | 	sasl.login.callback.handler.class = null
kafka-1          | 	sasl.login.class = null
kafka-1          | 	sasl.login.connect.timeout.ms = null
kafka-1          | 	sasl.login.read.timeout.ms = null
kafka-1          | 	sasl.login.refresh.buffer.seconds = 300
kafka-1          | 	sasl.login.refresh.min.period.seconds = 60
kafka-1          | 	sasl.login.refresh.window.factor = 0.8
kafka-1          | 	sasl.login.refresh.window.jitter = 0.05
kafka-1          | 	sasl.login.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.login.retry.backoff.ms = 100
kafka-1          | 	sasl.mechanism = GSSAPI
kafka-1          | 	sasl.oauthbearer.assertion.algorithm = RS256
kafka-1          | 	sasl.oauthbearer.assertion.claim.aud = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.minutes = 5
kafka-1          | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafka-1          | 	sasl.oauthbearer.assertion.claim.iss = null
kafka-1          | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.include = false
kafka-1          | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafka-1          | 	sasl.oauthbearer.assertion.claim.sub = null
kafka-1          | 	sasl.oauthbearer.assertion.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.file = null
kafka-1          | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafka-1          | 	sasl.oauthbearer.assertion.template.file = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.id = null
kafka-1          | 	sasl.oauthbearer.client.credentials.client.secret = null
kafka-1          | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-1          | 	sasl.oauthbearer.expected.audience = null
kafka-1          | 	sasl.oauthbearer.expected.issuer = null
kafka-1          | 	sasl.oauthbearer.header.urlencode = false
kafka-1          | 	sasl.oauthbearer.iat.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jti.validation.enabled = false
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1          | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-1          | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafka-1          | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafka-1          | 	sasl.oauthbearer.scope = null
kafka-1          | 	sasl.oauthbearer.scope.claim.name = scope
kafka-1          | 	sasl.oauthbearer.sub.claim.name = sub
kafka-1          | 	sasl.oauthbearer.token.endpoint.url = null
kafka-1          | 	security.protocol = PLAINTEXT
kafka-1          | 	security.providers = null
kafka-1          | 	send.buffer.bytes = 131072
kafka-1          | 	socket.connection.setup.timeout.max.ms = 30000
kafka-1          | 	socket.connection.setup.timeout.ms = 10000
kafka-1          | 	ssl.cipher.suites = null
kafka-1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1          | 	ssl.endpoint.identification.algorithm = https
kafka-1          | 	ssl.engine.factory.class = null
kafka-1          | 	ssl.key.password = null
kafka-1          | 	ssl.keymanager.algorithm = SunX509
kafka-1          | 	ssl.keystore.certificate.chain = null
kafka-1          | 	ssl.keystore.key = null
kafka-1          | 	ssl.keystore.location = null
kafka-1          | 	ssl.keystore.password = null
kafka-1          | 	ssl.keystore.type = JKS
kafka-1          | 	ssl.protocol = TLSv1.3
kafka-1          | 	ssl.provider = null
kafka-1          | 	ssl.secure.random.implementation = null
kafka-1          | 	ssl.trustmanager.algorithm = PKIX
kafka-1          | 	ssl.truststore.certificates = null
kafka-1          | 	ssl.truststore.location = null
kafka-1          | 	ssl.truststore.password = null
kafka-1          | 	ssl.truststore.type = JKS
kafka-1          | 	transaction.timeout.ms = 60000
kafka-1          | 	transaction.two.phase.commit.enable = false
kafka-1          | 	transactional.id = null
kafka-1          | 	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
kafka-1          |  (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:06,412] INFO Created log for partition __internal_confluent_only_broker_info-0 in /var/lib/kafka/data/__internal_confluent_only_broker_info-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:06,412] INFO Created log for partition __internal_confluent_only_broker_info-0 in /var/lib/kafka/data/__internal_confluent_only_broker_info-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
kafka-1          | [2025-11-13 18:48:06,413] INFO [Partition __internal_confluent_only_broker_info-0 broker=2] No checkpointed highwatermark is found for partition __internal_confluent_only_broker_info-0 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:06,413] INFO [Partition __internal_confluent_only_broker_info-0 broker=2] No checkpointed highwatermark is found for partition __internal_confluent_only_broker_info-0 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:06,414] INFO [Partition __internal_confluent_only_broker_info-0 broker=2] Log loaded for partition __internal_confluent_only_broker_info-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:06,414] INFO [Partition __internal_confluent_only_broker_info-0 broker=2] Log loaded for partition __internal_confluent_only_broker_info-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:06,415] INFO Setting topicIdPartition ZXPKAUH-QK-mWNqO-V5w-Q:__internal_confluent_only_broker_info-0 (kafka.tier.state.FileTierPartitionState)
kafka-1          | [2025-11-13 18:48:06,415] INFO Setting topicIdPartition ZXPKAUH-QK-mWNqO-V5w-Q:__internal_confluent_only_broker_info-0 (kafka.tier.state.FileTierPartitionState)
kafka-1          | [2025-11-13 18:48:06,415] INFO [MergedLog partition=__internal_confluent_only_broker_info-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __internal_confluent_only_broker_info-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
kafka-1          | [2025-11-13 18:48:06,415] INFO [MergedLog partition=__internal_confluent_only_broker_info-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __internal_confluent_only_broker_info-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
kafka-1          | [2025-11-13 18:48:06,416] INFO [Broker id=2] Leader __internal_confluent_only_broker_info-0 with topic id Some(ZXPKAUH-QK-mWNqO-V5w-Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [2], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
kafka-1          | [2025-11-13 18:48:06,416] INFO [Broker id=2] Leader __internal_confluent_only_broker_info-0 with topic id Some(ZXPKAUH-QK-mWNqO-V5w-Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [2], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
kafka-1          | [2025-11-13 18:48:06,417] INFO [DynamicConfigPublisher broker id=2] Updating topic __internal_confluent_only_broker_info with new configuration : cleanup.policy -> compact (kafka.server.metadata.DynamicConfigPublisher)
kafka-1          | [2025-11-13 18:48:06,417] INFO [DynamicConfigPublisher broker id=2] Updating topic __internal_confluent_only_broker_info with new configuration : cleanup.policy -> compact (kafka.server.metadata.DynamicConfigPublisher)
kafka-1          | [2025-11-13 18:48:06,422] INFO [Producer clientId=__kafka.brokerTypeTopicClient-Nk018hRAQFytWskYqtQduw-2] Instantiated an idempotent producer. (org.apache.kafka.clients.producer.KafkaProducer)
kafka-1          | [2025-11-13 18:48:06,427] INFO These configurations '[confluent.metrics.reporter.bootstrap.servers, jmx.hostname, confluent.license.topic.replication.factor, allow.auto.create.topics, jmx.port]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
kafka-1          | [2025-11-13 18:48:06,427] INFO Kafka version: 8.1.0-ce (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,427] INFO Kafka commitId: d0d61297560924ac (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,427] INFO Kafka startTimeMs: 1763059686427 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,432] INFO Producing record ProducerRecord(topic=__internal_confluent_only_broker_info, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=broker_type, value=confluent_platform, timestamp=null) (kafka.server.BrokerTypeTopicCreator)
kafka-1          | [2025-11-13 18:48:06,432] INFO Producing record ProducerRecord(topic=__internal_confluent_only_broker_info, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=broker_type, value=confluent_platform, timestamp=null) (kafka.server.BrokerTypeTopicCreator)
kafka-1          | [2025-11-13 18:48:06,442] INFO [Producer clientId=__kafka.brokerTypeTopicClient-Nk018hRAQFytWskYqtQduw-2] Cluster ID: Nk018hRAQFytWskYqtQduw (org.apache.kafka.clients.Metadata)
controller-1     | [2025-11-13 18:48:06,457] INFO [ControllerServer id=1] Replaying ProducerIdsRecord ProducerIdsRecord(brokerId=2, brokerEpoch=10, nextProducerId=1000) (org.apache.kafka.controller.ProducerIdControlManager)
kafka-1          | [2025-11-13 18:48:06,557] INFO [Producer clientId=__kafka.brokerTypeTopicClient-Nk018hRAQFytWskYqtQduw-2] ProducerId set to 0 with epoch 0 (org.apache.kafka.clients.producer.internals.TransactionManager)
kafka-1          | [2025-11-13 18:48:06,585] INFO [Partition __internal_confluent_only_broker_info-0 broker=2] roll: __internal_confluent_only_broker_info-0: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 181 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:06,585] INFO [Partition __internal_confluent_only_broker_info-0 broker=2] roll: __internal_confluent_only_broker_info-0: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 181 (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:06,589] INFO [Partition __internal_confluent_only_broker_info-0 broker=2] roll: __internal_confluent_only_broker_info-0: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1763059686401 ms, time diff: 186 ms (kafka.cluster.Partition)
kafka-1          | [2025-11-13 18:48:06,589] INFO [Partition __internal_confluent_only_broker_info-0 broker=2] roll: __internal_confluent_only_broker_info-0: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1763059686401 ms, time diff: 186 ms (kafka.cluster.Partition)
springcoreapi-1  | 2025-11-13T18:48:06.580Z  INFO 118 --- [feedback-api] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 6.6.33.Final
kafka-1          | [2025-11-13 18:48:06,601] INFO Record has been added successfully at __internal_confluent_only_broker_info-0@0. (kafka.server.BrokerTypeTopicCreator)
kafka-1          | [2025-11-13 18:48:06,601] INFO Record has been added successfully at __internal_confluent_only_broker_info-0@0. (kafka.server.BrokerTypeTopicCreator)
kafka-1          | [2025-11-13 18:48:06,602] INFO [Producer clientId=__kafka.brokerTypeTopicClient-Nk018hRAQFytWskYqtQduw-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer)
kafka-1          | [2025-11-13 18:48:06,605] INFO App info kafka.producer for __kafka.brokerTypeTopicClient-Nk018hRAQFytWskYqtQduw-2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
kafka-1          | [2025-11-13 18:48:06,605] INFO Ending the BrokerTypeTopicCreator thread. (kafka.server.BrokerTypeTopicCreator)
kafka-1          | [2025-11-13 18:48:06,605] INFO Ending the BrokerTypeTopicCreator thread. (kafka.server.BrokerTypeTopicCreator)
springcoreapi-1  | 2025-11-13T18:48:06.660Z  INFO 118 --- [feedback-api] [           main] o.h.c.internal.RegionFactoryInitiator    : HHH000026: Second-level cache disabled
kafka-ui-1       | [30m2025-11-13 18:48:06,801[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: LocalKafka
kafka-ui-1       | [30m2025-11-13 18:48:06,823[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui-1       | 	auto.include.jmx.reporter = true
kafka-ui-1       | 	bootstrap.servers = [kafka-1:19092]
kafka-ui-1       | 	client.dns.lookup = use_all_dns_ips
kafka-ui-1       | 	client.id = kafka-ui-admin-1763059686-1
kafka-ui-1       | 	connections.max.idle.ms = 300000
kafka-ui-1       | 	default.api.timeout.ms = 60000
kafka-ui-1       | 	metadata.max.age.ms = 300000
kafka-ui-1       | 	metric.reporters = []
kafka-ui-1       | 	metrics.num.samples = 2
kafka-ui-1       | 	metrics.recording.level = INFO
kafka-ui-1       | 	metrics.sample.window.ms = 30000
kafka-ui-1       | 	receive.buffer.bytes = 65536
kafka-ui-1       | 	reconnect.backoff.max.ms = 1000
kafka-ui-1       | 	reconnect.backoff.ms = 50
kafka-ui-1       | 	request.timeout.ms = 30000
kafka-ui-1       | 	retries = 2147483647
kafka-ui-1       | 	retry.backoff.ms = 100
kafka-ui-1       | 	sasl.client.callback.handler.class = null
kafka-ui-1       | 	sasl.jaas.config = null
kafka-ui-1       | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui-1       | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui-1       | 	sasl.kerberos.service.name = null
kafka-ui-1       | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui-1       | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui-1       | 	sasl.login.callback.handler.class = null
kafka-ui-1       | 	sasl.login.class = null
kafka-ui-1       | 	sasl.login.connect.timeout.ms = null
kafka-ui-1       | 	sasl.login.read.timeout.ms = null
kafka-ui-1       | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui-1       | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui-1       | 	sasl.login.refresh.window.factor = 0.8
kafka-ui-1       | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui-1       | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui-1       | 	sasl.login.retry.backoff.ms = 100
kafka-ui-1       | 	sasl.mechanism = GSSAPI
kafka-ui-1       | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui-1       | 	sasl.oauthbearer.expected.audience = null
kafka-ui-1       | 	sasl.oauthbearer.expected.issuer = null
kafka-ui-1       | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui-1       | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui-1       | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui-1       | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui-1       | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui-1       | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui-1       | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui-1       | 	security.protocol = PLAINTEXT
kafka-ui-1       | 	security.providers = null
kafka-ui-1       | 	send.buffer.bytes = 131072
kafka-ui-1       | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui-1       | 	socket.connection.setup.timeout.ms = 10000
kafka-ui-1       | 	ssl.cipher.suites = null
kafka-ui-1       | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui-1       | 	ssl.endpoint.identification.algorithm = https
kafka-ui-1       | 	ssl.engine.factory.class = null
kafka-ui-1       | 	ssl.key.password = null
kafka-ui-1       | 	ssl.keymanager.algorithm = SunX509
kafka-ui-1       | 	ssl.keystore.certificate.chain = null
kafka-ui-1       | 	ssl.keystore.key = null
kafka-ui-1       | 	ssl.keystore.location = null
kafka-ui-1       | 	ssl.keystore.password = null
kafka-ui-1       | 	ssl.keystore.type = JKS
kafka-ui-1       | 	ssl.protocol = TLSv1.3
kafka-ui-1       | 	ssl.provider = null
kafka-ui-1       | 	ssl.secure.random.implementation = null
kafka-ui-1       | 	ssl.trustmanager.algorithm = PKIX
kafka-ui-1       | 	ssl.truststore.certificates = null
kafka-ui-1       | 	ssl.truststore.location = null
kafka-ui-1       | 	ssl.truststore.password = null
kafka-ui-1       | 	ssl.truststore.type = JKS
kafka-ui-1       | 
kafka-ui-1       | [30m2025-11-13 18:48:06,922[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.5.0
kafka-ui-1       | [30m2025-11-13 18:48:06,923[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: c97b88d5db4de28d
kafka-ui-1       | [30m2025-11-13 18:48:06,923[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1763059686921
springcoreapi-1  | 2025-11-13T18:48:07.351Z  INFO 118 --- [feedback-api] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
springcoreapi-1  | 2025-11-13T18:48:07.432Z  INFO 118 --- [feedback-api] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
kafka-ui-1       | [30m2025-11-13 18:48:07,555[0;39m [39mDEBUG[0;39m [[34mparallel-13[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: LocalKafka
springcoreapi-1  | 2025-11-13T18:48:07.769Z  INFO 118 --- [feedback-api] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@ec5f944
springcoreapi-1  | 2025-11-13T18:48:07.774Z  INFO 118 --- [feedback-api] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
springcoreapi-1  | 2025-11-13T18:48:07.894Z  INFO 118 --- [feedback-api] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
springcoreapi-1  | 	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
springcoreapi-1  | 	Database driver: undefined/unknown
springcoreapi-1  | 	Database version: 18.0
springcoreapi-1  | 	Autocommit mode: undefined/unknown
springcoreapi-1  | 	Isolation level: undefined/unknown
springcoreapi-1  | 	Minimum pool size: undefined/unknown
springcoreapi-1  | 	Maximum pool size: undefined/unknown
controller-1     | [2025-11-13 18:48:08,723] INFO Waiting for 8 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
springcoreapi-1  | 2025-11-13T18:48:09.547Z  INFO 118 --- [feedback-api] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
springcoreapi-1  | 2025-11-13T18:48:09.619Z  INFO 118 --- [feedback-api] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
springcoreapi-1  | 2025-11-13T18:48:10.554Z  WARN 118 --- [feedback-api] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
springcoreapi-1  | 2025-11-13T18:48:11.312Z  INFO 118 --- [feedback-api] [           main] c.j.s.g.p.f.FeedbackApiApplicationTests  : Started FeedbackApiApplicationTests in 9.682 seconds (process running for 13.522)
springcoreapi-1  | [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.13 s -- in com.joey.stanley.group.project.feedback_api.FeedbackApiApplicationTests
springcoreapi-1  | [INFO] Running com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest
springcoreapi-1  | 2025-11-13T18:48:11.878Z  INFO 118 --- [feedback-api] [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest]: FeedbackControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
springcoreapi-1  | 2025-11-13T18:48:11.960Z  INFO 118 --- [feedback-api] [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration com.joey.stanley.group.project.feedback_api.FeedbackApiApplication for test class com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest
springcoreapi-1  | 2025-11-13T18:48:12.239Z  INFO 118 --- [feedback-api] [           main] o.s.b.d.r.RestartApplicationListener     : Restart disabled due to context in which it is running
springcoreapi-1  | 
springcoreapi-1  |   .   ____          _            __ _ _
springcoreapi-1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
springcoreapi-1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
springcoreapi-1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
springcoreapi-1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
springcoreapi-1  |  =========|_|==============|___/=/_/_/_/
springcoreapi-1  | 
springcoreapi-1  |  :: Spring Boot ::                (v3.5.7)
springcoreapi-1  | 
springcoreapi-1  | 2025-11-13T18:48:12.354Z  INFO 118 --- [feedback-api] [           main] c.j.s.g.p.f.c.FeedbackControllerTest     : Starting FeedbackControllerTest using Java 25.0.1 with PID 118 (started by root in /app)
springcoreapi-1  | 2025-11-13T18:48:12.354Z  INFO 118 --- [feedback-api] [           main] c.j.s.g.p.f.c.FeedbackControllerTest     : No active profile set, falling back to 1 default profile: "default"
springcoreapi-1  | 2025-11-13T18:48:12.761Z  WARN 118 --- [feedback-api] [           main] o.s.w.c.s.GenericWebApplicationContext   : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'feedbackController' defined in file [/app/target/classes/com/joey/stanley/group/project/feedback_api/controllers/FeedbackController.class]: Unsatisfied dependency expressed through constructor parameter 0: No qualifying bean of type 'com.joey.stanley.group.project.feedback_api.services.FeedbackService' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
springcoreapi-1  | 2025-11-13T18:48:12.786Z  INFO 118 --- [feedback-api] [           main] .s.b.a.l.ConditionEvaluationReportLogger : 
springcoreapi-1  | 
springcoreapi-1  | Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
springcoreapi-1  | 2025-11-13T18:48:12.885Z ERROR 118 --- [feedback-api] [           main] o.s.b.d.LoggingFailureAnalysisReporter   : 
springcoreapi-1  | 
springcoreapi-1  | ***************************
springcoreapi-1  | APPLICATION FAILED TO START
springcoreapi-1  | ***************************
springcoreapi-1  | 
springcoreapi-1  | Description:
springcoreapi-1  | 
springcoreapi-1  | Parameter 0 of constructor in com.joey.stanley.group.project.feedback_api.controllers.FeedbackController required a bean of type 'com.joey.stanley.group.project.feedback_api.services.FeedbackService' that could not be found.
springcoreapi-1  | 
springcoreapi-1  | 
springcoreapi-1  | Action:
springcoreapi-1  | 
springcoreapi-1  | Consider defining a bean of type 'com.joey.stanley.group.project.feedback_api.services.FeedbackService' in your configuration.
springcoreapi-1  | 
springcoreapi-1  | 2025-11-13T18:48:12.903Z  WARN 118 --- [feedback-api] [           main] o.s.test.context.TestContextManager      : Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener] to prepare test instance [com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest@7c8537e9]
springcoreapi-1  | 
springcoreapi-1  | java.lang.IllegalStateException: Failed to load ApplicationContext for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:180) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:130) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:155) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:111) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:260) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:159) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$10(ClassBasedTestDescriptor.java:383) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.executeAndMaskThrowable(ClassBasedTestDescriptor.java:388) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$11(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:186) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:197) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1716) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:570) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:560) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:153) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:176) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:632) ~[na:na]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestInstancePostProcessors(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$instantiateAndPostProcessTestInstance$6(ClassBasedTestDescriptor.java:293) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:292) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:281) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at java.base/java.util.Optional.orElseGet(Optional.java:364) ~[na:na]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:280) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:27) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:112) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:111) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:69) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:128) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:128) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604) ~[na:na]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604) ~[na:na]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.LauncherAdapter.executeWithoutCancellationToken(LauncherAdapter.java:60) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.LauncherAdapter.execute(LauncherAdapter.java:52) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:203) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:168) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:136) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'feedbackController' defined in file [/app/target/classes/com/joey/stanley/group/project/feedback_api/controllers/FeedbackController.class]: Unsatisfied dependency expressed through constructor parameter 0: No qualifying bean of type 'com.joey.stanley.group.project.feedback_api.services.FeedbackService' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
springcoreapi-1  | 	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:804) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1395) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1232) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:569) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:529) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:339) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:373) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1228) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1194) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1130) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:990) ~[spring-context-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627) ~[spring-context-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752) ~[spring-boot-3.5.7.jar:3.5.7]
springcoreapi-1  | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439) ~[spring-boot-3.5.7.jar:3.5.7]
springcoreapi-1  | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318) ~[spring-boot-3.5.7.jar:3.5.7]
springcoreapi-1  | 	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:144) ~[spring-boot-test-3.5.7.jar:3.5.7]
springcoreapi-1  | 	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58) ~[spring-core-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46) ~[spring-core-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1461) ~[spring-boot-3.5.7.jar:3.5.7]
springcoreapi-1  | 	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:563) ~[spring-boot-test-3.5.7.jar:3.5.7]
springcoreapi-1  | 	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:144) ~[spring-boot-test-3.5.7.jar:3.5.7]
springcoreapi-1  | 	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:110) ~[spring-boot-test-3.5.7.jar:3.5.7]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:225) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:152) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	... 80 common frames omitted
springcoreapi-1  | Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.joey.stanley.group.project.feedback_api.services.FeedbackService' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:2314) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1733) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1653) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ~[spring-beans-6.2.12.jar:6.2.12]
springcoreapi-1  | 	... 106 common frames omitted
springcoreapi-1  | 
springcoreapi-1  | 2025-11-13T18:48:12.978Z  WARN 118 --- [feedback-api] [           main] o.s.test.context.TestContextManager      : Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener] to prepare test instance [com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest@1766b009]
springcoreapi-1  | 
springcoreapi-1  | java.lang.IllegalStateException: ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:145) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:130) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:155) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:111) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:260) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:159) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$10(ClassBasedTestDescriptor.java:383) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.executeAndMaskThrowable(ClassBasedTestDescriptor.java:388) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$11(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:186) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:197) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1716) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:570) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:560) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:153) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:176) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:632) ~[na:na]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestInstancePostProcessors(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$instantiateAndPostProcessTestInstance$6(ClassBasedTestDescriptor.java:293) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:292) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:281) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at java.base/java.util.Optional.orElseGet(Optional.java:364) ~[na:na]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:280) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:27) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:112) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:111) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:69) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:128) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:128) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604) ~[na:na]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604) ~[na:na]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.LauncherAdapter.executeWithoutCancellationToken(LauncherAdapter.java:60) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.LauncherAdapter.execute(LauncherAdapter.java:52) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:203) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:168) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:136) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 
springcoreapi-1  | 2025-11-13T18:48:12.991Z  WARN 118 --- [feedback-api] [           main] o.s.test.context.TestContextManager      : Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener] to prepare test instance [com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest@4a571516]
springcoreapi-1  | 
springcoreapi-1  | java.lang.IllegalStateException: ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:145) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:130) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:155) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:111) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:260) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:159) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$10(ClassBasedTestDescriptor.java:383) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.executeAndMaskThrowable(ClassBasedTestDescriptor.java:388) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$11(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:186) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:197) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1716) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:570) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:560) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:153) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:176) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:632) ~[na:na]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestInstancePostProcessors(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$instantiateAndPostProcessTestInstance$6(ClassBasedTestDescriptor.java:293) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:292) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:281) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at java.base/java.util.Optional.orElseGet(Optional.java:364) ~[na:na]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:280) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:27) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:112) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:111) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:69) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:128) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:128) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604) ~[na:na]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604) ~[na:na]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.LauncherAdapter.executeWithoutCancellationToken(LauncherAdapter.java:60) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.LauncherAdapter.execute(LauncherAdapter.java:52) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:203) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:168) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:136) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 
springcoreapi-1  | 2025-11-13T18:48:13.002Z  WARN 118 --- [feedback-api] [           main] o.s.test.context.TestContextManager      : Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener] to prepare test instance [com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest@63f609a4]
springcoreapi-1  | 
springcoreapi-1  | java.lang.IllegalStateException: ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:145) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:130) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:155) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:111) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:260) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:159) ~[spring-test-6.2.12.jar:6.2.12]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$10(ClassBasedTestDescriptor.java:383) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.executeAndMaskThrowable(ClassBasedTestDescriptor.java:388) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeTestInstancePostProcessors$11(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:186) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:197) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1716) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:570) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:560) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:153) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:176) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265) ~[na:na]
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:632) ~[na:na]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestInstancePostProcessors(ClassBasedTestDescriptor.java:382) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$instantiateAndPostProcessTestInstance$6(ClassBasedTestDescriptor.java:293) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:292) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:281) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at java.base/java.util.Optional.orElseGet(Optional.java:364) ~[na:na]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:280) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:27) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:112) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:111) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:69) ~[junit-jupiter-engine-5.12.2.jar:5.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:128) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:128) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604) ~[na:na]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604) ~[na:na]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) ~[junit-platform-engine-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47) ~[junit-platform-launcher-1.12.2.jar:1.12.2]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.LauncherAdapter.executeWithoutCancellationToken(LauncherAdapter.java:60) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.LauncherAdapter.execute(LauncherAdapter.java:52) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:203) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:168) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:136) ~[surefire-junit-platform-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495) ~[surefire-booter-3.5.4.jar:3.5.4]
springcoreapi-1  | 
springcoreapi-1  | [ERROR] Tests run: 4, Failures: 0, Errors: 4, Skipped: 0, Time elapsed: 1.144 s <<< FAILURE! -- in com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest
springcoreapi-1  | [ERROR] com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest.testFindFeedbackByIdFailure -- Time elapsed: 0.011 s <<< ERROR!
springcoreapi-1  | java.lang.IllegalStateException: Failed to load ApplicationContext for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:180)
springcoreapi-1  | 	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:130)
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:155)
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:111)
springcoreapi-1  | 	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:260)
springcoreapi-1  | 	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:159)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:186)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:197)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214)
springcoreapi-1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1716)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:570)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:560)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:153)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:176)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:632)
springcoreapi-1  | 	at java.base/java.util.Optional.orElseGet(Optional.java:364)
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
springcoreapi-1  | Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'feedbackController' defined in file [/app/target/classes/com/joey/stanley/group/project/feedback_api/controllers/FeedbackController.class]: Unsatisfied dependency expressed through constructor parameter 0: No qualifying bean of type 'com.joey.stanley.group.project.feedback_api.services.FeedbackService' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
springcoreapi-1  | 	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:804)
springcoreapi-1  | 	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1395)
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1232)
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:569)
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:529)
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:339)
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:373)
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)
springcoreapi-1  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1228)
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1194)
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1130)
springcoreapi-1  | 	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:990)
springcoreapi-1  | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
springcoreapi-1  | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
springcoreapi-1  | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
springcoreapi-1  | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
springcoreapi-1  | 	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:144)
springcoreapi-1  | 	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58)
springcoreapi-1  | 	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46)
springcoreapi-1  | 	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1461)
springcoreapi-1  | 	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:563)
springcoreapi-1  | 	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:144)
springcoreapi-1  | 	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:110)
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:225)
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:152)
springcoreapi-1  | 	... 19 more
springcoreapi-1  | Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.joey.stanley.group.project.feedback_api.services.FeedbackService' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:2314)
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1733)
springcoreapi-1  | 	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1653)
springcoreapi-1  | 	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
springcoreapi-1  | 	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
springcoreapi-1  | 	... 45 more
springcoreapi-1  | 
springcoreapi-1  | [ERROR] com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest.testCreateNewFeedbackSuccess -- Time elapsed: 0.001 s <<< ERROR!
springcoreapi-1  | java.lang.IllegalStateException: ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:145)
springcoreapi-1  | 	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:130)
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:155)
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:111)
springcoreapi-1  | 	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:260)
springcoreapi-1  | 	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:159)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:186)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:197)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214)
springcoreapi-1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1716)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:570)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:560)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:153)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:176)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:632)
springcoreapi-1  | 	at java.base/java.util.Optional.orElseGet(Optional.java:364)
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
springcoreapi-1  | 
springcoreapi-1  | [ERROR] com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest.testCreateNewFeedbackFailure -- Time elapsed: 0.001 s <<< ERROR!
springcoreapi-1  | java.lang.IllegalStateException: ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:145)
springcoreapi-1  | 	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:130)
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:155)
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:111)
springcoreapi-1  | 	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:260)
springcoreapi-1  | 	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:159)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:186)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:197)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214)
springcoreapi-1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1716)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:570)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:560)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:153)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:176)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:632)
springcoreapi-1  | 	at java.base/java.util.Optional.orElseGet(Optional.java:364)
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
springcoreapi-1  | 
springcoreapi-1  | [ERROR] com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest.testFindFeedbackByIdSuccess -- Time elapsed: 0.001 s <<< ERROR!
springcoreapi-1  | java.lang.IllegalStateException: ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | 	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:145)
springcoreapi-1  | 	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:130)
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:155)
springcoreapi-1  | 	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:111)
springcoreapi-1  | 	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:260)
springcoreapi-1  | 	at org.springframework.test.context.junit.jupiter.SpringExtension.postProcessTestInstance(SpringExtension.java:159)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:186)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:197)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:214)
springcoreapi-1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1716)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:570)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:560)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:153)
springcoreapi-1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:176)
springcoreapi-1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265)
springcoreapi-1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:632)
springcoreapi-1  | 	at java.base/java.util.Optional.orElseGet(Optional.java:364)
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
springcoreapi-1  | 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1604)
springcoreapi-1  | 
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] Results:
springcoreapi-1  | [INFO] 
springcoreapi-1  | [ERROR] Errors: 
springcoreapi-1  | [ERROR]   FeedbackControllerTest.testCreateNewFeedbackFailure » IllegalState ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | [ERROR]   FeedbackControllerTest.testCreateNewFeedbackSuccess » IllegalState ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | [ERROR]   FeedbackControllerTest.testFindFeedbackByIdFailure » IllegalState Failed to load ApplicationContext for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | [ERROR]   FeedbackControllerTest.testFindFeedbackByIdSuccess » IllegalState ApplicationContext failure threshold (1) exceeded: skipping repeated attempt to load context for [WebMergedContextConfiguration@64e6cdad testClass = com.joey.stanley.group.project.feedback_api.controllers.FeedbackControllerTest, locations = [], classes = [com.joey.stanley.group.project.feedback_api.FeedbackApiApplication], contextInitializerClasses = [], activeProfiles = [], propertySourceDescriptors = [], propertySourceProperties = ["org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true"], contextCustomizers = [[ImportsContextCustomizer@5e6b2641 key = [org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientWebSecurityAutoConfiguration, org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration, org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration, org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration, org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration, org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration, org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration, org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration, org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration, org.springframework.boot.test.autoconfigure.web.reactive.WebTestClientAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration, org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration, org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration, org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration, org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration, org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@f68f0dc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@38145825, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.reactor.netty.DisableReactorResourceFactoryGlobalResourcesContextCustomizerFactory$DisableReactorResourceFactoryGlobalResourcesContextCustomizerCustomizer@4470fbd6, org.springframework.boot.test.autoconfigure.OnFailureConditionReportContextCustomizerFactory$OnFailureConditionReportContextCustomizer@503f91c3, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@18d8da77, org.springframework.boot.test.autoconfigure.actuate.observability.ObservabilityContextCustomizerFactory$DisableObservabilityContextCustomizer@1f, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@189873f, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@45449d9b, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizer@61710c6, org.springframework.test.context.support.DynamicPropertiesContextCustomizer@0, org.springframework.boot.test.context.SpringBootTestAnnotation@45601a0f], resourceBasePath = "src/main/webapp", contextLoader = org.springframework.boot.test.context.SpringBootContextLoader, parent = null]
springcoreapi-1  | [INFO] 
springcoreapi-1  | [ERROR] Tests run: 5, Failures: 0, Errors: 4, Skipped: 0
springcoreapi-1  | [INFO] 
springcoreapi-1  | [INFO] ------------------------------------------------------------------------
springcoreapi-1  | [INFO] BUILD FAILURE
springcoreapi-1  | [INFO] ------------------------------------------------------------------------
springcoreapi-1  | [INFO] Total time:  26.677 s
springcoreapi-1  | [INFO] Finished at: 2025-11-13T18:48:13Z
springcoreapi-1  | [INFO] ------------------------------------------------------------------------
springcoreapi-1  | [ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:3.5.4:test (default-test) on project feedback-api: 
springcoreapi-1  | [ERROR] 
springcoreapi-1  | [ERROR] See /app/target/surefire-reports for the individual test results.
springcoreapi-1  | [ERROR] See dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream.
springcoreapi-1  | [ERROR] -> [Help 1]
springcoreapi-1  | [ERROR] 
springcoreapi-1  | [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
springcoreapi-1  | [ERROR] Re-run Maven using the -X switch to enable full debug logging.
springcoreapi-1  | [ERROR] 
springcoreapi-1  | [ERROR] For more information about the errors and possible solutions, please read the following articles:
springcoreapi-1  | [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[Kspringcoreapi-1 exited with code 1
